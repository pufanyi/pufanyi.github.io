<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="EPlMR3j8io1DcEScvNJuBPxLxCTSnNUjNwF4ZBhRO-I"> <meta name="msvalidate.01" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Stochastic Processes and Reinforcement Learning | Fanyi Pu </title> <meta name="author" content="Fanyi Pu"> <meta name="description" content="Notes for NTU MH3512 Stochastic Processes"> <meta name="keywords" content="Fanyi, Fanyi Pu, 濮凡轶"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?16404ec2cd2689e8d0f38f73fe0d38f9"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?e19b909c603d80f6dfde4781dffed50c" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/avatar_very_small.webp?3828c08bd9576f9a024f464411e622b9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pufanyi.github.io/blog/SPRL/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Fanyi</span> Pu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/oi-blog/">oi-blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/resume/resume.pdf">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Stochastic Processes and Reinforcement Learning</h1> <p class="post-meta"> Created in October 16, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/probability-theory"> <i class="fa-solid fa-hashtag fa-sm"></i> Probability Theory</a>   <a href="/blog/tag/reinforcement-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Reinforcement Learning</a>   ·   <a href="/blog/category/notes"> <i class="fa-solid fa-tag fa-sm"></i> Notes</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>看我能坚持多久。。。</p> <h2 id="markov-chains">Markov Chains</h2> <p><a href="https://link.springer.com/book/10.1007/978-981-13-0659-4" rel="external nofollow noopener" target="_blank">教材捏</a></p> <p><a href="https://personal.ntu.edu.sg/ariel.neufeld/script_MH3512_Marked.pdf" rel="external nofollow noopener" target="_blank">划了重点的教材捏</a>（prof 划的，虽然我感觉他把整本书划了一遍。。。）</p> <h3 id="gambling-problems">Gambling Problems</h3> <p>有 \(S\) 块钱，\(A\) 有 \(K\) 块钱，\(B\) 有 \(S-K\) 块。每次有 \(p\) 的概率 \(A\) 从 \(B\) 拿走一块，\(q=1-p\) 的概率 \(B\) 从 \(A\) 拿走一块。谁拿到 \(S\) 块钱就算赢。</p> \[X_{n+1}=\begin{cases} X_n+1 &amp; p \\ X_n-1 &amp; q \end{cases}\] <p>\(f_S(k)\) 表示 \(A\) 赢的概率。很显然我们有：</p> \[f_S(k)=pf_{S}(k+1)+qf_{S}(k-1)\] <p>不难解出</p> \[f_S(k)=\frac{(p/q)^{S-k}-1}{(p/q)^S-1}\] <p>\(T_{0, S}\) 表示一个游戏啥时候结束，\(h_S(k)=\mathbb{E}\left[T_{0, S}\mid X_0=K\right]\)。</p> <p>很显然</p> \[h_S(k)=1+ph_S(k+1)+qh_S(k-1)\] <p>这个方程的特解比较难搞，注意到 \(p+q=1\)，我们可以改写成差分方程：</p> \[-1=p\left(h_S(k+1)-h_S(k)\right)+q\left(h_S(k)-h_S(k-1)\right)\] <p>观察出方程在 \(p\neq q\) 的时候一个特解为 \(\frac{k}{q-p}\)。</p> <p>不难解出齐次方程 \(h_S(k)=ph_S(k+1)+qh_S(k-1)\) 的解，最终可以得到在 \(p\neq q\) 时</p> \[h_s(k)=\frac{1}{q-p}\left(k-S\cdot\frac{1-(q/p)^k}{1-(q/p)^S}\right)\] <p>当 \(p=q=\frac{1}{2}\) 时，我们有特解 \(-k^2\)。所以说 \(p=q\) 时</p> \[h_S(k)=k(S-k)\] <h3 id="random-walks">Random Walks</h3> <p>Bernoulli Random Walks: \(X_n\) 相互独立，其中</p> \[\begin{cases} \mathbb{P}(X_k=+1)=p \\ \mathbb{P}(X_k=-1)=q \end{cases}\] <p>\(p+q=1\)，然后我们定义</p> \[S_n=\sum_{i=1}^nX_i\] <p>很显然 \(\mathbb{P}(S_{2n}=2k+1)=\mathbb{P}(S_{2n+1}=2k)=0\)，然后</p> \[\begin{cases} \mathbb{P}(S_{2n}=2k)=\binom{2n}{n+k}p^{n+k}q^{n-k} \\ \mathbb{P}(S_{2n+1}=2k+1)=\binom{2n+1}{n+k+1}p^{n+k+1}q^{n-k} \end{cases}\] <p>难度在我们怎么计算他啥时候回到 \(0\)。我们令</p> \[T_0^r=\inf\{n\geq 1: S_n=0\}\] <p>表示第一次回到 \(0\) 的时间。</p> <p>然后我们设</p> \[g(n)=\mathbb{P}\left(T_0^r=n\mid S_0=0\right)\] <p>也就是在第 \(n\) 步第一次回到 \(0\) 的概率。那很显然 \(g(2k+1)=0\)。</p> <p>接下来是一个比较神奇的套路，就是我们假设 \(h(n)\) 为第 \(n\) 步回到 \(0\) 的概率，那我们可以得到一个卷积式子：</p> \[h(n)=\sum_{k=0}^{n-2}g(n-k)h(k)\] <p>也就是先走 \(n-k\) 步第一次回到 \(0\)，然后继续走 \(k\) 步回到 \(0\)。所以我们现在只要解决 \(h\) 就可以了。</p> <p>我们考虑 \(h(n)\) 的生成函数</p> \[H(s)=\mathbb{E}\left[s^{T_0^r}\cdot\mathbb{1}_{T_0^r&lt;\infty}\right]=\sum_{n=0}^\infty h(n)s^n\] <p>大概推推：</p> \[\begin{aligned} H(s)&amp;=\sum_{n=0}^\infty h(n)s^n\\ &amp;=\sum_{n=0}^\infty\binom{2n}{n}p^nq^ns^{2n}\\ &amp;=\sum_{n=0}^\infty\frac{(2n)!}{(n!)^2}\left(pqs^2\right)^n\\ &amp;=\sum_{n=0}^\infty\frac{\left(\prod_{i=1}^n2i\right)\left(\prod_{i=1}^n(2i-1)\right)}{(n!)^2}\left(pqs^2\right)^n\\ &amp;=\sum_{n=0}^\infty\frac{\prod_{i=1}^n(2i-1)}{n!}\left(2pqs^2\right)^n\\ &amp;=\sum_{n=0}^\infty\frac{(-2)^n\prod_{i=1}^n\left(-\frac{1}{2}-(i-1)\right)}{n!}\left(2pqs^2\right)^n\\ &amp;=\sum_{n=0}^\infty\frac{\left(-\frac{1}{2}\right)^{\underline{i}}}{n!}\left(-4pqs^2\right)^n\\ &amp;=\left(1-4pqs^2\right)^{-\frac{1}{2}} \end{aligned}\] <p>又考虑到：</p> \[\begin{aligned} G(s)H(s)&amp;=\left(\sum_{i=1}^\infty s^ig(i)\right)\left(\sum_{j=0}^\infty s^jh(j)\right)\\ &amp;=\sum_{i=2}^\infty\sum_{j=0}^\infty s^{i+j}g(i)h(j)\\ &amp;=\sum_{k=2}^\infty s^k\sum_{i=2}^\infty g(i)h(k-i)\\ &amp;=\sum_{k=2}^\infty s^k h(k)\\ &amp;=-1 + \sum_{k=0}^\infty s^kh(k)\\ &amp;=-1 + H(s) \end{aligned}\] <p>于是乎</p> \[G(s)=1-\frac{1}{H(s)}=1-\sqrt{1-4pqs^2}\] <p>所以</p> \[\begin{aligned} \mathbb{P}\left(T_0^r=\infty\mid S_0=0\right)&amp;=1-\mathbb{P}\left(T_0^r&lt;\infty\mid S_0=0\right)\\ &amp;=1-G(1)=\sqrt{1-4pq}\\ &amp;=\sqrt{4p^2-4p+1}\\ &amp;=\lvert 2p-1\rvert\\ &amp;=\lvert p-q\rvert \end{aligned}\] <p>而根据前面的 Gambling Problems，其实我们已经解出当 \(k\neq 0\) 时：</p> \[\mathbb{P}\left(T_0^r=\infty\mid S_0=k\right)=1-\lim_{S\to\infty}f_S(k)=\max\left\{0, 1-\left(\frac{q}{p}\right)^k\right\}\] <p>然后我们来计算 \(\mathbb{E}\left[T_0^r\mid S_0=0\right]\) 的时候会发现如果 \(\mathbb{P}\left(T_0^r\mid S_0=0\right)&gt;0\) 的时候这个期望肯定是 \(\infty\)。而 \(\mathbb{P}\left(T_0^r\mid S_0=0\right)\) 只有在 \(p=q=\frac{1}{2}\) 的时候才会为 \(0\)。然鹅当 \(p=q=\frac{1}{2}\) 时：</p> \[\mathbb{E}\left[T_0^r\mid S_0=0\right]=\mathbb{E}\left[T_0^r \cdot\mathbb{1}_{\left\{T_0^r&lt;\infty\right\}}\mid S_0=0\right]=\left.\frac{\partial G}{\partial s}\right|_{s=1}=\infty\] <p>所以我们不管 \(p, q\) 都有：</p> \[\mathbb{E}\left[T_0^r\mid S_0=0\right]=\infty\] <p>关于 first time 的 distribution 的话，我们不难算出</p> \[\mathbb{P}\left(T_0^r=2k\mid S_0=0\right)=\frac{1}{(2k)!}\left.\frac{\partial^{2k}G}{\partial s^{2k}}\right|_{s=0}=\frac{1}{2k-1}\binom{2k}{k}(pq)^k\] <h3 id="discrete-time-markov-chains">Discrete-Time Markov Chains</h3> <p>Markov property 指的是下一步的 distribution 只跟当前有关：</p> \[\mathbb{P}\left(Z_{n+1}=j\mid Z_n=i_n, \cdots, Z_0=i_0\right)=\mathbb{P}\left(Z_{n+1}=j\mid Z_n=i_n\right)\] <p>\(\pi_n\) 是行向量，转移方程</p> \[\pi_{n+1}=\pi_n P\] <p>首先研究 hitting probabilities。假设状态空间为 \(\mathbb{S}\)，现在有一个点集 \(A\subset\mathbb{S}\) 是吸收点。也就是说 \(\forall s\in\mathbb{S}, P_{s, s}=1\)。我们康康从 \(k\) 开始被 \(A\) 中哪个点吸收的分布：</p> \[g_l(k)=\mathbb{P}\left(Z_{T_A}=l\mid Z_0=k\right)\] <p>其中 \(T_A\) 表示第一次撞到 \(A\) 的概率。</p> <p>显然</p> \[g_l(k) = P_{k, l} + \sum_{m\in\mathbb{S}\setminus A}P_{k, m} g_l(m)\] <p>然后我们研究从一个点开始期望多久被吸收，我们定义：</p> \[h_A(k) = \mathbb{E}\left[T_A\mid Z_0=k\right]\] <p>显然</p> \[h_A(k) = 1 + \sum_{m\in\mathbb{S}\setminus A}P_{k, m} h_A(m)\] <p>当然很多事会我们会钦定最后 \(d\) 个为吸收点，也就是：</p> \[P = \begin{bmatrix} Q &amp; R \\ 0 &amp; I_d \\ \end{bmatrix}\] <p>酱一来我们就可以简单地写成</p> \[h_A = \mathbb{1}_{n-d} + Qh_A\] <p>当然很多时候我们每个点都是有个 utility 的，也就是说：</p> \[h_A(k) = \mathbb{E}\left[\sum_{n=0}^{T_A}r(Z_n)\mid Z_0=k\right]\] <p>那酱的话就把 \(\mathbb{1}\) 换成 \(r\) 就可以了。</p> <p>接下来是 return times。我们定义 \(T_j^r\) 为第一次到 \(j\) 的时间（但不是 \(Z_0\)）：</p> \[T_j^r = \inf\{n\ge 1: Z_n=j\}\] <p>然后 \(\mu_j(i)\) 表示从 \(i\) 开始第一次回到 \(j\) 的期望时间：</p> \[\mu_j(i) = \mathbb{E}\left[T_j^r\mid Z_0=i\right]\] <p>酱紫 \(\mu_i(i)\) 就成功定义了“return times”。</p> <p>显然：</p> \[\mu_j(i) = 1 + \sum_{m\in\mathbb{S}}P_{i, m}\mu_j(m)\] <p>我们接下来定义 \(p_{i, j}\) 为从 \(i\) 能走到 \(j\) 的概率，当然一开始不算：</p> \[p_{i, j} = \mathbb{P}\left(T_j^r&lt;\infty\mid Z_0=i\right)\] <p>我们定义 \(f_{i, j}^{(n)}\) 为从 \(i\) 开始走 \(n\) 步恰好第一次走到 \(j\) 的概率：</p> \[f_{i, j}^{(n)} = \mathbb{P}\left(T_j^r=n\mid Z_0=i\right)\] <p>显然</p> \[p_{i, j} = \sum_{n=1}^\infty f_{i, j}^{(n)}\] <p>Number of returns 被定义为：</p> \[R_j = \sum_{n=1}^\infty\mathbb{1}_{\{Z_n=j\}}\] <p>那么 \(R_j\) 的分布其实是：</p> \[\mathbb{P}(R_j = m \mid Z_0 = i) = \begin{cases} 1 - p_{i, j} &amp; m = 0 \\ p_{i, j}\cdot p_{j, j}^{m - 1}\cdot (1 - p_{j, j}) &amp; m \ge 1 \end{cases}\] <p>那期望也好算：</p> \[\mathbb{E}[R_j \mid Z_0 = i] = \sum_{m = 1}^\infty m\cdot p_{i, j}\cdot p_{j, j}^{m - 1}\cdot (1 - p_{j, j}) = \frac{1}{1 - p_{j, j}}\] <p>所以说我们得到一个性质就是，如果要</p> \[\mathbb{E}[R_i\mid Z_0=i] = \frac{1}{1 - p_{i, i}}\] <p>这个东西有穷，当且仅当 \(p_{i, i} &lt; 1\)。</p> <p>而还有一个意义比较明确而且封闭的式子是：</p> \[\mathbb{E}[R_j\mid Z_0=i] = \mathbb{E}\left[\mathbb{1}_{\{X_n=j\}}\mid X_0=i\right] = \sum_{n=1}^\infty\left[P^n\right]_{i, j} = -\mathbb{1}_{\{i=j\}} + \left[(I - P)^{-1}\right]_{i, j}\] <h3 id="branching-processes">Branching Processes</h3> <p>一开始我有一个东西，然后没过一段时间这个东西随机分裂成 \(Y\) 个一样的东西，然后一直这样分裂下去。</p> \[X_0 = 1, X_{n+1} = \sum_{k=1}^{X_n} Y_k\] <p>其中</p> \[\mathbb{P}(Y &lt; \infty) = \sum_{n\ge 0}\mathbb{P}(Y = n) = 1\] <p>考虑转移矩阵 \(P\)，\(P_{i,j}\) 表示 \(i\) 个东西分裂成 \(j\) 个的概率。显然 \(P_{0,0}=1\)，没有东西就无法分裂。\(P_{1, j}=\mathbb{P}(Y=j)\)，指的是从一个东西分裂开来。</p> <p>酱紫的话是个树状结构，所以叫 Branching Process。</p> <p>考虑生成函数 \(G_n(s) = \mathbb{E}\left[s^{X_n}\mid X_0 = 1\right]\) 表示第 \(n\) 代的概率生成函数，我们有：</p> \[G_{n+1}(s) = G_n(G_1(s)) = G_1(G_n(s))\] <p>证明的话：</p> \[\begin{aligned} G_{n+1}(s) &amp;= \mathbb{E}\left[s^{X_{n+1}}\mid X_0 = 1\right]\\ &amp;=\mathbb{E}\left[s^{\sum_{l=1}^{X_n}Y_l}\mid X_0=1\right]\\ &amp;=\sum_{k=1}^\infty\mathbb{E}\left[\prod_{l=1}^{k}s^{Y_l}\mid X_n=k\right]\mathbb{P}(X_n=k\mid X_1 = 1)\\ &amp;=\sum_{k=1}^\infty\mathbb{E}\left[s^{Y}\right]^k\mathbb{P}(X_n=k\mid X_1 = 1)\\ &amp;=\sum_{k=1}^\infty G_1(s)^k\mathbb{P}(X_n=k\mid X_1 = 1)\\ &amp;=G_n(G_1(s)) \end{aligned}\] <p>于是乎对于 \(n\) 轮后的期望值我们有：</p> \[\begin{aligned} \mu_n &amp;= \mathbb{E}\left[X_n\mid X_0 = 1\right]\\ &amp;=\left.\frac{\partial G_n(s)}{\partial s}\right|_{s=1}\\ &amp;=\left.\frac{\partial G_{n-1}(G_1(s))}{\partial G_1(s)}\cdot\frac{\partial G_1(s)}{\partial s}\right|_{s=1}\\ &amp;=\left.\frac{\partial G_{n-1}(G_1(s))}{\partial G_1(s)}\right|_{s=1}\cdot\left.\lim_{s\to 1^-}\frac{\partial G_1(s)}{\partial s}\right|_{s=1}\\ &amp;=\left.\frac{\partial G_{n-1}(s)}{\partial s}\right|_{s=1}\cdot\left.\frac{\partial G_1(s)}{\partial s}\right|_{s=1}\\ &amp;=\mu_{n-1}\mu_1\\ &amp;=\mu_1^n \end{aligned}\] <p>对于一个 branching process \((X_n)_{n\in\mathbb{N}}\)：</p> <ul> <li>Supercritical: \(\mu_1 &gt; 1\)，\(\mu_n\to\infty\)</li> <li>Critical: \(\mu_1 = 1\)，\(\mu_n\to\infty\)</li> <li>Subcritical: \(\mu_1 &lt; 1\)，\(\mu_n\to 0\)</li> </ul> <p>同样的，我们考虑方差</p> \[\begin{aligned} \sigma_n^2 &amp;= \mathrm{Var}\left[X_n\mid X_0 = 1\right]\\ &amp;= \left.\frac{1}{2}\frac{\partial^2G_{n}(s)}{\partial s^2}\right|_{s=1}\\ &amp;= \left.\frac{1}{2}\frac{\partial}{\partial s}\left(\frac{\partial}{\partial s} G_{n-1}(s)\cdot\frac{\partial}{\partial s}G_1(s)\right)\right|_{s=1}\\ &amp;= \left.\frac{\partial^2}{\partial s^2}G_{n-1}(s)\cdot\frac{\partial}{\partial s}G_1(s)\right|_{s=1} + \left.\frac{\partial}{\partial s}G_{n-1}(s)\cdot\frac{\partial^2}{\partial s^2}G_1(s)\right|_{s=1}\\ &amp;= \sigma_{n-1}^2\mu_1 + \mu_{n-1}\sigma_1^2\\ &amp;= \sigma_{n-1}^2\mu_1 + \mu_{1}^{n-1}\sigma_1^2\\ &amp;=\begin{cases} n\sigma_1^2 &amp; \mu = 1\\ \sigma_1^2\mu_1^{n-1}\frac{1-\mu_1^n}{1-\mu_1} &amp; \mu\neq 1 \end{cases} \end{aligned}\] <p>接下来我们要研究的是，\(X_n\) 能延续多久，也就是“time to extinction”。我们定义</p> \[T_0 = \inf\{n\ge 0: X_n = 0\}\] <p>以及最终的 extinction probability</p> \[\alpha_k = \mathbb{P}(T_0 &lt; \infty\mid X_0 = k)\] <p>首先显然我们有：</p> \[\begin{aligned} \mathbb{P}(T_0 = n\mid X_0 = 1) &amp;= \mathbb{P}(X_n = 0\mid X_0 = 1) - \mathbb{P}(X_{n-1} = 0\mid X_0 = 1) \\ &amp;= G_n(0) - G_{n-1}(0)\\ &amp;= G_1(G_{n-1}(0)) - G_{n-1}(0) \end{aligned}\] <h3 id="continuous-time-markov-chains">Continuous-Time Markov Chains</h3> <p>首先是 Poisson Process。就是隔一段时间往上 \(+1\)。\(N_t\) 表示 \(t\) 时刻是多少，其中 \(N_0=0\)。我们定义 \(T_k\) 为第一次到达 \(k\) 的时间。</p> \[N_t = \sum_{k\ge 1} k\cdot\mathbb{1}_{t\in \left[T_{k-1}, T_k\right)} = \sum_{k\ge 1}\mathbb{1}_{t\in \left[T_{k-1}, \infty\right)}\] <p>我们需要这种过程满足两个性质：</p> <ol> <li>Independence of increments: 对于任意的 \(0\le t_1 &lt; t_2 &lt; \cdots &lt; t_n\)，\(N_{t_1}-N_{t_0}, N_{t_2}-N_{t_1}, \cdots, N_{t_n}-N_{t_{n-1}}\) 是相互独立的。</li> <li>Stationarity of increments: \(N_{t+s}-N_s\sim N_t\)。</li> </ol> <p>那其实很显然这就是一个 poison distribution 嘛：</p> \[\mathbb{P}(N_t - N_s = k) = e^{-\lambda(t-s)}\frac{(\lambda(t-s))^k}{k!}\] <p>其中</p> \[\lambda = \lim_{h\to 0^+} \frac{1}{h}\mathbb{P}(N_h = 1)\] <p>然后还有就是 \(T_1\) 个 exp distribution 有关，\(T_n\) 跟 gamma distribution 有关。</p> \[T_n \sim \Gamma(n, \lambda): f_{T_n}(t) = \lambda^n e^{-\lambda t}\frac{(\lambda t)^{n-1}}{\Gamma(n)}\] <p>然后我们把他一般化一下，得到 continuous-time Markov chain。其实核心也就是 “Memoryless”。</p> <p>只不过这次的转移矩阵是一个关于时间的函数了：</p> \[P_{i, j}(t) = \mathbb{P}(Z_{s + t} = j\mid Z_s = i)\] <p>而显然 \(P(0)=I\)。</p> <p>很显然的性质是：</p> \[P(s + t) = P(s)P(t) = P(t)P(s)\] <p>学习 Poisson process，我们来研究类似 \(\lambda\) 的一个跟“平均”有关的东西，我们考虑：</p> \[Q = \lim_{t\to 0^+}\frac{1}{t}\left(P(t) - P(0)\right) = \left.\frac{\partial}{\partial t}P(t)\right|_{t=0}\] <p>而其实我们有（这个叫“backward Kolmogorov equation”）：</p> \[\begin{aligned} \frac{\partial}{\partial t}P(t) &amp;= \lim_{h\to 0^+}\frac{1}{h}\left(P(t+h) - P(t)\right)\\ &amp;= \lim_{h\to 0^+}\frac{1}{h}\left(P(h)P(t) - P(t)\right)\\ &amp;= \lim_{h\to 0^+}\frac{1}{h}\left(P(h) - I\right)P(t)\\ &amp;= QP(t) \end{aligned}\] <p>当然同理我们还可以得到（这个叫“forward Kolmogorov equation”）：</p> \[\frac{\partial}{\partial t}P(t) = P(t)Q\] <p>解这个微分方程我们有：</p> \[P(t) = e^{Qt} = \sum_{n=0}^\infty\frac{t^n}{n!}Q^n = I + \sum_{n=1}^\infty\frac{t^n}{n!}Q^n\] <p>我们记 \(\lambda_{i,j} = Q_{i,j}\)，其实这个 \(\lambda_{i,j}\) 就和 Poisson process 那个一样了：</p> \[P(h) = I + hQ + \mathcal{O}(h)\] <p>另外还有一个性质是：</p> \[\sum_{j\in\mathbb{S}}\lambda_{i,j} = 0\] <h2 id="discrete-time-martingales">Discrete-Time Martingales</h2> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"pufanyi/pufanyi.github.io","data-repo-id":"R_kgDOJnYv-A","data-category":"General","data-category-id":"DIC_kwDOJnYv-M4CW4n7","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Fanyi Pu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: November 29, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?b09662effa0739abf36e63d5ddf8979a"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?eaf77346e117baa09987a278a117b9a7"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?8d7ebe8276cfa922ec1506a5c6b20c13"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"* means equal contribution",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-oi-blog",title:"oi-blog",description:"",section:"Navigation",handler:()=>{window.location.href="/oi-blog/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/assets/pdf/resume/resume.pdf"}},{id:"post-stochastic-processes-and-reinforcement-learning",title:"Stochastic Processes and Reinforcement Learning",description:"Notes for NTU MH3512 Stochastic Processes",section:"Posts",handler:()=>{window.location.href="/blog/SPRL/"}},{id:"post-machine-learning",title:"Machine Learning",description:"Notes for UC Berkeley CS 189 Machine Learning",section:"Posts",handler:()=>{window.location.href="/blog/Berkeley-CS189/"}},{id:"post-game-theory",title:"Game Theory",description:"Notes for UC Berkeley STAT 155 Game Theory + NTU MH4320 Computational Economics",section:"Posts",handler:()=>{window.location.href="/blog/Berkeley-STAT155/"}},{id:"post-uc-berkeley-cs-161-computer-security",title:"UC Berkeley CS 161 Computer Security",description:"Notes for UC Berkeley CS 161 Computer Security",section:"Posts",handler:()=>{window.location.href="/blog/Berkeley-CS161/"}},{id:"post-2021-zhejiang-gao-kao",title:"2021 Zhejiang Gao Kao",description:"\u660e\u5929\u5c31\u8981\u9ad8\u8003\u53bb\u4e86\uff0c\u4eca\u5929\u4e34\u65f6\u62b1\u4e2a\u4f5b\u811a",section:"Posts",handler:()=>{window.location.href="/blog/GaoKao/"}},{id:"post-classical-mechanics",title:"Classical Mechanics",description:"\u5b66\u70b9\u597d\u73a9\u7684",section:"Posts",handler:()=>{window.location.href="/blog/ClassicalMechanics/"}},{id:"post-ntu-mh3700-numerical-analysis-i",title:"NTU MH3700 Numerical Analysis I",description:"Notes for NTU MH3700 Numerical Analysis I.",section:"Posts",handler:()=>{window.location.href="/blog/MH3700-Notes/"}},{id:"post-maxwell-39-s-equations",title:"Maxwell&#39;s Equations",description:"\u5b66\u4e0d\u5b8c\u4e86\u5b66\u4e0d\u5b8c\u4e86\u5b66\u4e0d\u5b8c\u4e86\u554a\u554a\u554a\u554a\u554a\u554a\u554a\u554a\u554a\u554a\u554a",section:"Posts",handler:()=>{window.location.href="/blog/Maxwell/"}},{id:"post-lmms-eval-command-generator",title:"LMMs Eval Command Generator",description:"a simple tool to generate commands for LMMs-Eval",section:"Posts",handler:()=>{window.location.href="/blog/LMMs-Eval-Cmd/"}},{id:"post-statistics-notes",title:"Statistics Notes",description:"Notes for NTU MH3500 Statistics.",section:"Posts",handler:()=>{window.location.href="/blog/MH3500-Notes/"}},{id:"post-ucb-eecs-70-discrete-mathematics-and-probability-theory",title:"UCB EECS 70 Discrete Mathematics and Probability Theory",description:"My answer for the UCB EECS 70 Discrete Mathematics and Probability Theory course.",section:"Posts",handler:()=>{window.location.href="/blog/UCBCS70/"}},{id:"post-hello-world",title:"Hello World!",description:"the first post on this blog",section:"Posts",handler:()=>{window.location.href="/blog/HelloWorld/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%46%50%55%30%30%31@%65.%6E%74%75.%65%64%75.%73%67","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=58tv6skAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/pufanyi","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/pufanyi","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>