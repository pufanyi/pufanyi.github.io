<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="EPlMR3j8io1DcEScvNJuBPxLxCTSnNUjNwF4ZBhRO-I"> <meta name="msvalidate.01" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Game Theory | Fanyi Pu </title> <meta name="author" content="Fanyi Pu"> <meta name="description" content="Notes for UC Berkeley STAT 155 Game Theory + NTU MH4320 Computational Economics"> <meta name="keywords" content="Fanyi, Fanyi Pu, 濮凡轶"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/avatar_very_small.webp?3828c08bd9576f9a024f464411e622b9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pufanyi.github.io/blog/Berkeley-STAT155/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Fanyi</span> Pu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/oi-blog/">oi-blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/resume/resume.pdf">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Game Theory</h1> <p class="post-meta"> Created in June 18, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/game-theory"> <i class="fa-solid fa-hashtag fa-sm"></i> Game Theory</a>   ·   <a href="/blog/category/notes"> <i class="fa-solid fa-tag fa-sm"></i> Notes</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <ul> <li> <a href="https://classes.berkeley.edu/content/2024-summer-stat-155-001-lec-001" rel="external nofollow noopener" target="_blank">STAT 155 Game Theory</a> <ul> <li><a href="https://mitpress.mit.edu/9780262650403/a-course-in-game-theory/" rel="external nofollow noopener" target="_blank">Textbook 1</a></li> <li><a href="https://mitpress.mit.edu/9780262061414/game-theory/" rel="external nofollow noopener" target="_blank">Textbook 2</a></li> <li><a href="https://doi.org/10.2307/j.ctvjsf522" rel="external nofollow noopener" target="_blank">Textbook 3</a></li> </ul> </li> <li> <a href="https://www.ntu.edu.sg/docs/librariesprovider123/obtl/mas/updated-obtl/mh4320-spms-mas-outcomes-based-teaching-and-learning-document-(obtl)-5-jun-2023.pdf" rel="external nofollow noopener" target="_blank">MH4320 Computational Economics</a> <ul> <li><a href="https://www.cambridge.org/core/books/game-theory/B0C072F66E027614E46A5CAB26394C7D" rel="external nofollow noopener" target="_blank">Textbook</a></li> </ul> </li> </ul> <h2 id="preferences">Preferences</h2> <h3 id="一些基础定义和概念">一些基础定义和概念</h3> <p><strong>Consumption Space</strong>: \(X\subseteq\mathbb{R}_+^n\)</p> <p><strong>Preference Relation</strong>: \(x\succsim y\) or \(x\succeq y\), \(x\) is as lease as good as \(y\)</p> <p><strong>Indifference</strong>: \(x\sim y \Longleftrightarrow x\succsim y \land y\succsim x\)</p> <p><strong>Strict Preference</strong>: \(x\succ y \Longleftrightarrow x\succsim y \land x\nsim y\)</p> <h3 id="常见的-assumptions">常见的 Assumptions</h3> <p>Preference 这个概念挺大的，通常我们会带着一些 assumption 来研究。下面是一些常见的 assumption。</p> <p><strong>Rationality Assumption</strong>: completeness and transitivity。</p> <p>这样不会陷入死循环和一些矛盾的情况。</p> <p>反例：</p> <ol> <li>剪刀石头布：\(x\succ y\succ z\succ x\)，无法做出最优选择</li> <li>咖啡加糖：\(c_1\sim c_{0.9}\sim c_{0.8}\sim\cdots\sim c_{0.1}\sim c_0\)，但是\(c_1\nsim c_0\)。需要考虑一些心理的情况。</li> </ol> <p><em><strong>Convex Combination</strong></em>:</p> \[\alpha x+(1-\alpha)y, \alpha\in[0,1]\] <p><em><strong>Convex Set</strong></em>:</p> \[\forall x, y\in X\ ,\forall\alpha\in[0, 1], \alpha x+(1-\alpha)y\in X\] <p><em><strong>Convex Function</strong></em>:</p> \[f: X\to\mathbb{R}, \forall x, y\in X, \forall\alpha\in[0, 1], f(\alpha x+(1-\alpha)y)\le \alpha f(x)+(1-\alpha)f(y)\] <p>Convex 是笑脸，concave 是哭脸。</p> <p>高维空间比大小的一些记号：</p> \[\begin{aligned} x\ge y&amp;\Longleftrightarrow \forall i, x_i\ge y_i\\ x&gt;y&amp;\Longleftrightarrow x\ge y\land x\neq y\\ x\gg y&amp;\Longleftrightarrow \forall i, x_i&gt;y_i \end{aligned}\] <p><em><strong>Strongly Monotone</strong></em>:</p> \[x&gt;y\Longrightarrow f(x)&gt;f(y)\] <p><em><strong>Weakly Monotone</strong></em>:</p> \[x\gg y\Longrightarrow f(x)&gt; f(y)\] <p><strong>Locally Satisfied Preference</strong>:</p> \[\forall x\in X, \forall \epsilon&gt;0, \exists y, \lVert x-y\rVert&lt;\epsilon\land y\succsim x\] <p>旁边总有比他好的。</p> <p><strong>Weekly Monotone Preference</strong>:</p> \[x\gg y\Longrightarrow x\succ y\] <p>所有东西都来一点更好。</p> <p><strong>Strongly Monotone Preference</strong>:</p> \[x&gt;y\Longrightarrow x\succ y\] <p>越多越好。</p> <p><strong>Convex Preference</strong>:</p> \[x\succsim z, y\succsim z\Longrightarrow\forall\alpha\in[0, 1], \alpha x+(1-\alpha)y\succsim z\] <p><strong>Strictly Convex Preference</strong>:</p> \[x\succsim z, y\succsim z, y\neq x\Longrightarrow \forall\alpha\in(0, 1), \alpha x+(1-\alpha)y\succ z\] <p>我们称 \(f\) 是 quasi-concave 的当且仅当</p> \[f(\lambda x+(1-\lambda)y)\le\max\{f(x), f(y)\}\] <p><strong>Continuous Preference</strong>:</p> \[\forall n\in\mathbb{N}, x_n\succsim y_n, x_n\to x, y_n\to y\Longrightarrow x\succsim y\] <h2 id="utility-functions">Utility Functions</h2> <p>我们定义一个 \(u: X\to \mathbb{R}\) 使得</p> \[u(x)\ge u(y)\Longleftrightarrow x\succsim y\] <p>我们说是 \(u\) represents \(\succsim\)。</p> <p>这个 \(u\) 就是 \(\succsim\) 的 utility functions。</p> <p>一个定理是 \(\succsim\) 是 rational and continuous 的当且仅当存在一个连续的 \(u\)。</p> <ul> <li>\(\succsim\) is monotone \(\Longleftrightarrow\) \(u\) is monotone</li> <li>\(\succsim\) is convex \(\Longleftrightarrow\) \(u\) is quasi-concave</li> </ul> <p>当然很显然地：</p> \[\begin{cases} x\sim y\Longleftrightarrow u(x)=u(y)\\ x\succ y\Longleftrightarrow u(x)&gt;u(y) \end{cases}\] <h2 id="marginal-utility">Marginal Utility</h2> \[\mathrm{MU}(x)=\frac{\partial u(x)}{\partial x}\] <p>一般比如说对钱，我们会有 \(\mathrm{MU}(x)\) 是递减的。给的越多，多一块的价值越小。也就是 \(u''(x)&lt;0\)。</p> <h2 id="decision-making-under-uncertainty">Decision Making Under Uncertainty</h2> <h3 id="lotteries">Lotteries</h3> <p>在有 uncertainty 的情况下，用户做的决策是 lotteries，而不是确定的 goods。</p> <p>A lottery is a vector \(L = (x_1, p_1; x_2, p_2; \cdots; x_n, p_n)\). \(x_i\) 是 realization，\(p_i\) 是 probability。</p> <p>对于某个 realization，我们有其 utility \(u(x_i)\)，然后我们定义整个 lottery 的 utility 为 \(U(L) = \mathbb{E}[u(L)]\) (Von-Neumann Morgenstern Utility Function)。</p> <p>很多时候我们会对 lotteries 做线性叠加，比如一些钱买定期，一些钱买股票。所以其实我们就是在一个 convex set 上做决策。</p> <p>这时候问题就简化为我们有 \(n\) 个 realizations \(X = \{x_1, x_2, \cdots, x_n\}\)，将这 \(n\) 个 realizations 做线性组合，我们将这个 simplex 定义为 \(\mathbb{L}(X)\)，也就是：</p> \[\mathbb{L}(X) = \left\{(x_1, p_1; x_2, p_2; \cdots; x_n, p_n): p_i\ge 0, \sum_{i=1}^n p_i = 1\right\}\] <p>我们同样可以在 \(\mathbb{L}(X)\) 上定义 \(\succsim\)，而 \(\succsim\) 需要满足如下公理：</p> <ul> <li>Completeness: \(\forall L_1, L_2\in\mathbb{L}(X), L_1\succsim L_2\lor L_2\succsim L_1\)</li> <li>Transitivity: \(L_1\succsim L_2, L_2\succsim L_3\Longrightarrow L_1\succsim L_3\)</li> <li>Continuity: \(L_1\succsim L_2\succsim L_3\Longrightarrow \exists\alpha\in[0, 1], L_2\sim \alpha L_1+(1-\alpha)L_3\)</li> <li>Independence: \(L_1\succsim L_2\Longrightarrow \forall \alpha\in[0, 1], \alpha L_1+(1-\alpha)L_3\succsim \alpha L_2+(1-\alpha)L_3\)</li> </ul> <p><strong>Von Neumann–Morgenstern utility theorem</strong>: 上面四条同时 hold，等价于存在一个 \(u\)，并且任何可行的 \(u'\) 都可以通过一个 affine transformation 得到：\(u' = a+bu, b&gt;0\)。</p> <h3 id="st-petersburg-paradox">St. Petersburg paradox</h3> <p>这个是用来展示为什么必须要用 \(\mathbb{E}[u(L)]\) 而不是直接 \(\mathbb{E}[L]\) 的例子。</p> <p>假设有一个游戏，需要 1000 块钱。游戏是给你一个硬币你去抛，如果正面就给你一块钱继续抛，第二次正面两块钱，第三次四块钱，第 \(n\) 次 \(2^{n-1}\) 块钱，直到你抛到反面结束。</p> <p>这个游戏是铁不会玩的，因为你回本概率挺低的。但是</p> \[\mathbb{E}[L] = \sum_{n=1}^\infty\frac{1}{2^n}\times 2^{n-1} = \infty\] <p>这也显示了人们对赌钱是 risk averse 的。</p> <h3 id="risk-aversion">Risk Aversion</h3> <p>对于一个通过 \(u\) 来进行选择的 agent，我们判断他是否喜欢 take risks：</p> <ul> <li>Risk Averse: \(u(\mathbb{E}[L])\ge \mathbb{E}[u(L)]\)</li> <li>Risk Neutral: \(u(\mathbb{E}[L]) = \mathbb{E}[u(L)]\)</li> <li>Risk Loving: \(u(\mathbb{E}[L])\le \mathbb{E}[u(L)]\)</li> </ul> <p>用 Jensen’s inequality 很好判断: For a convex function \(f\), we have \(f(\mathbb{E}[X])\le \mathbb{E}[f(X)]\).</p> <p>对于一个 Risk Averse 的 agent，会有一个 \(\mathrm{CE}\) 来表示他愿意用这么多钱来换取一个稳定的状态：</p> \[u(\mathbb{E}[L]-\mathrm{CE}) = \mathbb{E}[u(L)]\] <p>我们考虑把一个 agent 的对 risk 的态度量化地表示，我们考虑 \(-u''(x)\) 的正负是个很好的指标。但如果 \(v=a+bu\)，那么 \(-v''(x)\neq -u''(x)\)，所以我们考虑：</p> \[R_A(x)=-\frac{u''(x)}{u'(x)}\] <p>我们将其称作 Arrow-Pratt Absolute Risk Aversion Coefficient，越大越 risk averse。</p> <p>但是有时候钱越多我们就会越极端，所以我们考虑定义 Relative Risk Aversion：</p> \[R_R(x)=-x\cdot\frac{u''(x)}{u'(x)}\] <h3 id="allais-paradox">Allais Paradox</h3> <p>考虑四个 lotteries：</p> <ul> <li>Lottery A: \(\left(\$10^6, 11\%; \$0, 89\%\right)\)</li> <li>Lottery B: \(\left(\$5\times 10^6, 10\%; \$0, 90\%\right)\)</li> <li>Lottery C: \(\left(\$10^6, 100\%\right)\)</li> <li>Lottery D: \(\left(\$5\times 10^6, 10\%; \$10^6, 89\%, \$0, 1\%\right)\)</li> </ul> <p>A 比 B，C 比 D。几乎大部分人会更喜欢 B 和 C。（虽然其实我上课的时候选了 B 和 D 呃呃呃）</p> <p>我们令 \(u(x)\) 表示获得 \(x\times 10^6\) 块钱，于是我们有：</p> \[\begin{cases} u(1)\times 0.11 &lt; u(5)\times 0.1\\ u(1)&gt;u(5)\times 0.1+u(1)\times 0.89 \end{cases}\] <p>而下面一个式子化简一下能得到：</p> \[u(1)\times 0.11 &gt; u(5)\times 0.1\] <p>两个式子是矛盾的。</p> <p>这让我们意识到其实在人真正考虑概率的时候，将“小概率发生”和“完全不发生”是分的很明确的。因为上面那个例子很多人时看到 D 项中有 \(1\%\) 的概率拿不到钱而去选 C 项。解决方法是我们对概率需要加一个修正函数 \(\pi(p)\)，使得我们的 utility function 变为 \(u(x)\times\pi(p)\)。这个 \(\pi\) 函数在 \(p=0\) 的时候会有一个陡增。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-06-18-Berkeley-STAT155/allais_paradox_pi-480.webp 480w,/assets/img/2024-06-18-Berkeley-STAT155/allais_paradox_pi-800.webp 800w,/assets/img/2024-06-18-Berkeley-STAT155/allais_paradox_pi-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-06-18-Berkeley-STAT155/allais_paradox_pi.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="ambiguity-aversion">Ambiguity Aversion</h3> <p>另一个叫 Ellsberg Paradox 的悖论，我们考虑现在有两个盒子，每个盒子有 100 个红球或黑球。第一个盒子有 50 红 50 黑，第二个盒子啥也不知道。</p> <p>有四个选项：</p> <ul> <li>A: 从第一个盒子里随机抽一个球，如果是红球，拿 100 块钱，否则拿 0 块钱</li> <li>B: 从第一个盒子里随机抽一个球，如果是黑球，拿 100 块钱，否则拿 0 块钱</li> <li>C: 从第二个盒子里随机抽一个球，如果是红球，拿 100 块钱，否则拿 0 块钱</li> <li>D: 从第二个盒子里随机抽一个球，如果是黑球，拿 100 块钱，否则拿 0 块钱</li> </ul> <p>很显然 \(A\sim B, C\sim D\)。尽管 A 和 B 加起来和 C 和 D 加起来是一样的，但大部分人会认为 \(A\succ C, B\succ D\)。</p> <p>这是因为人们不喜欢不确定性，也就是 ambiguity aversion。</p> <h2 id="definition-of-a-game">Definition of a Game</h2> <h3 id="actions-and-preferences">Actions and Preferences</h3> <p>接下来正是讨论 Game Theory 了。</p> <p>之前我们考虑的都是一个人的选择，现在是多人的决策问题，也就是说我们要考虑别人的操作。</p> <p>有 \(N\) 个 agents，每个 agent 有一个 action set</p> \[\mathcal{S}_i = \{s_{1}^i, s_{2}^i, \cdots, s_{N_i}^i\}\] <p>当然后面好像也有很多是写成 \(\mathcal{A}_i\) 的，反正看得懂就行。</p> <p>A strategic game consists of</p> <ul> <li>The players \(\mathcal{N} = \{1, 2, \cdots, N\}\)</li> <li>Actions: \(\mathcal{A}=\mathcal{A_1}\times\cdots\times\mathcal{A}_N\)</li> <li>Preferences: \(\succsim_i\) for each player \(i\)</li> <li>Outcomes</li> </ul> <h3 id="information-sets-and-strategies">Information Sets and Strategies</h3> <p>The set of possible strategy profiles is</p> \[\mathcal{S} = \mathcal{S}_1\times \mathcal{S}_2\times\cdots\times \mathcal{S}_N\] <p>对于一个游戏，在玩的过程中，每个人都会有一个 information \(H\)，对于第 \(i\) 个人所有可能的 information 集合我们记作 information sets \(\mathscr{H}_i\)。玩家只能看到 \(H\) 以内的东西，其他的（比如 \(H\) 以外别人的决策）他是看不见的。</p> <p>对于第 \(i\) 个玩家，假设现在有 information \(H\in\mathscr{H}_i\)，那么定义他可行的方案 \(\mathcal{C}_i(H)\subseteq\mathcal{A}_i\)（对于每个 \(H\) 可行方案肯定是一样的，否则他就有更多 information 了），然后我们定义他的 strategy 为 \(s_i: \mathscr{H}_i\to\mathcal{A}_i\) 并且 \(s_i(H)\in\mathcal{C}_i(H)\)。</p> <p>最终综合每个人的选择，我们有一个 strategy profile:</p> \[s = (s_1, s_2, \cdots, s_N)\in \mathcal{S}\] <p>而很多时候我们会关注某个 player \(i\) 的 strategy，我们一般会将 strategy profile 写作 \((s_i, s_{-i})\)，其中 \(s_{-i}\) 是除了 \(i\) 以外的其他人的 strategy。</p> <h3 id="payoff-functions">Payoff Functions</h3> <p>对于一个游戏，第 \(i\) 个人选了决策 \(s_i\)，我们有 \(s=(s_1, s_2, \cdots, s_N)\in\mathcal{S}\)。</p> <p>这样子我们可以定义第 \(i\) 个人的 utility function 为 \(u_i(s)\)，我们也叫做 payoff function。</p> <p>两个人的时候我们通常写成表格的形式：</p> <table> <thead> <tr> <th> </th> <th>Rock</th> <th>Paper</th> <th>Scissors</th> </tr> </thead> <tbody> <tr> <td><strong>Rock</strong></td> <td>\((0, 0)\)</td> <td>\((-1, 1)\)</td> <td>\((1, -1)\)</td> </tr> <tr> <td><strong>Paper</strong></td> <td>\((1, -1)\)</td> <td>\((0, 0)\)</td> <td>\((-1, 1)\)</td> </tr> <tr> <td><strong>Scissors</strong></td> <td>\((-1, 1)\)</td> <td>\((1, -1)\)</td> <td>\((0, 0)\)</td> </tr> </tbody> </table> <h3 id="strategy-form">Strategy Form</h3> <p>我们定义一个 \(\mathcal{I}\) 个人的 simple game 的 strategy / normal form 为：</p> \[\Gamma = \left&lt;\mathcal{I}, \left\{S_i\right\}, \left\{u_i(\cdot)\right\}\right&gt;\] <h3 id="pure-strategies-and-mixed-strategies">Pure Strategies and Mixed Strategies</h3> <p>Pure strategy 指的是一个人只能选一个 action，而 mixed strategy 指的是一个人可以通过概率分布选多个 actions。</p> <p>假设 \(P_1\) 选的概率为 \(\boldsymbol{p}\)，\(P_2\) 选的为 \(\boldsymbol{q}\)。\(P_1\) 的 payoff 为 \(M\)，那么我们有 \(P_1\) 的 expected payoff：</p> \[U_1(\boldsymbol{p}, \boldsymbol{q}) = \sum_{i\in\mathcal{I}}\sum_{j\in\mathcal{J}}M^{(1)}_{ij}p_iq_j=p^{\top}M_1q\] <p>对于每个人策略一定在一个 simplex 上，我们定义其为 \(\Delta(\mathcal{I})\) 和 \(\Delta(\mathcal{J})\)。</p> <h2 id="zero-sum-games">Zero-Sum Games</h2> <p>最先讨论的是零和博弈。也就是</p> \[\forall s\in \mathcal{S}, \sum_{i=1}^N u_i(s) = 0\] <p>你要获利的唯一方法是让别人变差。</p> <p>对于双人的，我们可以在表中只写第一个人的 payoff：</p> <table> <thead> <tr> <th> </th> <th>Rock</th> <th>Paper</th> <th>Scissors</th> </tr> </thead> <tbody> <tr> <td><strong>Rock</strong></td> <td>\(0\)</td> <td>\(-1\)</td> <td>\(1\)</td> </tr> <tr> <td><strong>Paper</strong></td> <td>\(1\)</td> <td>\(0\)</td> <td>\(-1\)</td> </tr> <tr> <td><strong>Scissors</strong></td> <td>\(-1\)</td> <td>\(1\)</td> <td>\(0\)</td> </tr> </tbody> </table> <p>这样子也就是 \(P_1\) 要最大化 \(P_2\) 要最小化。</p> <p>如果一个游戏不是零和的，我们可以加一个人，让</p> \[u_{N+1}(a_1, a_2, \cdots, a_N) = -\sum_{i=1}^N u_i(a_1, a_2, \cdots, a_N)\] <p>这样子就变成了零和博弈。</p> <h3 id="security-level">Security Level</h3> <p>\(\underline{v}\): \(P_1\) 先来，然后他考虑 \(P_2\) 的最优策略。</p> <p>对于 pure strategies：</p> \[\underline{v} = \max_{s_1\in\mathcal{S}_1}\min_{s_2\in\mathcal{S}_2}u_1(s_1, s_2)\] <p>对于 mixed strategies：</p> \[\underline{v} = \max_{\boldsymbol{p}\in\Delta(\mathcal{I})}\min_{\boldsymbol{q}\in\Delta(\mathcal{J})}p^{\top}Mq\] <p>\(\overline{v}\): \(P_2\) 先来，然后他考虑 \(P_1\) 的最优策略。</p> <p>对于 pure strategies：</p> \[\overline{v} = \min_{s_2\in\mathcal{S}_2}\max_{s_1\in\mathcal{S}_1}u_2(s_1, s_2)\] <p>对于 mixed strategies：</p> \[\overline{v} = \min_{\boldsymbol{q}\in\Delta(\mathcal{J})}\max_{\boldsymbol{p}\in\Delta(\mathcal{I})}p^{\top}Mq\] <p>很显然后手肯定是占优的，因为他知道先手的信息，所以</p> \[\underline{v}\le \overline{v}\] <p>如果 \(\underline{v} = \overline{v}\)，我们定义 \(v=\underline{v}=\overline{v}\) 为 the value of the game。</p> <h3 id="maxmin-and-minmax-strategies">Maxmin and Minmax Strategies</h3> <p>对于 maxmin 和 minmax，我们考虑的是假设我们告诉对手我们的策略（包含概率），对手选择最优 pure strategy。对于一个 \(n\times m\) 的矩阵 \(U\)：</p> \[\begin{aligned} \max\min(U)&amp;=\max_{\boldsymbol{p}\in\Delta[n]}\min_{y\in[m]}\sum_{i\in\mathcal{n}}p_i\cdot U_{i, y}\\ \min\max(U)&amp;=\min_{\boldsymbol{q}\in\Delta[m]}\max_{x\in[n]}\sum_{j\in\mathcal{m}}q_j\cdot U_{x, j} \end{aligned}\] <p>Von Neumann’s Minimax Theorem: 对于零和博弈</p> \[\max\min(U) = \min\max(U)\] <h2 id="dominant-strategies">Dominant Strategies</h2> <h3 id="strictly-dominant-strategies">Strictly Dominant Strategies</h3> <p>对于一个 player，如果不管对方怎么做决策，他做某个决策一定是最优的，那这个决策就是 strictly dominant 的。</p> <p>A strategy \(s_i\in \mathcal{S}_i\) is strictly dominant for player \(i\) if</p> \[\forall s_{-i}\in\mathcal{S}_{-i}, \forall s_i'\in\mathcal{S}_i, u_i(s_i, s_{-i})&gt;u_i(s_i', s_{-i})\] <h3 id="strictly-dominated-strategies">Strictly Dominated Strategies</h3> <p>我们说一个 strategy 是 strictly dominated 的，如果存在另一个 strategy 使得不管对方怎么做，这个 strategy 都比他好。换句话说，就是这个 strategy 一定不会被选。</p> <p>A strategy \(s_i\in \mathcal{S}_i\) is strictly dominated for player \(i\) if</p> \[\exists s_i'\in\mathcal{S}_i, \forall s_{-i}\in\mathcal{S}_{-i}, u_i(s_i', s_{-i})&gt;u_i(s_i, s_{-i})\] <h3 id="weakly-dominated-strategies">Weakly Dominated Strategies</h3> <p>A strategy \(s_i\in \mathcal{S}_i\) is weakly dominated for player \(i\) if</p> \[\exists s_i'\in\mathcal{S}_i, \forall s_{-i}\in\mathcal{S}_{-i}, u_i(s_i', s_{-i})\ge u_i(s_i, s_{-i})\] <h3 id="iterated-elimination-of-strictly-dominated-strategies">Iterated Elimination of Strictly Dominated Strategies</h3> <p>Strictly dominated strategies 一定不会被选，所以我们可以直接把这个策略去掉。然后我们就可以不断找每个人的 strictly dominated strategies，然后去掉来简化游戏。</p> <p>不能用 weekly dominated strategies，因为这些策略还是有可能会被选的。</p> <h3 id="strictly-dominated-strategies-in-mixed-strategies">Strictly Dominated Strategies in Mixed Strategies</h3> <p>有时候尽管 pure strategy 不存在 strictly dominated strategies，考虑 mixed strategies 时可能会存在。</p> <p>比如说</p> <table> <thead> <tr> <th> </th> <th>L</th> <th>R</th> </tr> </thead> <tbody> <tr> <td><strong>U</strong></td> <td>\((10, 1)\)</td> <td>\((0, 0)\)</td> </tr> <tr> <td><strong>M</strong></td> <td>\((4, 2)\)</td> <td>\((4, 1)\)</td> </tr> <tr> <td><strong>D</strong></td> <td>\((0, 5)\)</td> <td>\((10, 2)\)</td> </tr> </tbody> </table> <p>这玩意儿 \(M\) 是被 strictly dominated by \(\frac{1}{2}U+\frac{1}{2}D\) 的。</p> <p>我们说一个 mixed strategy \(\sigma_i\) 是 strictly dominated 的，当且仅当存在 \(\sigma_i'\) 使得</p> \[\forall\sigma_{-i}, u_i(\sigma_i', \sigma_{-i})&gt;u_i(\sigma_i, \sigma_{-i})\] <p>移项然后展开：</p> \[u_i(\sigma_i', \sigma_{-i})-u_i(\sigma_i, \sigma_{-i})=\sum_{-i\in s_{-i}}\left[\prod_{k\neq i}\sigma_{k}(s_k)\right]\left[u_i(\sigma'_i, s_{-i})-u_i(\sigma_i, s_{-i})\right]&gt;0\] <p>我们考虑这个式子，如果所有的 \(u_i(\sigma'_i, s_{-i})-u_i(\sigma_i, s_{-i})&gt;0\) 的话，很显然整个式子是正的，如果其中有一个小于 \(0\)，我们就让这一项前面的 \(\sigma_k(s_k)=1\)，其他都变成 \(0\)，这样整个式子就小于 \(0\) 了。</p> <p>于是乎对于一个 \(\sigma_i\)，我们只要 check 所有的 pure strategies 就可以。</p> <h2 id="knowledge">Knowledge</h2> <p><strong>Mutual Knowledge</strong>: 如果大家都知道某个 knowledge，那么这个 knowledge 是 mutual knowledge。</p> <p><strong>Common Knowledge</strong>: 如果任意一个 player 序列 \(i_1, i_2, \cdots, i_k\)，我们有 \(i_1\) 知道 \(i_2\) 知道 \(\cdots\) 知道 \(i_k\) 知道某个 knowledge，那么我们说这个 knowledge 是 common knowledge。</p> <p>很显然 common knowledge 是 mutual knowledge。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-06-18-Berkeley-STAT155/common_knowledge-480.webp 480w,/assets/img/2024-06-18-Berkeley-STAT155/common_knowledge-800.webp 800w,/assets/img/2024-06-18-Berkeley-STAT155/common_knowledge-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-06-18-Berkeley-STAT155/common_knowledge.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>假设人从左到右是 \(A, B, C\)，\(A\) 不知道 \(A\) 的帽子颜色。我们现在假定 player 序列是 \(A, B, C\)。对于 \(A\) 来说，假设 \(A\) 的帽子颜色是红的，那么 \(B\) 就能看到俩红，那他就能知道 \(C\) 肯定能看到至少一红。但是如果 \(A\) 的帽子不是红色的，那么 \(B\) 只能看到一红，他就不能确定 \(C\) 是否能看到红色了。这导致了这道题不是 common knowledge。</p> <h2 id="nash-equilibrium">Nash Equilibrium</h2> <h3 id="best-response">Best Response</h3> <p>We say that a strategy \(\sigma_i\) is a best response to \(\sigma_{-i}\) if</p> \[\forall\sigma'_i\in\Delta(\mathcal{S}_i), u_i(\sigma_i, \sigma_{-i})\ge u_i(\sigma'_i, \sigma_{-i})\] <p><strong><em>Best response correspondence</em></strong>:</p> \[b_i(\sigma_{-i})=\left\{\sigma_i\in\Delta(\mathcal{S}_i): \forall \sigma_i'\in\Delta(\mathcal{S}_i), u_i(\sigma_i, \sigma_{-i})\ge u_i(\sigma_i', \sigma_{-i})\right\}\] <h3 id="nash-equilibrium-in-pure-strategies">Nash Equilibrium in Pure Strategies</h3> <p>每个人都是 best response 的策略。</p> <p>A strategy profile \(s=(s_1, \cdots, s_\mathcal{I})\) constitutes a Nash equilibrium of a game \(\Gamma=\left[\mathcal{I}, \left\{S_i\right\}, \left\{u_i(\cdot)\right\}\right]\) if for every \(i=1, \cdots, \mathcal{I}\),</p> \[u_i(s_i, s_{-i})\ge u_i(s_i', s_{-i})\] <p>for all \(s_i'\in S_i\).</p> <h3 id="nash-equilibrium-in-mixed-strategies">Nash Equilibrium in Mixed Strategies</h3> <p>和 pure strategies 的定义是一样的，对于游戏 \(\Gamma=\left[\mathcal{I}, \left\{\Delta(\mathcal{S}_i)\right\}, \left\{u_i(\cdot)\right\}\right]\), 我们有 \(\sigma = (\sigma_1, \cdots, \sigma_\mathcal{I})\) 是 Nash equilibrium if for every \(i=1, \cdots, \mathcal{I}\),</p> \[u_i(\sigma_i, \sigma_{-i})\ge u_i(\sigma_i', \sigma_{-i})\] <p>for all \(\sigma_i'\in\Delta(\mathcal{S}_i)\).</p> <p>其实也就是</p> \[\forall i, \sigma_i\in b_i(\sigma_{-i})\] <p>所以直觉上来讲其实就是这些 correspondence 的交集。</p> <p>比如说这个游戏：</p> <table> <thead> <tr> <th> </th> <th>Bach (\(\mathscr{B}_2\))</th> <th>Stravinsky (\(\mathscr{S}_2\))</th> </tr> </thead> <tbody> <tr> <td> <strong>Bach</strong> (\(\mathscr{B}_1\))</td> <td>\((10, 5)\)</td> <td>\((0, 0)\)</td> </tr> <tr> <td> <strong>Stravinsky</strong> (\(\mathscr{S}_1\))</td> <td>\((0, 0)\)</td> <td>\((5, 10)\)</td> </tr> </tbody> </table> <p>我们有对于 \(P_1\)：</p> \[\mathscr{B}_1\succsim\mathscr{S}_1\Longleftrightarrow p(\mathscr{B}_2)\ge\frac{1}{3}\] <p>同理，对称地对于 \(P_2\)：</p> \[\mathscr{B}_2\succsim\mathscr{S}_2\Longleftrightarrow p(\mathscr{B}_1)\ge\frac{2}{3}\] <p>画出图：</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-06-18-Berkeley-STAT155/nash_equilibrium_bach-480.webp 480w,/assets/img/2024-06-18-Berkeley-STAT155/nash_equilibrium_bach-800.webp 800w,/assets/img/2024-06-18-Berkeley-STAT155/nash_equilibrium_bach-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-06-18-Berkeley-STAT155/nash_equilibrium_bach.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>交点为 \((0, 0), \left(\frac{1}{3}, \frac{2}{3}\right), (1, 1)\)，所以这三个点是 Nash equilibrium。</p> <h3 id="checking-for-nash-equilibrium">Checking for Nash Equilibrium</h3> <p>我们考虑游戏 \(\Gamma=\left[\mathcal{I}, \left\{\Delta(\mathcal{S}_i)\right\}, \left\{u_i(\cdot)\right\}\right]\)。对于一个 \(\sigma=(\sigma_1, \cdots, \sigma_\mathcal{I})\)，我们定义 \(\mathcal{S}_i^+\subseteq\mathcal{S}_i\)：</p> \[\mathcal{S}_i^+=\left\{s_j\in\mathcal{S}_i: \sigma_{i,j}&gt;0\right\}\] <p>也就是这个人有可能执行这个操作。</p> <p>于是乎一个 \(\sigma\) 要满足他是 Nash equilibrium 当且仅当对于 \(i=1, \cdots, \mathcal{I}\)：</p> <ol> <li>\(u_i(s_i, \sigma_{-i})=u_i(s_i', \sigma_{-i})\) for all \(s_i, s_i'\in\mathcal{S}_i^+\)</li> <li>\(u_i(s_i, \sigma_{-i})\ge u_i(s_i', \sigma_{-i})\) for all \(s_i\in\mathcal{S}_i^+\) and \(s_i'\in\mathcal{S}_i\setminus\mathcal{S}_i^+\)</li> </ol> <p>大概就是，对于我来说，我知道别人有一个 mixed strategy，而我出的这个 mixed strategy 中的任何一种可能性都是一样优的（否则我就不要他了），而我不选的那几个操作一定不会更优（否则我肯定会增加它的概率）。如果对于每个人来说都是这样，那么就达到了一种均衡。</p> <h3 id="existence-of-nash-equilibrium">Existence of Nash Equilibrium</h3> <p>A Nash equilibrium exists in game \(\Gamma=\left[\mathcal{I}, \left\{\mathcal{S}_i\right\}, \left\{u_i(\cdot)\right\}\right]\) if for all \(i=1, \cdots, \mathcal{I}\):</p> <ol> <li>\(\mathcal{S}_i\) is a nonempty, convex, and compact subset of some Euclidean space \(\mathbb{R}^M\);</li> <li>\(u_i(s_1, \cdots, s_\mathcal{I})\) is continuous in \((s_1, \cdots, s_\mathcal{I})\) and quasi-concave in \(s_i\).</li> </ol> <p>考虑到当 \(\mathcal{S}\) 有限的时候，\(\Delta(\mathcal{S})\) 满足了 nonempty, convex, compact 三个条件，而且 \(u_i\) 也是 continuous 和 quasi-concave 的。所以我们说对于 mixed strategies game \(\Gamma=\left[\mathcal{I}, \left\{\Delta(\mathcal{S}_i)\right\}, \left\{u_i(\cdot)\right\}\right]\)，如果 \(\mathcal{S}_i\) 是有限的，那么 Nash equilibrium 一定存在。</p> <h3 id="correlated-equilibria">Correlated Equilibria</h3> <p>前面我们考虑 \(\sigma_i\) 都是独立的。但在现实生活中，一些信息是共享的，导致我们的策略是相关的。</p> <p>比如说红绿灯，大家会看到信号灯的信息来做出决策。</p> <p>这时候我们就要定义：</p> \[U_i(\sigma_1, \cdots, \sigma_\mathcal{I})=\sum_{s}\mathbb{P}[s_1, \cdots, s_\mathcal{I}]u_i(s_1, \cdots, s_\mathcal{I})\] <p>而这时候我们的 strategy 概率就应该是定义在 \(\mathcal{S}=S_1\times\cdots\times S_\mathcal{I}\) 上了，也就是描述 NE 需要考虑 joint distribution。</p> <h3 id="the-oddness-theorem">The Oddness Theorem</h3> <p>一个神奇的结论是在大部分情况下，一个游戏一定有奇数个 NE。</p> <p>严谨的说，拥有偶数个 NE 的游戏所构成的集合 Lebesgue measure 为 \(0\)。</p> <p>比如说有一个游戏：</p> <table> <thead> <tr> <th> </th> <th>L</th> <th>R</th> </tr> </thead> <tbody> <tr> <td><strong>U</strong></td> <td>\((a_1, a_2)\)</td> <td>\((b_1, b_2)\)</td> </tr> <tr> <td><strong>D</strong></td> <td>\((c_1, c_2)\)</td> <td>\((d_1, d_2)\)</td> </tr> </tbody> </table> <p>那么我们对于任意 \(\epsilon&gt;0\)，存在 \(0\le \epsilon_1, \cdots, \epsilon_8\le \epsilon\) 使得游戏：</p> <table> <thead> <tr> <th> </th> <th>L</th> <th>R</th> </tr> </thead> <tbody> <tr> <td><strong>U</strong></td> <td>\((a_1+\epsilon_1, a_2+\epsilon_2)\)</td> <td>\((b_1+\epsilon_3, b_2+\epsilon_4)\)</td> </tr> <tr> <td><strong>D</strong></td> <td>\((c_1+\epsilon_5, c_2+\epsilon_6)\)</td> <td>\((d_1+\epsilon_7, d_2+\epsilon_8)\)</td> </tr> </tbody> </table> <p>拥有奇数个 NE。</p> <p>证明没有详细地讲，只说了个大概的思路。主要是考虑一个 \(f: X\to X\) 的连续函数，不动点在大部分情况下有奇数个。除非与 \(y=x\) 相切或者端点在 \((x, x)\) 上，这种情况下稍稍移动一下函数就可以了。</p> <h2 id="welfare--optimality">Welfare / Optimality</h2> <p>很多时候我们需要知道什么是“好的”，因为有时候 Nash equilibrium 并不是最优的。</p> <h3 id="social-welfare">Social Welfare</h3> <p>最直观的方法是定义一个函数来表示整个社会的 welfare。我们定义 social welfare function 为</p> \[\mathcal{W}(x_1, \cdots, x_\mathcal{I})=\sum_{i=1}^\mathcal{I}\alpha_i u_i(x_i, x_{-i})\] <p>但这样做有两个很显然的问题：</p> <ol> <li>谁来定义 \(\alpha_i\)？</li> <li>是否所有人都能 accept 这个定义？</li> </ol> <p>所以我们下面引出 Pareto Optimality。</p> <h3 id="pareto-optimality">Pareto Optimality</h3> <p>假设我们有两个 agents 和两种物品进行分配，第一个物品有 \(A\) 个，第二个物品有 \(B\) 个。那么我们可以定义 allocation 为：</p> \[\left((x_1^a, x_2^a), (x_1^b, x_2^b)\right)\] <p>而物品的数量有限，所以：</p> \[\begin{cases} x_1^a+x_1^b=A\\ x_2^a+x_2^b=B \end{cases}\] <p>我们定义一个 Pareto Improvement \(\left((y_1^a, y_2^a), (y_1^b, y_2^b)\right)\) 满足：</p> \[\begin{bmatrix} u_a(y_1^a, y_2^a)\\ u_b(y_1^b, y_2^b) \end{bmatrix}&gt; \begin{bmatrix} u_a(x_1^a, x_2^a)\\ u_b(x_1^b, x_2^b) \end{bmatrix}\] <p>其中的 \(&gt;\) 指的是有一个大于其余大于等于。</p> <p>如果一个 allocation 没有 Pareto Improvement，那么我们称其为 Pareto Optimal。</p> <p>然而 Pareto Optimal 也不一定是 fair 的，但是他是 bare minimum，也就是说如果不是 Pareto Optimal，那么我们应该做出改进。</p> <p>上课提到了一个叫 laissez-fairez 的名词，其实就是自由放任。让市场自由调节来达到一个 Pareto Optimal 的状态。</p> <h3 id="mechanism--market-design">Mechanism / Market Design</h3> <p>另一种让社会达到最优状态的方法叫 mechanism design，也叫 reverse game theory。我们通过设计和修改游戏机制来打到社会的最优性。</p> <h2 id="rationalizable-strategies">Rationalizable Strategies</h2> <p>我们考虑一个游戏，如果对方做出某个选择，我们会做出相应的 best response。但是有些策略不管对方选了什么，我们都不可能作为 best response 去选择，我们把这种策略叫做 NBR（never best response）。</p> <p>那很显然 NBR 是可以忽略的，所以我们就重复在游戏中删除 NBR，直到没有 NBR 为止。</p> <p>最终剩下来的策略就是 rationalizable strategies。</p> <p>如果最终只剩了一个，那么我们说这个游戏是 dominance solvable 的。</p> <p>很显然 NE 肯定是 rationalizable 的，因为如果他不是 rationalizable，那肯定在某一次删除的时候被定义为 NBR 了，而那个 best response 肯定比这个好。</p> <p>但是 rationalizable 不一定是 NE 的，比如说 Matching Pennies：</p> <table> <thead> <tr> <th> </th> <th>Heads</th> <th>Tails</th> </tr> </thead> <tbody> <tr> <td><strong>Heads</strong></td> <td>\((1, -1)\)</td> <td>\((-1, 1)\)</td> </tr> <tr> <td><strong>Tails</strong></td> <td>\((-1, 1)\)</td> <td>\((1, -1)\)</td> </tr> </tbody> </table> <p>当然，NBR 也可能不是 strictly dominated by pure 的：</p> <table> <thead> <tr> <th> </th> <th>X</th> <th>Y</th> </tr> </thead> <tbody> <tr> <td><strong>A</strong></td> <td>\((2, 1)\)</td> <td>\((0, 0)\)</td> </tr> <tr> <td><strong>B</strong></td> <td>\((0, 1)\)</td> <td>\((2, 0)\)</td> </tr> <tr> <td><strong>C</strong></td> <td>\((1, 1)\)</td> <td>\((1, 2)\)</td> </tr> </tbody> </table> <p>尽管我们考虑 pure strategies，\(b_1(X)=\{A\}, b_1(Y)=\{B\}\)，\(C\) 是不会被选的。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-06-18-Berkeley-STAT155/rationalizable-480.webp 480w,/assets/img/2024-06-18-Berkeley-STAT155/rationalizable-800.webp 800w,/assets/img/2024-06-18-Berkeley-STAT155/rationalizable-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2024-06-18-Berkeley-STAT155/rationalizable.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="games-with-trembling-hands">Games with Trembling Hands</h2> <h3 id="trembling-hand-perfect-equilibrium">Trembling Hand Perfect Equilibrium</h3> <p>有时候我们做选择会手抖出错。也就其实是我们在选操作 \(i\) 的时候，我们其实选的是一个概率分布 \(\sigma_i\)。</p> <p>We say that a strategy profile \(\sigma\) is a trembling-hand perfect Nash Equilibrium if it can be approximated by a sequence of totally mixed strategy profiles for each player. 其中的 totally mixed 指的是所有概率都大于 \(0\)。也就是说，对于一个 pure strategy，稍稍扰动一下也是没有问题的。</p> <p>就比如下面这个例子：</p> <table> <thead> <tr> <th> </th> <th>U</th> <th>D</th> </tr> </thead> <tbody> <tr> <td><strong>U</strong></td> <td>\((1, 1)\)</td> <td>\((0, -3)\)</td> </tr> <tr> <td><strong>D</strong></td> <td>\((-3, 0)\)</td> <td>\((0, 0)\)</td> </tr> </tbody> </table> <p>\((D, D)\) 是 NE 但不是 THNE，因为如果稍微扰动一下，变成 \(((\epsilon_1, 1-\epsilon_1), (\epsilon_2, 1-\epsilon_2))\)，这时候是不如 \(((1-\epsilon_1, \epsilon_1), (\epsilon_2, 1-\epsilon_2))\) 的。也就是说，在有 trembling hand 的情况下，\(P_1\) 和 \(P_2\) 其实会考虑换到 \(U\)。</p> <h3 id="evolutionary-stable">Evolutionary Stable</h3> <p>当然根据这个定义，所有 totally mixed strategies 都是 THNE 的。但是我们可以沿用这个 idea 来定义和 “stability”。我们把一个 NE 扰动一下，如果还是 NE，那么我们就说这个 NE 是 stable 的。我们定义这个东西叫做 evolutionary stable。</p> <p>A mixed strategy profile \(\sigma^*\) is Evolutionary Stable if:</p> <ol> <li>\(u_i(\sigma_i^*, \sigma_{-i}^*)\ge u_i(\sigma_i, \sigma_{-i}^*)\) for all \(i\) and \(\sigma_i\in\Delta(\mathcal{S}_i)\)</li> <li>if \(u_i(\sigma_i^*, \sigma_{-i}^*)=u_i(\sigma_i, \sigma_{-i}^*)\), then \(u_i(\sigma_i^*, \sigma_{-i})&gt;u_i(\sigma_i, \sigma_{-i})\)</li> </ol> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"pufanyi/pufanyi.github.io","data-repo-id":"R_kgDOJnYv-A","data-category":"General","data-category-id":"DIC_kwDOJnYv-M4CW4n7","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Fanyi Pu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: September 14, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"* means equal contribution",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-oi-blog",title:"oi-blog",description:"",section:"Navigation",handler:()=>{window.location.href="/oi-blog/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/assets/pdf/resume/resume.pdf"}},{id:"post-berkeley-cs-189-machine-learning",title:"Berkeley CS 189 Machine Learning",description:"Notes for UC Berkeley CS 189 Machine Learning",section:"Posts",handler:()=>{window.location.href="/blog/Berkeley-CS189/"}},{id:"post-game-theory",title:"Game Theory",description:"Notes for UC Berkeley STAT 155 Game Theory + NTU MH4320 Computational Economics",section:"Posts",handler:()=>{window.location.href="/blog/Berkeley-STAT155/"}},{id:"post-uc-berkeley-cs-161-computer-security",title:"UC Berkeley CS 161 Computer Security",description:"Notes for UC Berkeley CS 161 Computer Security",section:"Posts",handler:()=>{window.location.href="/blog/Berkeley-CS161/"}},{id:"post-2021-zhejiang-gao-kao",title:"2021 Zhejiang Gao Kao",description:"\u660e\u5929\u5c31\u8981\u9ad8\u8003\u53bb\u4e86\uff0c\u4eca\u5929\u4e34\u65f6\u62b1\u4e2a\u4f5b\u811a",section:"Posts",handler:()=>{window.location.href="/blog/GaoKao/"}},{id:"post-classical-mechanics",title:"Classical Mechanics",description:"\u5b66\u70b9\u597d\u73a9\u7684",section:"Posts",handler:()=>{window.location.href="/blog/ClassicalMechanics/"}},{id:"post-ntu-mh3700-numerical-analysis-i",title:"NTU MH3700 Numerical Analysis I",description:"Notes for NTU MH3700 Numerical Analysis I.",section:"Posts",handler:()=>{window.location.href="/blog/MH3700-Notes/"}},{id:"post-maxwell-39-s-equations",title:"Maxwell&#39;s Equations",description:"\u5b66\u4e0d\u5b8c\u4e86\u5b66\u4e0d\u5b8c\u4e86\u5b66\u4e0d\u5b8c\u4e86\u554a\u554a\u554a\u554a\u554a\u554a\u554a\u554a\u554a\u554a\u554a",section:"Posts",handler:()=>{window.location.href="/blog/Maxwell/"}},{id:"post-lmms-eval-command-generator",title:"LMMs Eval Command Generator",description:"a simple tool to generate commands for LMMs-Eval",section:"Posts",handler:()=>{window.location.href="/blog/LMMs-Eval-Cmd/"}},{id:"post-ntu-mh3500-statistics",title:"NTU MH3500 Statistics",description:"Notes for NTU MH3500 Statistics.",section:"Posts",handler:()=>{window.location.href="/blog/MH3500-Notes/"}},{id:"post-ucb-eecs-70-discrete-mathematics-and-probability-theory",title:"UCB EECS 70 Discrete Mathematics and Probability Theory",description:"My answer for the UCB EECS 70 Discrete Mathematics and Probability Theory course.",section:"Posts",handler:()=>{window.location.href="/blog/UCBCS70/"}},{id:"post-hello-world",title:"Hello World!",description:"the first post on this blog",section:"Posts",handler:()=>{window.location.href="/blog/HelloWorld/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%46%50%55%30%30%31@%65.%6E%74%75.%65%64%75.%73%67","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=58tv6skAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/pufanyi","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/pufanyi","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>