<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://pufanyi.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://pufanyi.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-01T13:21:19+00:00</updated><id>https://pufanyi.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Machine Learning</title><link href="https://pufanyi.github.io/blog/Berkeley-CS189/" rel="alternate" type="text/html" title="Machine Learning"/><published>2025-04-01T00:00:00+00:00</published><updated>2025-04-01T00:00:00+00:00</updated><id>https://pufanyi.github.io/blog/Berkeley-CS189</id><content type="html" xml:base="https://pufanyi.github.io/blog/Berkeley-CS189/"><![CDATA[<h2 id="math-review">Math Review</h2> <p>All modern machine learning algorithms are just nearest neighbors. It’s only that the neural networks are telling you the space in which to compute the distance.</p> <h4 id="svd">SVD</h4> <p><a href="https://web.stanford.edu/class/cs168/l/l9.pdf">Notes</a></p> \[A = U \Sigma V^\top=\sum_{i=1}^{\min\{m, n\}}\sigma_i u_i v_i^\top\] <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-09-05-Berkeley-CS189/SVD-480.webp 480w,/assets/img/2024-09-05-Berkeley-CS189/SVD-800.webp 800w,/assets/img/2024-09-05-Berkeley-CS189/SVD-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2024-09-05-Berkeley-CS189/SVD.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Compute largest \(k\) singular values and vectors: \(\mathcal{O}(kmn)\).</p> <p>Approximation:</p> \[\hat{A} = \sum_{i=1}^{k}\sigma_i u_i v_i^\top = U_k \Sigma_k V_k^\top\] <p>For all rank \(k\) matrices \(B\):</p> \[\|A - \hat{A}\|_F \le \|A - B\|_F\] <h3 id="maximum-likelihood-estimation">Maximum Likelihood Estimation</h3> <p>Maximum likelihood estimation:</p> \[\hat{\theta} = \arg\max_{\theta\in\Theta} p(D\mid\theta)\] <p>Properties:</p> <ol> <li><em>Consistency</em>: more data, more accurate (but maybe biased).</li> <li><em>Statistically efficient</em>: least variance.</li> <li>The value of \(p(D\mid\theta_{\text{MLE})\) is invariant to re-parameterization.</li> </ol>]]></content><author><name></name></author><category term="Notes"/><category term="Machine Learning"/><category term="Artificial Intelligence"/><summary type="html"><![CDATA[Notes for Machine Learning]]></summary></entry><entry><title type="html">Parallel Computing and Distributed Systems</title><link href="https://pufanyi.github.io/blog/Parallel-Computing-and-Distributed-Systems/" rel="alternate" type="text/html" title="Parallel Computing and Distributed Systems"/><published>2025-03-30T00:00:00+00:00</published><updated>2025-03-30T00:00:00+00:00</updated><id>https://pufanyi.github.io/blog/Parallel-Computing-and-Distributed-Systems</id><content type="html" xml:base="https://pufanyi.github.io/blog/Parallel-Computing-and-Distributed-Systems/"><![CDATA[<h2 id="parallel-computing">Parallel Computing</h2> <p><a href="https://cs149.stanford.edu/">Stanford CS149</a></p> <h3 id="a-modern-multi-core-processor">A Modern Multi-Core Processor</h3> <p>Forms of Parallel Execution</p> <ol> <li>Superscalar: 找到不相关的语句然后并行执行</li> <li>SIMD：ALU 的并行，Single instruction, multiple data</li> <li>Multi-core：多个 core，所以想咋玩咋玩</li> </ol> <p>SIMD 遇到 branchs？一部分 ALU 需要等待</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-03-30-Parallel-Computing-and-Distributed-Systems/pc/simd_branch-480.webp 480w,/assets/img/2025-03-30-Parallel-Computing-and-Distributed-Systems/pc/simd_branch-800.webp 800w,/assets/img/2025-03-30-Parallel-Computing-and-Distributed-Systems/pc/simd_branch-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-03-30-Parallel-Computing-and-Distributed-Systems/pc/simd_branch.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Interleaved (temporal) multi-threading: 这个任务在 stall 了（比如在 fetch memory），先执行别的任务</p> <p>Overcoming bandwidth limits is often the most important challenge facing software developers targeting modern throughput-optimized systems.</p> <hr/> <h2 id="distributed-system">Distributed System</h2> <p><a href="https://pdos.csail.mit.edu/6.824/index.html">MIT 6.824</a></p> <p><a href="https://www.scs.stanford.edu/24sp-cs244b/">Stanford CS244B</a></p> <p>忽然发现 CS244B 的 instructor 是 <d-cite key="vamplew2016get"></d-cite> 的一作。</p> <h3 id="introduction">Introduction</h3> <p>You should try everything else before you try distributed systems.</p> <p>Why distributed systems?</p> <ul> <li>Parallelism</li> <li>Fault tolerance</li> <li>Physical</li> <li>Security (isolation)</li> </ul> <h3 id="remote-procedure-call-rpc">Remote Procedure Call (RPC)</h3> <p>需要比普通的 procedure 多一个 “I don’t know” 的选项。</p> <p>Interface Definition Languages (IDL): Specify RPC call and return types</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-03-30-Parallel-Computing-and-Distributed-Systems/ds/idl-480.webp 480w,/assets/img/2025-03-30-Parallel-Computing-and-Distributed-Systems/ds/idl-800.webp 800w,/assets/img/2025-03-30-Parallel-Computing-and-Distributed-Systems/ds/idl-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-03-30-Parallel-Computing-and-Distributed-Systems/ds/idl.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><a href="https://datatracker.ietf.org/doc/html/rfc4506">External Data Representation Standard (XDR)</a></p> <h3 id="consensus">Consensus</h3> <p>在讨论 asynchronous systems 的时候，我们会保守地认为网络是很慢的。也就是说，we can’t distinguish failed agent from slow network.</p> <p>有 \(n\) 个 agents，每个 agent input 一个数字，现在要各个 agent 通过互相交流达成一致，使得每个 agent 的 output 都相同，并且是其中一个 agent 的 input。</p> <p><strong>Safety</strong>: 所有 agent 的 output 都相同（agreement）并且 output 为其中某个 agent 的 input（validity）</p> <p><strong>Liveness</strong>: 所有 non-failed 的 agents 都有输出</p> <p><strong>Fault tolerance</strong>:</p> <ul> <li>Fail-stop: 如果 agent 出错，那么他会立即停止</li> <li>Byzantine-fault-tolerant <d-cite key="lamport2019byzantine"></d-cite>: agent 出错可能出现任意行为，比如发送假消息</li> </ul> <p><strong>FLP impossibility result</strong> <d-cite key="fischer1985impossibility"></d-cite>: No deterministic consensus protocol guarantees all three of safety, liveness, and fault tolerance in an asynchronous system.</p> <p><strong>Bivalent</strong>: An execution of a consensus protocol is in a bivalent state when the network can affect which value agents choose.</p> <p><strong>Univalent, Valent</strong>: An execution of a consensus protocol is in a univalent state when only one output value is possible. If that value is \(i\), call the state \(i\)-valent.</p> <p><strong>Stuck</strong>: An execution of a [broken] consensus protocol is in a stuck state when one or more non-faulty nodes can never output a value.</p>]]></content><author><name>Pu Fanyi</name></author><category term="Notes"/><category term="Parallel Computing"/><category term="Distributed System"/><summary type="html"><![CDATA[Notes for Parallel Computing and Distributed Systems]]></summary></entry><entry><title type="html">Stochastic Processes and Reinforcement Learning</title><link href="https://pufanyi.github.io/blog/SPRL/" rel="alternate" type="text/html" title="Stochastic Processes and Reinforcement Learning"/><published>2024-10-16T00:00:00+00:00</published><updated>2024-10-16T00:00:00+00:00</updated><id>https://pufanyi.github.io/blog/SPRL</id><content type="html" xml:base="https://pufanyi.github.io/blog/SPRL/"><![CDATA[<p>看我能坚持多久。。。</p> <h2 id="markov-chains">Markov Chains</h2> <p><a href="https://link.springer.com/book/10.1007/978-981-13-0659-4">教材捏</a></p> <p><a href="https://personal.ntu.edu.sg/ariel.neufeld/script_MH3512_Marked.pdf">划了重点的教材捏</a>（prof 划的，虽然我感觉他把整本书划了一遍。。。）</p> <h3 id="gambling-problems">Gambling Problems</h3> <p>有 \(S\) 块钱，\(A\) 有 \(K\) 块钱，\(B\) 有 \(S-K\) 块。每次有 \(p\) 的概率 \(A\) 从 \(B\) 拿走一块，\(q=1-p\) 的概率 \(B\) 从 \(A\) 拿走一块。谁拿到 \(S\) 块钱就算赢。</p> \[X_{n+1}=\begin{cases} X_n+1 &amp; p \\ X_n-1 &amp; q \end{cases}\] <p>\(f_S(k)\) 表示 \(A\) 赢的概率。很显然我们有：</p> \[f_S(k)=pf_{S}(k+1)+qf_{S}(k-1)\] <p>不难解出</p> \[f_S(k)=\frac{(p/q)^{S-k}-1}{(p/q)^S-1}\] <p>\(T_{0, S}\) 表示一个游戏啥时候结束，\(h_S(k)=\mathbb{E}\left[T_{0, S}\mid X_0=K\right]\)。</p> <p>很显然</p> \[h_S(k)=1+ph_S(k+1)+qh_S(k-1)\] <p>这个方程的特解比较难搞，注意到 \(p+q=1\)，我们可以改写成差分方程：</p> \[-1=p\left(h_S(k+1)-h_S(k)\right)+q\left(h_S(k)-h_S(k-1)\right)\] <p>观察出方程在 \(p\neq q\) 的时候一个特解为 \(\frac{k}{q-p}\)。</p> <p>不难解出齐次方程 \(h_S(k)=ph_S(k+1)+qh_S(k-1)\) 的解，最终可以得到在 \(p\neq q\) 时</p> \[h_s(k)=\frac{1}{q-p}\left(k-S\cdot\frac{1-(q/p)^k}{1-(q/p)^S}\right)\] <p>当 \(p=q=\frac{1}{2}\) 时，我们有特解 \(-k^2\)。所以说 \(p=q\) 时</p> \[h_S(k)=k(S-k)\] <h3 id="random-walks">Random Walks</h3> <p>Bernoulli Random Walks: \(X_n\) 相互独立，其中</p> \[\begin{cases} \mathbb{P}(X_k=+1)=p \\ \mathbb{P}(X_k=-1)=q \end{cases}\] <p>\(p+q=1\)，然后我们定义</p> \[S_n=\sum_{i=1}^nX_i\] <p>很显然 \(\mathbb{P}(S_{2n}=2k+1)=\mathbb{P}(S_{2n+1}=2k)=0\)，然后</p> \[\begin{cases} \mathbb{P}(S_{2n}=2k)=\binom{2n}{n+k}p^{n+k}q^{n-k} \\ \mathbb{P}(S_{2n+1}=2k+1)=\binom{2n+1}{n+k+1}p^{n+k+1}q^{n-k} \end{cases}\] <p>难度在我们怎么计算他啥时候回到 \(0\)。我们令</p> \[T_0^r=\inf\{n\geq 1: S_n=0\}\] <p>表示第一次回到 \(0\) 的时间。</p> <p>然后我们设</p> \[g(n)=\mathbb{P}\left(T_0^r=n\mid S_0=0\right)\] <p>也就是在第 \(n\) 步第一次回到 \(0\) 的概率。那很显然 \(g(2k+1)=0\)。</p> <p>接下来是一个比较神奇的套路，就是我们假设 \(h(n)\) 为第 \(n\) 步回到 \(0\) 的概率，那我们可以得到一个卷积式子：</p> \[h(n)=\sum_{k=0}^{n-2}g(n-k)h(k)\] <p>也就是先走 \(n-k\) 步第一次回到 \(0\)，然后继续走 \(k\) 步回到 \(0\)。所以我们现在只要解决 \(h\) 就可以了。</p> <p>我们考虑 \(h(n)\) 的生成函数</p> \[H(s)=\mathbb{E}\left[s^{T_0^r}\cdot\mathbb{1}_{T_0^r&lt;\infty}\right]=\sum_{n=0}^\infty h(n)s^n\] <p>大概推推：</p> \[\begin{aligned} H(s)&amp;=\sum_{n=0}^\infty h(n)s^n\\ &amp;=\sum_{n=0}^\infty\binom{2n}{n}p^nq^ns^{2n}\\ &amp;=\sum_{n=0}^\infty\frac{(2n)!}{(n!)^2}\left(pqs^2\right)^n\\ &amp;=\sum_{n=0}^\infty\frac{\left(\prod_{i=1}^n2i\right)\left(\prod_{i=1}^n(2i-1)\right)}{(n!)^2}\left(pqs^2\right)^n\\ &amp;=\sum_{n=0}^\infty\frac{\prod_{i=1}^n(2i-1)}{n!}\left(2pqs^2\right)^n\\ &amp;=\sum_{n=0}^\infty\frac{(-2)^n\prod_{i=1}^n\left(-\frac{1}{2}-(i-1)\right)}{n!}\left(2pqs^2\right)^n\\ &amp;=\sum_{n=0}^\infty\frac{\left(-\frac{1}{2}\right)^{\underline{i}}}{n!}\left(-4pqs^2\right)^n\\ &amp;=\left(1-4pqs^2\right)^{-\frac{1}{2}} \end{aligned}\] <p>又考虑到：</p> \[\begin{aligned} G(s)H(s)&amp;=\left(\sum_{i=1}^\infty s^ig(i)\right)\left(\sum_{j=0}^\infty s^jh(j)\right)\\ &amp;=\sum_{i=2}^\infty\sum_{j=0}^\infty s^{i+j}g(i)h(j)\\ &amp;=\sum_{k=2}^\infty s^k\sum_{i=2}^\infty g(i)h(k-i)\\ &amp;=\sum_{k=2}^\infty s^k h(k)\\ &amp;=-1 + \sum_{k=0}^\infty s^kh(k)\\ &amp;=-1 + H(s) \end{aligned}\] <p>于是乎</p> \[G(s)=1-\frac{1}{H(s)}=1-\sqrt{1-4pqs^2}\] <p>所以</p> \[\begin{aligned} \mathbb{P}\left(T_0^r=\infty\mid S_0=0\right)&amp;=1-\mathbb{P}\left(T_0^r&lt;\infty\mid S_0=0\right)\\ &amp;=1-G(1)=\sqrt{1-4pq}\\ &amp;=\sqrt{4p^2-4p+1}\\ &amp;=\lvert 2p-1\rvert\\ &amp;=\lvert p-q\rvert \end{aligned}\] <p>而根据前面的 Gambling Problems，其实我们已经解出当 \(k\neq 0\) 时：</p> \[\mathbb{P}\left(T_0^r=\infty\mid S_0=k\right)=1-\lim_{S\to\infty}f_S(k)=\max\left\{0, 1-\left(\frac{q}{p}\right)^k\right\}\] <p>然后我们来计算 \(\mathbb{E}\left[T_0^r\mid S_0=0\right]\) 的时候会发现如果 \(\mathbb{P}\left(T_0^r\mid S_0=0\right)&gt;0\) 的时候这个期望肯定是 \(\infty\)。而 \(\mathbb{P}\left(T_0^r\mid S_0=0\right)\) 只有在 \(p=q=\frac{1}{2}\) 的时候才会为 \(0\)。然鹅当 \(p=q=\frac{1}{2}\) 时：</p> \[\mathbb{E}\left[T_0^r\mid S_0=0\right]=\mathbb{E}\left[T_0^r \cdot\mathbb{1}_{\left\{T_0^r&lt;\infty\right\}}\mid S_0=0\right]=\left.\frac{\partial G}{\partial s}\right|_{s=1}=\infty\] <p>所以我们不管 \(p, q\) 都有：</p> \[\mathbb{E}\left[T_0^r\mid S_0=0\right]=\infty\] <p>关于 first time 的 distribution 的话，我们不难算出</p> \[\mathbb{P}\left(T_0^r=2k\mid S_0=0\right)=\frac{1}{(2k)!}\left.\frac{\partial^{2k}G}{\partial s^{2k}}\right|_{s=0}=\frac{1}{2k-1}\binom{2k}{k}(pq)^k\] <h3 id="discrete-time-markov-chains">Discrete-Time Markov Chains</h3> <p>Markov property 指的是下一步的 distribution 只跟当前有关：</p> \[\mathbb{P}\left(Z_{n+1}=j\mid Z_n=i_n, \cdots, Z_0=i_0\right)=\mathbb{P}\left(Z_{n+1}=j\mid Z_n=i_n\right)\] <p>\(\pi_n\) 是行向量，转移方程</p> \[\pi_{n+1}=\pi_n P\] <p>首先研究 hitting probabilities。假设状态空间为 \(\mathbb{S}\)，现在有一个点集 \(A\subset\mathbb{S}\) 是吸收点。也就是说 \(\forall s\in\mathbb{S}, P_{s, s}=1\)。我们康康从 \(k\) 开始被 \(A\) 中哪个点吸收的分布：</p> \[g_l(k)=\mathbb{P}\left(Z_{T_A}=l\mid Z_0=k\right)\] <p>其中 \(T_A\) 表示第一次撞到 \(A\) 的概率。</p> <p>显然</p> \[g_l(k) = P_{k, l} + \sum_{m\in\mathbb{S}\setminus A}P_{k, m} g_l(m)\] <p>然后我们研究从一个点开始期望多久被吸收，我们定义：</p> \[h_A(k) = \mathbb{E}\left[T_A\mid Z_0=k\right]\] <p>显然</p> \[h_A(k) = 1 + \sum_{m\in\mathbb{S}\setminus A}P_{k, m} h_A(m)\] <p>当然很多事会我们会钦定最后 \(d\) 个为吸收点，也就是：</p> \[P = \begin{bmatrix} Q &amp; R \\ 0 &amp; I_d \\ \end{bmatrix}\] <p>酱一来我们就可以简单地写成</p> \[h_A = \mathbb{1}_{n-d} + Qh_A\] <p>当然很多时候我们每个点都是有个 utility 的，也就是说：</p> \[h_A(k) = \mathbb{E}\left[\sum_{n=0}^{T_A}r(Z_n)\mid Z_0=k\right]\] <p>那酱的话就把 \(\mathbb{1}\) 换成 \(r\) 就可以了。</p> <p>接下来是 return times。我们定义 \(T_j^r\) 为第一次到 \(j\) 的时间（但不是 \(Z_0\)）：</p> \[T_j^r = \inf\{n\ge 1: Z_n=j\}\] <p>然后 \(\mu_j(i)\) 表示从 \(i\) 开始第一次回到 \(j\) 的期望时间：</p> \[\mu_j(i) = \mathbb{E}\left[T_j^r\mid Z_0=i\right]\] <p>酱紫 \(\mu_i(i)\) 就成功定义了“return times”。</p> <p>显然：</p> \[\mu_j(i) = 1 + \sum_{m\in\mathbb{S}}P_{i, m}\mu_j(m)\] <p>我们接下来定义 \(p_{i, j}\) 为从 \(i\) 能走到 \(j\) 的概率，当然一开始不算：</p> \[p_{i, j} = \mathbb{P}\left(T_j^r&lt;\infty\mid Z_0=i\right)\] <p>我们定义 \(f_{i, j}^{(n)}\) 为从 \(i\) 开始走 \(n\) 步恰好第一次走到 \(j\) 的概率：</p> \[f_{i, j}^{(n)} = \mathbb{P}\left(T_j^r=n\mid Z_0=i\right)\] <p>显然</p> \[p_{i, j} = \sum_{n=1}^\infty f_{i, j}^{(n)}\] <p>Number of returns 被定义为：</p> \[R_j = \sum_{n=1}^\infty\mathbb{1}_{\{Z_n=j\}}\] <p>那么 \(R_j\) 的分布其实是：</p> \[\mathbb{P}(R_j = m \mid Z_0 = i) = \begin{cases} 1 - p_{i, j} &amp; m = 0 \\ p_{i, j}\cdot p_{j, j}^{m - 1}\cdot (1 - p_{j, j}) &amp; m \ge 1 \end{cases}\] <p>那期望也好算：</p> \[\mathbb{E}[R_j \mid Z_0 = i] = \sum_{m = 1}^\infty m\cdot p_{i, j}\cdot p_{j, j}^{m - 1}\cdot (1 - p_{j, j}) = \frac{1}{1 - p_{j, j}}\] <p>所以说我们得到一个性质就是，如果要</p> \[\mathbb{E}[R_i\mid Z_0=i] = \frac{1}{1 - p_{i, i}}\] <p>这个东西有穷，当且仅当 \(p_{i, i} &lt; 1\)。</p> <p>而还有一个意义比较明确而且封闭的式子是：</p> \[\mathbb{E}[R_j\mid Z_0=i] = \mathbb{E}\left[\mathbb{1}_{\{X_n=j\}}\mid X_0=i\right] = \sum_{n=1}^\infty\left[P^n\right]_{i, j} = -\mathbb{1}_{\{i=j\}} + \left[(I - P)^{-1}\right]_{i, j}\] <h3 id="branching-processes">Branching Processes</h3> <p>一开始我有一个东西，然后没过一段时间这个东西随机分裂成 \(Y\) 个一样的东西，然后一直这样分裂下去。</p> \[X_0 = 1, X_{n+1} = \sum_{k=1}^{X_n} Y_k\] <p>其中</p> \[\mathbb{P}(Y &lt; \infty) = \sum_{n\ge 0}\mathbb{P}(Y = n) = 1\] <p>考虑转移矩阵 \(P\)，\(P_{i,j}\) 表示 \(i\) 个东西分裂成 \(j\) 个的概率。显然 \(P_{0,0}=1\)，没有东西就无法分裂。\(P_{1, j}=\mathbb{P}(Y=j)\)，指的是从一个东西分裂开来。</p> <p>酱紫的话是个树状结构，所以叫 Branching Process。</p> <p>考虑生成函数 \(G_n(s) = \mathbb{E}\left[s^{X_n}\mid X_0 = 1\right]\) 表示第 \(n\) 代的概率生成函数，我们有：</p> \[G_{n+1}(s) = G_n(G_1(s)) = G_1(G_n(s))\] <p>证明的话：</p> \[\begin{aligned} G_{n+1}(s) &amp;= \mathbb{E}\left[s^{X_{n+1}}\mid X_0 = 1\right]\\ &amp;=\mathbb{E}\left[s^{\sum_{l=1}^{X_n}Y_l}\mid X_0=1\right]\\ &amp;=\sum_{k=1}^\infty\mathbb{E}\left[\prod_{l=1}^{k}s^{Y_l}\mid X_n=k\right]\mathbb{P}(X_n=k\mid X_1 = 1)\\ &amp;=\sum_{k=1}^\infty\mathbb{E}\left[s^{Y}\right]^k\mathbb{P}(X_n=k\mid X_1 = 1)\\ &amp;=\sum_{k=1}^\infty G_1(s)^k\mathbb{P}(X_n=k\mid X_1 = 1)\\ &amp;=G_n(G_1(s)) \end{aligned}\] <p>于是乎对于 \(n\) 轮后的期望值我们有：</p> \[\begin{aligned} \mu_n &amp;= \mathbb{E}\left[X_n\mid X_0 = 1\right]\\ &amp;=\left.\frac{\partial G_n(s)}{\partial s}\right|_{s=1}\\ &amp;=\left.\frac{\partial G_{n-1}(G_1(s))}{\partial G_1(s)}\cdot\frac{\partial G_1(s)}{\partial s}\right|_{s=1}\\ &amp;=\left.\frac{\partial G_{n-1}(G_1(s))}{\partial G_1(s)}\right|_{s=1}\cdot\left.\lim_{s\to 1^-}\frac{\partial G_1(s)}{\partial s}\right|_{s=1}\\ &amp;=\left.\frac{\partial G_{n-1}(s)}{\partial s}\right|_{s=1}\cdot\left.\frac{\partial G_1(s)}{\partial s}\right|_{s=1}\\ &amp;=\mu_{n-1}\mu_1\\ &amp;=\mu_1^n \end{aligned}\] <p>对于一个 branching process \((X_n)_{n\in\mathbb{N}}\)：</p> <ul> <li>Supercritical: \(\mu_1 &gt; 1\)，\(\mu_n\to\infty\)</li> <li>Critical: \(\mu_1 = 1\)，\(\mu_n\to\infty\)</li> <li>Subcritical: \(\mu_1 &lt; 1\)，\(\mu_n\to 0\)</li> </ul> <p>同样的，我们考虑方差</p> \[\begin{aligned} \sigma_n^2 &amp;= \mathrm{Var}\left[X_n\mid X_0 = 1\right]\\ &amp;= \left.\frac{1}{2}\frac{\partial^2G_{n}(s)}{\partial s^2}\right|_{s=1}\\ &amp;= \left.\frac{1}{2}\frac{\partial}{\partial s}\left(\frac{\partial}{\partial s} G_{n-1}(s)\cdot\frac{\partial}{\partial s}G_1(s)\right)\right|_{s=1}\\ &amp;= \left.\frac{\partial^2}{\partial s^2}G_{n-1}(s)\cdot\frac{\partial}{\partial s}G_1(s)\right|_{s=1} + \left.\frac{\partial}{\partial s}G_{n-1}(s)\cdot\frac{\partial^2}{\partial s^2}G_1(s)\right|_{s=1}\\ &amp;= \sigma_{n-1}^2\mu_1 + \mu_{n-1}\sigma_1^2\\ &amp;= \sigma_{n-1}^2\mu_1 + \mu_{1}^{n-1}\sigma_1^2\\ &amp;=\begin{cases} n\sigma_1^2 &amp; \mu = 1\\ \sigma_1^2\mu_1^{n-1}\frac{1-\mu_1^n}{1-\mu_1} &amp; \mu\neq 1 \end{cases} \end{aligned}\] <p>接下来我们要研究的是，\(X_n\) 能延续多久，也就是“time to extinction”。我们定义</p> \[T_0 = \inf\{n\ge 0: X_n = 0\}\] <p>以及最终的 extinction probability</p> \[\alpha_k = \mathbb{P}(T_0 &lt; \infty\mid X_0 = k)\] <p>首先显然我们有：</p> \[\begin{aligned} \mathbb{P}(T_0 = n\mid X_0 = 1) &amp;= \mathbb{P}(X_n = 0\mid X_0 = 1) - \mathbb{P}(X_{n-1} = 0\mid X_0 = 1) \\ &amp;= G_n(0) - G_{n-1}(0)\\ &amp;= G_1(G_{n-1}(0)) - G_{n-1}(0) \end{aligned}\] <p>而我们来考虑 \(\alpha_k\)，首先显然这 \(k\) 个是独立的：</p> \[\alpha_k = \alpha_1^k\] <p>而我们考虑了 \(\alpha_1\)：</p> \[\begin{aligned} \alpha_1 &amp;= \lim_{n\to\infty}\mathbb{P}(T_0 &lt; n\mid X_0 = 1)\\ &amp;= \lim_{n\to\infty}\mathbb{P}(X_n=0\mid X_0 = 1)\\ &amp;= \lim_{n\to\infty}G_n(0) \end{aligned}\] <p>另一个神奇的性知识 \(\alpha_1\) 一定是方程 \(G_1(\alpha) = \alpha\) 的解：</p> \[\begin{aligned} \alpha_1 &amp;= \sum_{k=0}^\infty\alpha_k\mathbb{P}(X_1 = k\mid X_0 = 1)\\ &amp;= \sum_{k=0}^\infty\alpha_1^k\mathbb{P}(X_1 = k\mid X_0 = 1)\\ &amp;= G_1(\alpha_1) \end{aligned}\] <p>当然考虑到</p> \[\alpha = G_1(\alpha) = G_1(G_1(\alpha)) = \cdots\] <p>所以</p> \[\forall k\in\mathbb{N}, \alpha = G_k(\alpha)\] <p>我们可以进一步证明 \(\alpha_1\) 一定是方程 \(G_1(\alpha) = \alpha\) 最小的正解。</p> <p>首先因为 \(\frac{\partial}{\partial s}G_1(s) &gt; 0\)，这个函数肯定是递增的，所以说对于任意 \(k\)，\(G_k\) 肯定是递增的。</p> <p>而考虑到上面已经论证过只要满足 \(\alpha = G_1(\alpha)\)，肯定对于任意 \(k\)，能满足 \(\alpha = G_k(\alpha)\)，于是乎：</p> \[\alpha_1 = \lim_{n\to\infty}G_n(0)\le \lim_{n\to\infty}G_n(\alpha) = \alpha\] <p>也就是说对于任意符合条件的 \(\alpha\)，他肯定是大于等于 \(\alpha_1\) 的。于是乎 \(\alpha_1\) 一定是最小的正解。</p> <h3 id="continuous-time-markov-chains">Continuous-Time Markov Chains</h3> <p>首先是 Poisson Process。就是隔一段时间往上 \(+1\)。\(N_t\) 表示 \(t\) 时刻是多少，其中 \(N_0=0\)。我们定义 \(T_k\) 为第一次到达 \(k\) 的时间。</p> \[N_t = \sum_{k\ge 1} k\cdot\mathbb{1}_{t\in \left[T_{k-1}, T_k\right)} = \sum_{k\ge 1}\mathbb{1}_{t\in \left[T_{k-1}, \infty\right)}\] <p>我们需要这种过程满足两个性质：</p> <ol> <li>Independence of increments: 对于任意的 \(0\le t_1 &lt; t_2 &lt; \cdots &lt; t_n\)，\(N_{t_1}-N_{t_0}, N_{t_2}-N_{t_1}, \cdots, N_{t_n}-N_{t_{n-1}}\) 是相互独立的。</li> <li>Stationarity of increments: \(N_{t+s}-N_s\sim N_t\)。</li> </ol> <p>那其实很显然这就是一个 poison distribution 嘛：</p> \[\mathbb{P}(N_t - N_s = k) = e^{-\lambda(t-s)}\frac{(\lambda(t-s))^k}{k!}\] <p>其中</p> \[\lambda = \lim_{h\to 0^+} \frac{1}{h}\mathbb{P}(N_h = 1)\] <p>然后还有就是 \(T_1\) 个 exp distribution 有关，\(T_n\) 跟 gamma distribution 有关。</p> \[T_n \sim \Gamma(n, \lambda): f_{T_n}(t) = \lambda^n e^{-\lambda t}\frac{(\lambda t)^{n-1}}{\Gamma(n)}\] <p>然后我们把他一般化一下，得到 continuous-time Markov chain。其实核心也就是 “Memoryless”。</p> <p>只不过这次的转移矩阵是一个关于时间的函数了：</p> \[P_{i, j}(t) = \mathbb{P}(Z_{s + t} = j\mid Z_s = i)\] <p>而显然 \(P(0)=I\)。</p> <p>很显然的性质是：</p> \[P(s + t) = P(s)P(t) = P(t)P(s)\] <p>学习 Poisson process，我们来研究类似 \(\lambda\) 的一个跟“平均”有关的东西，我们考虑：</p> \[Q = \lim_{t\to 0^+}\frac{1}{t}\left(P(t) - P(0)\right) = \left.\frac{\partial}{\partial t}P(t)\right|_{t=0}\] <p>而其实我们有（这个叫“backward Kolmogorov equation”）：</p> \[\begin{aligned} \frac{\partial}{\partial t}P(t) &amp;= \lim_{h\to 0^+}\frac{1}{h}\left(P(t+h) - P(t)\right)\\ &amp;= \lim_{h\to 0^+}\frac{1}{h}\left(P(h)P(t) - P(t)\right)\\ &amp;= \lim_{h\to 0^+}\frac{1}{h}\left(P(h) - I\right)P(t)\\ &amp;= QP(t) \end{aligned}\] <p>当然同理我们还可以得到（这个叫“forward Kolmogorov equation”）：</p> \[\frac{\partial}{\partial t}P(t) = P(t)Q\] <p>解这个微分方程我们有：</p> \[P(t) = e^{Qt} = \sum_{n=0}^\infty\frac{t^n}{n!}Q^n = I + \sum_{n=1}^\infty\frac{t^n}{n!}Q^n\] <p>我们记 \(\lambda_{i,j} = Q_{i,j}\)，其实这个 \(\lambda_{i,j}\) 就和 Poisson process 那个一样了：</p> \[P(h) = I + hQ + \mathcal{O}(h^2)\] <p>也就是：</p> \[\mathbb{P}(X_{x + h} = j\mid X_t = i) = P_{i, j}(h) = \begin{cases} \lambda_{i,j}h + \mathcal{O}(h^2) &amp; i\neq j \\ 1 + \lambda_{i,i}h + \mathcal{O}(h^2) &amp; i = j \end{cases}\] <p>根据这个，我们对于 \(i\neq j\)，如果我们已经知道它下一步会到 \(j\)。我们定义停留在 \(i\) 的时间为 \(\tau_{i, j}\)，我们可以有：</p> \[\mathbb{P}(\tau_{i, j}&gt;t\mid i\to j) = e^{-\lambda_{i, j}t}\] <p>以及</p> \[\mathbb{E}[\tau_{i, j}\mid i\to j] = \int_{0}^\infty t\lambda_{i, j}e^{-\lambda_{i, j}t}\mathrm{d}t = \frac{1}{\lambda_{i, j}}\] <p>当然另外还有一个性质是：</p> \[\sum_{j\in\mathbb{S}}\lambda_{i,j} = 0\] <p>就是每个点要么出去要么留在原地嘛。</p> <p>然后我们考虑 \(\tau_i\)，也就是停留在 \(i\) 的时间：</p> \[\tau_i = \min_{j\neq i}\tau_{i, j}\] <p>我们可以计算概率：</p> \[\begin{aligned} \mathbb{P}(\tau_i &gt; t) &amp;= \mathbb{P}\left(\min_{j\neq i}\tau_{i, j}\right)\\ &amp;= \prod_{j\neq i}\mathbb{P}(\tau_{i, j} &gt; t)\\ &amp;= \exp\left(-\sum_{j\neq i}\lambda_{i, j}t\right)\\ &amp;= e^{\lambda_{i, i}t} \end{aligned}\] <p>于是乎</p> \[\mathbb{E}[\tau_i] = \frac{1}{\sum_{j\neq i}\lambda_{i, j}} = -\frac{1}{\lambda_{i, i}}\] <h2 id="discrete-time-martingales">Discrete-Time Martingales</h2>]]></content><author><name></name></author><category term="Notes"/><category term="Probability Theory"/><category term="Reinforcement Learning"/><summary type="html"><![CDATA[Notes for NTU MH3512 Stochastic Processes]]></summary></entry><entry><title type="html">Game Theory</title><link href="https://pufanyi.github.io/blog/Berkeley-STAT155/" rel="alternate" type="text/html" title="Game Theory"/><published>2024-06-18T00:00:00+00:00</published><updated>2024-06-18T00:00:00+00:00</updated><id>https://pufanyi.github.io/blog/Berkeley-STAT155</id><content type="html" xml:base="https://pufanyi.github.io/blog/Berkeley-STAT155/"><![CDATA[<ul> <li><a href="https://classes.berkeley.edu/content/2024-summer-stat-155-001-lec-001">STAT 155 Game Theory</a> <ul> <li><a href="https://mitpress.mit.edu/9780262650403/a-course-in-game-theory/">Textbook 1</a></li> <li><a href="https://mitpress.mit.edu/9780262061414/game-theory/">Textbook 2</a></li> <li><a href="https://doi.org/10.2307/j.ctvjsf522">Textbook 3</a></li> </ul> </li> <li><a href="https://www.ntu.edu.sg/docs/librariesprovider123/obtl/mas/updated-obtl/mh4320-spms-mas-outcomes-based-teaching-and-learning-document-(obtl)-5-jun-2023.pdf">MH4320 Computational Economics</a> <ul> <li><a href="https://www.cambridge.org/core/books/game-theory/B0C072F66E027614E46A5CAB26394C7D">Textbook</a></li> </ul> </li> </ul> <h2 id="preferences">Preferences</h2> <h3 id="一些基础定义和概念">一些基础定义和概念</h3> <p><strong>Consumption Space</strong>: \(X\subseteq\mathbb{R}_+^n\)</p> <p><strong>Preference Relation</strong>: \(x\succsim y\) or \(x\succeq y\), \(x\) is as lease as good as \(y\)</p> <p><strong>Indifference</strong>: \(x\sim y \Longleftrightarrow x\succsim y \land y\succsim x\)</p> <p><strong>Strict Preference</strong>: \(x\succ y \Longleftrightarrow x\succsim y \land x\nsim y\)</p> <h3 id="常见的-assumptions">常见的 Assumptions</h3> <p>Preference 这个概念挺大的，通常我们会带着一些 assumption 来研究。下面是一些常见的 assumption。</p> <p><strong>Rationality Assumption</strong>: completeness and transitivity。</p> <p>这样不会陷入死循环和一些矛盾的情况。</p> <p>反例：</p> <ol> <li>剪刀石头布：\(x\succ y\succ z\succ x\)，无法做出最优选择</li> <li>咖啡加糖：\(c_1\sim c_{0.9}\sim c_{0.8}\sim\cdots\sim c_{0.1}\sim c_0\)，但是\(c_1\nsim c_0\)。需要考虑一些心理的情况。</li> </ol> <p><em><strong>Convex Combination</strong></em>:</p> \[\alpha x+(1-\alpha)y, \alpha\in[0,1]\] <p><em><strong>Convex Set</strong></em>:</p> \[\forall x, y\in X\ ,\forall\alpha\in[0, 1], \alpha x+(1-\alpha)y\in X\] <p><em><strong>Convex Function</strong></em>:</p> \[f: X\to\mathbb{R}, \forall x, y\in X, \forall\alpha\in[0, 1], f(\alpha x+(1-\alpha)y)\le \alpha f(x)+(1-\alpha)f(y)\] <p>Convex 是笑脸，concave 是哭脸。</p> <p>高维空间比大小的一些记号：</p> \[\begin{aligned} x\ge y&amp;\Longleftrightarrow \forall i, x_i\ge y_i\\ x&gt;y&amp;\Longleftrightarrow x\ge y\land x\neq y\\ x\gg y&amp;\Longleftrightarrow \forall i, x_i&gt;y_i \end{aligned}\] <p><em><strong>Strongly Monotone</strong></em>:</p> \[x&gt;y\Longrightarrow f(x)&gt;f(y)\] <p><em><strong>Weakly Monotone</strong></em>:</p> \[x\gg y\Longrightarrow f(x)&gt; f(y)\] <p><strong>Locally Satisfied Preference</strong>:</p> \[\forall x\in X, \forall \epsilon&gt;0, \exists y, \lVert x-y\rVert&lt;\epsilon\land y\succsim x\] <p>旁边总有比他好的。</p> <p><strong>Weekly Monotone Preference</strong>:</p> \[x\gg y\Longrightarrow x\succ y\] <p>所有东西都来一点更好。</p> <p><strong>Strongly Monotone Preference</strong>:</p> \[x&gt;y\Longrightarrow x\succ y\] <p>越多越好。</p> <p><strong>Convex Preference</strong>:</p> \[x\succsim z, y\succsim z\Longrightarrow\forall\alpha\in[0, 1], \alpha x+(1-\alpha)y\succsim z\] <p><strong>Strictly Convex Preference</strong>:</p> \[x\succsim z, y\succsim z, y\neq x\Longrightarrow \forall\alpha\in(0, 1), \alpha x+(1-\alpha)y\succ z\] <p>我们称 \(f\) 是 quasi-concave 的当且仅当</p> \[f(\lambda x+(1-\lambda)y)\le\max\{f(x), f(y)\}\] <p><strong>Continuous Preference</strong>:</p> \[\forall n\in\mathbb{N}, x_n\succsim y_n, x_n\to x, y_n\to y\Longrightarrow x\succsim y\] <h2 id="utility-functions">Utility Functions</h2> <p>我们定义一个 \(u: X\to \mathbb{R}\) 使得</p> \[u(x)\ge u(y)\Longleftrightarrow x\succsim y\] <p>我们说是 \(u\) represents \(\succsim\)。</p> <p>这个 \(u\) 就是 \(\succsim\) 的 utility functions。</p> <p>一个定理是 \(\succsim\) 是 rational and continuous 的当且仅当存在一个连续的 \(u\)。</p> <ul> <li>\(\succsim\) is monotone \(\Longleftrightarrow\) \(u\) is monotone</li> <li>\(\succsim\) is convex \(\Longleftrightarrow\) \(u\) is quasi-concave</li> </ul> <p>当然很显然地：</p> \[\begin{cases} x\sim y\Longleftrightarrow u(x)=u(y)\\ x\succ y\Longleftrightarrow u(x)&gt;u(y) \end{cases}\] <h2 id="marginal-utility">Marginal Utility</h2> \[\mathrm{MU}(x)=\frac{\partial u(x)}{\partial x}\] <p>一般比如说对钱，我们会有 \(\mathrm{MU}(x)\) 是递减的。给的越多，多一块的价值越小。也就是 \(u''(x)&lt;0\)。</p> <h2 id="decision-making-under-uncertainty">Decision Making Under Uncertainty</h2> <h3 id="lotteries">Lotteries</h3> <p>在有 uncertainty 的情况下，用户做的决策是 lotteries，而不是确定的 goods。</p> <p>A lottery is a vector \(L = (x_1, p_1; x_2, p_2; \cdots; x_n, p_n)\). \(x_i\) 是 realization，\(p_i\) 是 probability。</p> <p>对于某个 realization，我们有其 utility \(u(x_i)\)，然后我们定义整个 lottery 的 utility 为 \(U(L) = \mathbb{E}[u(L)]\) (Von-Neumann Morgenstern Utility Function)。</p> <p>很多时候我们会对 lotteries 做线性叠加，比如一些钱买定期，一些钱买股票。所以其实我们就是在一个 convex set 上做决策。</p> <p>这时候问题就简化为我们有 \(n\) 个 realizations \(X = \{x_1, x_2, \cdots, x_n\}\)，将这 \(n\) 个 realizations 做线性组合，我们将这个 simplex 定义为 \(\mathbb{L}(X)\)，也就是：</p> \[\mathbb{L}(X) = \left\{(x_1, p_1; x_2, p_2; \cdots; x_n, p_n): p_i\ge 0, \sum_{i=1}^n p_i = 1\right\}\] <p>我们同样可以在 \(\mathbb{L}(X)\) 上定义 \(\succsim\)，而 \(\succsim\) 需要满足如下公理：</p> <ul> <li>Completeness: \(\forall L_1, L_2\in\mathbb{L}(X), L_1\succsim L_2\lor L_2\succsim L_1\)</li> <li>Transitivity: \(L_1\succsim L_2, L_2\succsim L_3\Longrightarrow L_1\succsim L_3\)</li> <li>Continuity: \(L_1\succsim L_2\succsim L_3\Longrightarrow \exists\alpha\in[0, 1], L_2\sim \alpha L_1+(1-\alpha)L_3\)</li> <li>Independence: \(L_1\succsim L_2\Longrightarrow \forall \alpha\in[0, 1], \alpha L_1+(1-\alpha)L_3\succsim \alpha L_2+(1-\alpha)L_3\)</li> </ul> <p><strong>Von Neumann–Morgenstern utility theorem</strong>: 上面四条同时 hold，等价于存在一个 \(u\)，并且任何可行的 \(u'\) 都可以通过一个 affine transformation 得到：\(u' = a+bu, b&gt;0\)。</p> <h3 id="st-petersburg-paradox">St. Petersburg paradox</h3> <p>这个是用来展示为什么必须要用 \(\mathbb{E}[u(L)]\) 而不是直接 \(\mathbb{E}[L]\) 的例子。</p> <p>假设有一个游戏，需要 1000 块钱。游戏是给你一个硬币你去抛，如果正面就给你一块钱继续抛，第二次正面两块钱，第三次四块钱，第 \(n\) 次 \(2^{n-1}\) 块钱，直到你抛到反面结束。</p> <p>这个游戏是铁不会玩的，因为你回本概率挺低的。但是</p> \[\mathbb{E}[L] = \sum_{n=1}^\infty\frac{1}{2^n}\times 2^{n-1} = \infty\] <p>这也显示了人们对赌钱是 risk averse 的。</p> <h3 id="risk-aversion">Risk Aversion</h3> <p>对于一个通过 \(u\) 来进行选择的 agent，我们判断他是否喜欢 take risks：</p> <ul> <li>Risk Averse: \(u(\mathbb{E}[L])\ge \mathbb{E}[u(L)]\)</li> <li>Risk Neutral: \(u(\mathbb{E}[L]) = \mathbb{E}[u(L)]\)</li> <li>Risk Loving: \(u(\mathbb{E}[L])\le \mathbb{E}[u(L)]\)</li> </ul> <p>用 Jensen’s inequality 很好判断: For a convex function \(f\), we have \(f(\mathbb{E}[X])\le \mathbb{E}[f(X)]\).</p> <p>对于一个 Risk Averse 的 agent，会有一个 \(\mathrm{CE}\) 来表示他愿意用这么多钱来换取一个稳定的状态：</p> \[u(\mathbb{E}[L]-\mathrm{CE}) = \mathbb{E}[u(L)]\] <p>我们考虑把一个 agent 的对 risk 的态度量化地表示，我们考虑 \(-u''(x)\) 的正负是个很好的指标。但如果 \(v=a+bu\)，那么 \(-v''(x)\neq -u''(x)\)，所以我们考虑：</p> \[R_A(x)=-\frac{u''(x)}{u'(x)}\] <p>我们将其称作 Arrow-Pratt Absolute Risk Aversion Coefficient，越大越 risk averse。</p> <p>但是有时候钱越多我们就会越极端，所以我们考虑定义 Relative Risk Aversion：</p> \[R_R(x)=-x\cdot\frac{u''(x)}{u'(x)}\] <h3 id="allais-paradox">Allais Paradox</h3> <p>考虑四个 lotteries：</p> <ul> <li>Lottery A: \(\left(\$10^6, 11\%; \$0, 89\%\right)\)</li> <li>Lottery B: \(\left(\$5\times 10^6, 10\%; \$0, 90\%\right)\)</li> <li>Lottery C: \(\left(\$10^6, 100\%\right)\)</li> <li>Lottery D: \(\left(\$5\times 10^6, 10\%; \$10^6, 89\%, \$0, 1\%\right)\)</li> </ul> <p>A 比 B，C 比 D。几乎大部分人会更喜欢 B 和 C。（虽然其实我上课的时候选了 B 和 D 呃呃呃）</p> <p>我们令 \(u(x)\) 表示获得 \(x\times 10^6\) 块钱，于是我们有：</p> \[\begin{cases} u(1)\times 0.11 &lt; u(5)\times 0.1\\ u(1)&gt;u(5)\times 0.1+u(1)\times 0.89 \end{cases}\] <p>而下面一个式子化简一下能得到：</p> \[u(1)\times 0.11 &gt; u(5)\times 0.1\] <p>两个式子是矛盾的。</p> <p>这让我们意识到其实在人真正考虑概率的时候，将“小概率发生”和“完全不发生”是分的很明确的。因为上面那个例子很多人时看到 D 项中有 \(1\%\) 的概率拿不到钱而去选 C 项。解决方法是我们对概率需要加一个修正函数 \(\pi(p)\)，使得我们的 utility function 变为 \(u(x)\times\pi(p)\)。这个 \(\pi\) 函数在 \(p=0\) 的时候会有一个陡增。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-06-18-Berkeley-STAT155/allais_paradox_pi-480.webp 480w,/assets/img/2024-06-18-Berkeley-STAT155/allais_paradox_pi-800.webp 800w,/assets/img/2024-06-18-Berkeley-STAT155/allais_paradox_pi-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2024-06-18-Berkeley-STAT155/allais_paradox_pi.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="ambiguity-aversion">Ambiguity Aversion</h3> <p>另一个叫 Ellsberg Paradox 的悖论，我们考虑现在有两个盒子，每个盒子有 100 个红球或黑球。第一个盒子有 50 红 50 黑，第二个盒子啥也不知道。</p> <p>有四个选项：</p> <ul> <li>A: 从第一个盒子里随机抽一个球，如果是红球，拿 100 块钱，否则拿 0 块钱</li> <li>B: 从第一个盒子里随机抽一个球，如果是黑球，拿 100 块钱，否则拿 0 块钱</li> <li>C: 从第二个盒子里随机抽一个球，如果是红球，拿 100 块钱，否则拿 0 块钱</li> <li>D: 从第二个盒子里随机抽一个球，如果是黑球，拿 100 块钱，否则拿 0 块钱</li> </ul> <p>很显然 \(A\sim B, C\sim D\)。尽管 A 和 B 加起来和 C 和 D 加起来是一样的，但大部分人会认为 \(A\succ C, B\succ D\)。</p> <p>这是因为人们不喜欢不确定性，也就是 ambiguity aversion。</p> <h2 id="definition-of-a-game">Definition of a Game</h2> <h3 id="actions-and-preferences">Actions and Preferences</h3> <p>接下来正是讨论 Game Theory 了。</p> <p>之前我们考虑的都是一个人的选择，现在是多人的决策问题，也就是说我们要考虑别人的操作。</p> <p>有 \(N\) 个 agents，每个 agent 有一个 action set</p> \[\mathcal{S}_i = \{s_{1}^i, s_{2}^i, \cdots, s_{N_i}^i\}\] <p>当然后面好像也有很多是写成 \(\mathcal{A}_i\) 的，反正看得懂就行。</p> <p>A strategic game consists of</p> <ul> <li>The players \(\mathcal{N} = \{1, 2, \cdots, N\}\)</li> <li>Actions: \(\mathcal{A}=\mathcal{A_1}\times\cdots\times\mathcal{A}_N\)</li> <li>Preferences: \(\succsim_i\) for each player \(i\)</li> <li>Outcomes</li> </ul> <h3 id="information-sets-and-strategies">Information Sets and Strategies</h3> <p>The set of possible strategy profiles is</p> \[\mathcal{S} = \mathcal{S}_1\times \mathcal{S}_2\times\cdots\times \mathcal{S}_N\] <p>对于一个游戏，在玩的过程中，每个人都会有一个 information \(H\)，对于第 \(i\) 个人所有可能的 information 集合我们记作 information sets \(\mathscr{H}_i\)。玩家只能看到 \(H\) 以内的东西，其他的（比如 \(H\) 以外别人的决策）他是看不见的。</p> <p>对于第 \(i\) 个玩家，假设现在有 information \(H\in\mathscr{H}_i\)，那么定义他可行的方案 \(\mathcal{C}_i(H)\subseteq\mathcal{A}_i\)（对于每个 \(H\) 可行方案肯定是一样的，否则他就有更多 information 了），然后我们定义他的 strategy 为 \(s_i: \mathscr{H}_i\to\mathcal{A}_i\) 并且 \(s_i(H)\in\mathcal{C}_i(H)\)。</p> <p>最终综合每个人的选择，我们有一个 strategy profile:</p> \[s = (s_1, s_2, \cdots, s_N)\in \mathcal{S}\] <p>而很多时候我们会关注某个 player \(i\) 的 strategy，我们一般会将 strategy profile 写作 \((s_i, s_{-i})\)，其中 \(s_{-i}\) 是除了 \(i\) 以外的其他人的 strategy。</p> <h3 id="payoff-functions">Payoff Functions</h3> <p>对于一个游戏，第 \(i\) 个人选了决策 \(s_i\)，我们有 \(s=(s_1, s_2, \cdots, s_N)\in\mathcal{S}\)。</p> <p>这样子我们可以定义第 \(i\) 个人的 utility function 为 \(u_i(s)\)，我们也叫做 payoff function。</p> <p>两个人的时候我们通常写成表格的形式：</p> <table> <thead> <tr> <th> </th> <th>Rock</th> <th>Paper</th> <th>Scissors</th> </tr> </thead> <tbody> <tr> <td><strong>Rock</strong></td> <td>\((0, 0)\)</td> <td>\((-1, 1)\)</td> <td>\((1, -1)\)</td> </tr> <tr> <td><strong>Paper</strong></td> <td>\((1, -1)\)</td> <td>\((0, 0)\)</td> <td>\((-1, 1)\)</td> </tr> <tr> <td><strong>Scissors</strong></td> <td>\((-1, 1)\)</td> <td>\((1, -1)\)</td> <td>\((0, 0)\)</td> </tr> </tbody> </table> <h3 id="strategy-form">Strategy Form</h3> <p>我们定义一个 \(\mathcal{I}\) 个人的 simple game 的 strategy / normal form 为：</p> \[\Gamma = \left&lt;\mathcal{I}, \left\{S_i\right\}, \left\{u_i(\cdot)\right\}\right&gt;\] <h3 id="pure-strategies-and-mixed-strategies">Pure Strategies and Mixed Strategies</h3> <p>Pure strategy 指的是一个人只能选一个 action，而 mixed strategy 指的是一个人可以通过概率分布选多个 actions。</p> <p>假设 \(P_1\) 选的概率为 \(\boldsymbol{p}\)，\(P_2\) 选的为 \(\boldsymbol{q}\)。\(P_1\) 的 payoff 为 \(M\)，那么我们有 \(P_1\) 的 expected payoff：</p> \[U_1(\boldsymbol{p}, \boldsymbol{q}) = \sum_{i\in\mathcal{I}}\sum_{j\in\mathcal{J}}M^{(1)}_{ij}p_iq_j=p^{\top}M_1q\] <p>对于每个人策略一定在一个 simplex 上，我们定义其为 \(\Delta(\mathcal{I})\) 和 \(\Delta(\mathcal{J})\)。</p> <h2 id="zero-sum-games">Zero-Sum Games</h2> <p>最先讨论的是零和博弈。也就是</p> \[\forall s\in \mathcal{S}, \sum_{i=1}^N u_i(s) = 0\] <p>你要获利的唯一方法是让别人变差。</p> <p>对于双人的，我们可以在表中只写第一个人的 payoff：</p> <table> <thead> <tr> <th> </th> <th>Rock</th> <th>Paper</th> <th>Scissors</th> </tr> </thead> <tbody> <tr> <td><strong>Rock</strong></td> <td>\(0\)</td> <td>\(-1\)</td> <td>\(1\)</td> </tr> <tr> <td><strong>Paper</strong></td> <td>\(1\)</td> <td>\(0\)</td> <td>\(-1\)</td> </tr> <tr> <td><strong>Scissors</strong></td> <td>\(-1\)</td> <td>\(1\)</td> <td>\(0\)</td> </tr> </tbody> </table> <p>这样子也就是 \(P_1\) 要最大化 \(P_2\) 要最小化。</p> <p>如果一个游戏不是零和的，我们可以加一个人，让</p> \[u_{N+1}(a_1, a_2, \cdots, a_N) = -\sum_{i=1}^N u_i(a_1, a_2, \cdots, a_N)\] <p>这样子就变成了零和博弈。</p> <h3 id="security-level">Security Level</h3> <p>\(\underline{v}\): \(P_1\) 先来，然后他考虑 \(P_2\) 的最优策略。</p> <p>对于 pure strategies：</p> \[\underline{v} = \max_{s_1\in\mathcal{S}_1}\min_{s_2\in\mathcal{S}_2}u_1(s_1, s_2)\] <p>对于 mixed strategies：</p> \[\underline{v} = \max_{\boldsymbol{p}\in\Delta(\mathcal{I})}\min_{\boldsymbol{q}\in\Delta(\mathcal{J})}p^{\top}Mq\] <p>\(\overline{v}\): \(P_2\) 先来，然后他考虑 \(P_1\) 的最优策略。</p> <p>对于 pure strategies：</p> \[\overline{v} = \min_{s_2\in\mathcal{S}_2}\max_{s_1\in\mathcal{S}_1}u_2(s_1, s_2)\] <p>对于 mixed strategies：</p> \[\overline{v} = \min_{\boldsymbol{q}\in\Delta(\mathcal{J})}\max_{\boldsymbol{p}\in\Delta(\mathcal{I})}p^{\top}Mq\] <p>很显然后手肯定是占优的，因为他知道先手的信息，所以</p> \[\underline{v}\le \overline{v}\] <p>如果 \(\underline{v} = \overline{v}\)，我们定义 \(v=\underline{v}=\overline{v}\) 为 the value of the game。</p> <h3 id="maxmin-and-minmax-strategies">Maxmin and Minmax Strategies</h3> <p>对于 maxmin 和 minmax，我们考虑的是假设我们告诉对手我们的策略（包含概率），对手选择最优 pure strategy。对于一个 \(n\times m\) 的矩阵 \(U\)：</p> \[\begin{aligned} \max\min(U)&amp;=\max_{\boldsymbol{p}\in\Delta[n]}\min_{y\in[m]}\sum_{i\in\mathcal{n}}p_i\cdot U_{i, y}\\ \min\max(U)&amp;=\min_{\boldsymbol{q}\in\Delta[m]}\max_{x\in[n]}\sum_{j\in\mathcal{m}}q_j\cdot U_{x, j} \end{aligned}\] <p>Von Neumann’s Minimax Theorem: 对于零和博弈</p> \[\max\min(U) = \min\max(U)\] <h2 id="dominant-strategies">Dominant Strategies</h2> <h3 id="strictly-dominant-strategies">Strictly Dominant Strategies</h3> <p>对于一个 player，如果不管对方怎么做决策，他做某个决策一定是最优的，那这个决策就是 strictly dominant 的。</p> <p>A strategy \(s_i\in \mathcal{S}_i\) is strictly dominant for player \(i\) if</p> \[\forall s_{-i}\in\mathcal{S}_{-i}, \forall s_i'\in\mathcal{S}_i, u_i(s_i, s_{-i})&gt;u_i(s_i', s_{-i})\] <h3 id="strictly-dominated-strategies">Strictly Dominated Strategies</h3> <p>我们说一个 strategy 是 strictly dominated 的，如果存在另一个 strategy 使得不管对方怎么做，这个 strategy 都比他好。换句话说，就是这个 strategy 一定不会被选。</p> <p>A strategy \(s_i\in \mathcal{S}_i\) is strictly dominated for player \(i\) if</p> \[\exists s_i'\in\mathcal{S}_i, \forall s_{-i}\in\mathcal{S}_{-i}, u_i(s_i', s_{-i})&gt;u_i(s_i, s_{-i})\] <h3 id="weakly-dominated-strategies">Weakly Dominated Strategies</h3> <p>A strategy \(s_i\in \mathcal{S}_i\) is weakly dominated for player \(i\) if</p> \[\exists s_i'\in\mathcal{S}_i, \forall s_{-i}\in\mathcal{S}_{-i}, u_i(s_i', s_{-i})\ge u_i(s_i, s_{-i})\] <h3 id="iterated-elimination-of-strictly-dominated-strategies">Iterated Elimination of Strictly Dominated Strategies</h3> <p>Strictly dominated strategies 一定不会被选，所以我们可以直接把这个策略去掉。然后我们就可以不断找每个人的 strictly dominated strategies，然后去掉来简化游戏。</p> <p>不能用 weekly dominated strategies，因为这些策略还是有可能会被选的。</p> <h3 id="strictly-dominated-strategies-in-mixed-strategies">Strictly Dominated Strategies in Mixed Strategies</h3> <p>有时候尽管 pure strategy 不存在 strictly dominated strategies，考虑 mixed strategies 时可能会存在。</p> <p>比如说</p> <table> <thead> <tr> <th> </th> <th>L</th> <th>R</th> </tr> </thead> <tbody> <tr> <td><strong>U</strong></td> <td>\((10, 1)\)</td> <td>\((0, 0)\)</td> </tr> <tr> <td><strong>M</strong></td> <td>\((4, 2)\)</td> <td>\((4, 1)\)</td> </tr> <tr> <td><strong>D</strong></td> <td>\((0, 5)\)</td> <td>\((10, 2)\)</td> </tr> </tbody> </table> <p>这玩意儿 \(M\) 是被 strictly dominated by \(\frac{1}{2}U+\frac{1}{2}D\) 的。</p> <p>我们说一个 mixed strategy \(\sigma_i\) 是 strictly dominated 的，当且仅当存在 \(\sigma_i'\) 使得</p> \[\forall\sigma_{-i}, u_i(\sigma_i', \sigma_{-i})&gt;u_i(\sigma_i, \sigma_{-i})\] <p>移项然后展开：</p> \[u_i(\sigma_i', \sigma_{-i})-u_i(\sigma_i, \sigma_{-i})=\sum_{-i\in s_{-i}}\left[\prod_{k\neq i}\sigma_{k}(s_k)\right]\left[u_i(\sigma'_i, s_{-i})-u_i(\sigma_i, s_{-i})\right]&gt;0\] <p>我们考虑这个式子，如果所有的 \(u_i(\sigma'_i, s_{-i})-u_i(\sigma_i, s_{-i})&gt;0\) 的话，很显然整个式子是正的，如果其中有一个小于 \(0\)，我们就让这一项前面的 \(\sigma_k(s_k)=1\)，其他都变成 \(0\)，这样整个式子就小于 \(0\) 了。</p> <p>于是乎对于一个 \(\sigma_i\)，我们只要 check 所有的 pure strategies 就可以。</p> <h2 id="knowledge">Knowledge</h2> <p><strong>Mutual Knowledge</strong>: 如果大家都知道某个 knowledge，那么这个 knowledge 是 mutual knowledge。</p> <p><strong>Common Knowledge</strong>: 如果任意一个 player 序列 \(i_1, i_2, \cdots, i_k\)，我们有 \(i_1\) 知道 \(i_2\) 知道 \(\cdots\) 知道 \(i_k\) 知道某个 knowledge，那么我们说这个 knowledge 是 common knowledge。</p> <p>很显然 common knowledge 是 mutual knowledge。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-06-18-Berkeley-STAT155/common_knowledge-480.webp 480w,/assets/img/2024-06-18-Berkeley-STAT155/common_knowledge-800.webp 800w,/assets/img/2024-06-18-Berkeley-STAT155/common_knowledge-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2024-06-18-Berkeley-STAT155/common_knowledge.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>假设人从左到右是 \(A, B, C\)，\(A\) 不知道 \(A\) 的帽子颜色。我们现在假定 player 序列是 \(A, B, C\)。对于 \(A\) 来说，假设 \(A\) 的帽子颜色是红的，那么 \(B\) 就能看到俩红，那他就能知道 \(C\) 肯定能看到至少一红。但是如果 \(A\) 的帽子不是红色的，那么 \(B\) 只能看到一红，他就不能确定 \(C\) 是否能看到红色了。这导致了这道题不是 common knowledge。</p> <h2 id="nash-equilibrium">Nash Equilibrium</h2> <h3 id="best-response">Best Response</h3> <p>We say that a strategy \(\sigma_i\) is a best response to \(\sigma_{-i}\) if</p> \[\forall\sigma'_i\in\Delta(\mathcal{S}_i), u_i(\sigma_i, \sigma_{-i})\ge u_i(\sigma'_i, \sigma_{-i})\] <p><strong><em>Best response correspondence</em></strong>:</p> \[b_i(\sigma_{-i})=\left\{\sigma_i\in\Delta(\mathcal{S}_i): \forall \sigma_i'\in\Delta(\mathcal{S}_i), u_i(\sigma_i, \sigma_{-i})\ge u_i(\sigma_i', \sigma_{-i})\right\}\] <h3 id="nash-equilibrium-in-pure-strategies">Nash Equilibrium in Pure Strategies</h3> <p>每个人都是 best response 的策略。</p> <p>A strategy profile \(s=(s_1, \cdots, s_\mathcal{I})\) constitutes a Nash equilibrium of a game \(\Gamma=\left[\mathcal{I}, \left\{S_i\right\}, \left\{u_i(\cdot)\right\}\right]\) if for every \(i=1, \cdots, \mathcal{I}\),</p> \[u_i(s_i, s_{-i})\ge u_i(s_i', s_{-i})\] <p>for all \(s_i'\in S_i\).</p> <h3 id="nash-equilibrium-in-mixed-strategies">Nash Equilibrium in Mixed Strategies</h3> <p>和 pure strategies 的定义是一样的，对于游戏 \(\Gamma=\left[\mathcal{I}, \left\{\Delta(\mathcal{S}_i)\right\}, \left\{u_i(\cdot)\right\}\right]\), 我们有 \(\sigma = (\sigma_1, \cdots, \sigma_\mathcal{I})\) 是 Nash equilibrium if for every \(i=1, \cdots, \mathcal{I}\),</p> \[u_i(\sigma_i, \sigma_{-i})\ge u_i(\sigma_i', \sigma_{-i})\] <p>for all \(\sigma_i'\in\Delta(\mathcal{S}_i)\).</p> <p>其实也就是</p> \[\forall i, \sigma_i\in b_i(\sigma_{-i})\] <p>所以直觉上来讲其实就是这些 correspondence 的交集。</p> <p>比如说这个游戏：</p> <table> <thead> <tr> <th> </th> <th>Bach (\(\mathscr{B}_2\))</th> <th>Stravinsky (\(\mathscr{S}_2\))</th> </tr> </thead> <tbody> <tr> <td><strong>Bach</strong> (\(\mathscr{B}_1\))</td> <td>\((10, 5)\)</td> <td>\((0, 0)\)</td> </tr> <tr> <td><strong>Stravinsky</strong> (\(\mathscr{S}_1\))</td> <td>\((0, 0)\)</td> <td>\((5, 10)\)</td> </tr> </tbody> </table> <p>我们有对于 \(P_1\)：</p> \[\mathscr{B}_1\succsim\mathscr{S}_1\Longleftrightarrow p(\mathscr{B}_2)\ge\frac{1}{3}\] <p>同理，对称地对于 \(P_2\)：</p> \[\mathscr{B}_2\succsim\mathscr{S}_2\Longleftrightarrow p(\mathscr{B}_1)\ge\frac{2}{3}\] <p>画出图：</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-06-18-Berkeley-STAT155/nash_equilibrium_bach-480.webp 480w,/assets/img/2024-06-18-Berkeley-STAT155/nash_equilibrium_bach-800.webp 800w,/assets/img/2024-06-18-Berkeley-STAT155/nash_equilibrium_bach-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2024-06-18-Berkeley-STAT155/nash_equilibrium_bach.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>交点为 \((0, 0), \left(\frac{1}{3}, \frac{2}{3}\right), (1, 1)\)，所以这三个点是 Nash equilibrium。</p> <h3 id="checking-for-nash-equilibrium">Checking for Nash Equilibrium</h3> <p>我们考虑游戏 \(\Gamma=\left[\mathcal{I}, \left\{\Delta(\mathcal{S}_i)\right\}, \left\{u_i(\cdot)\right\}\right]\)。对于一个 \(\sigma=(\sigma_1, \cdots, \sigma_\mathcal{I})\)，我们定义 \(\mathcal{S}_i^+\subseteq\mathcal{S}_i\)：</p> \[\mathcal{S}_i^+=\left\{s_j\in\mathcal{S}_i: \sigma_{i,j}&gt;0\right\}\] <p>也就是这个人有可能执行这个操作。</p> <p>于是乎一个 \(\sigma\) 要满足他是 Nash equilibrium 当且仅当对于 \(i=1, \cdots, \mathcal{I}\)：</p> <ol> <li>\(u_i(s_i, \sigma_{-i})=u_i(s_i', \sigma_{-i})\) for all \(s_i, s_i'\in\mathcal{S}_i^+\)</li> <li>\(u_i(s_i, \sigma_{-i})\ge u_i(s_i', \sigma_{-i})\) for all \(s_i\in\mathcal{S}_i^+\) and \(s_i'\in\mathcal{S}_i\setminus\mathcal{S}_i^+\)</li> </ol> <p>大概就是，对于我来说，我知道别人有一个 mixed strategy，而我出的这个 mixed strategy 中的任何一种可能性都是一样优的（否则我就不要他了），而我不选的那几个操作一定不会更优（否则我肯定会增加它的概率）。如果对于每个人来说都是这样，那么就达到了一种均衡。</p> <h3 id="existence-of-nash-equilibrium">Existence of Nash Equilibrium</h3> <p>A Nash equilibrium exists in game \(\Gamma=\left[\mathcal{I}, \left\{\mathcal{S}_i\right\}, \left\{u_i(\cdot)\right\}\right]\) if for all \(i=1, \cdots, \mathcal{I}\):</p> <ol> <li>\(\mathcal{S}_i\) is a nonempty, convex, and compact subset of some Euclidean space \(\mathbb{R}^M\);</li> <li>\(u_i(s_1, \cdots, s_\mathcal{I})\) is continuous in \((s_1, \cdots, s_\mathcal{I})\) and quasi-concave in \(s_i\).</li> </ol> <p>考虑到当 \(\mathcal{S}\) 有限的时候，\(\Delta(\mathcal{S})\) 满足了 nonempty, convex, compact 三个条件，而且 \(u_i\) 也是 continuous 和 quasi-concave 的。所以我们说对于 mixed strategies game \(\Gamma=\left[\mathcal{I}, \left\{\Delta(\mathcal{S}_i)\right\}, \left\{u_i(\cdot)\right\}\right]\)，如果 \(\mathcal{S}_i\) 是有限的，那么 Nash equilibrium 一定存在。</p> <h3 id="correlated-equilibria">Correlated Equilibria</h3> <p>前面我们考虑 \(\sigma_i\) 都是独立的。但在现实生活中，一些信息是共享的，导致我们的策略是相关的。</p> <p>比如说红绿灯，大家会看到信号灯的信息来做出决策。</p> <p>这时候我们就要定义：</p> \[U_i(\sigma_1, \cdots, \sigma_\mathcal{I})=\sum_{s}\mathbb{P}[s_1, \cdots, s_\mathcal{I}]u_i(s_1, \cdots, s_\mathcal{I})\] <p>而这时候我们的 strategy 概率就应该是定义在 \(\mathcal{S}=S_1\times\cdots\times S_\mathcal{I}\) 上了，也就是描述 NE 需要考虑 joint distribution。</p> <h3 id="the-oddness-theorem">The Oddness Theorem</h3> <p>一个神奇的结论是在大部分情况下，一个游戏一定有奇数个 NE。</p> <p>严谨的说，拥有偶数个 NE 的游戏所构成的集合 Lebesgue measure 为 \(0\)。</p> <p>比如说有一个游戏：</p> <table> <thead> <tr> <th> </th> <th>L</th> <th>R</th> </tr> </thead> <tbody> <tr> <td><strong>U</strong></td> <td>\((a_1, a_2)\)</td> <td>\((b_1, b_2)\)</td> </tr> <tr> <td><strong>D</strong></td> <td>\((c_1, c_2)\)</td> <td>\((d_1, d_2)\)</td> </tr> </tbody> </table> <p>那么我们对于任意 \(\epsilon&gt;0\)，存在 \(0\le \epsilon_1, \cdots, \epsilon_8\le \epsilon\) 使得游戏：</p> <table> <thead> <tr> <th> </th> <th>L</th> <th>R</th> </tr> </thead> <tbody> <tr> <td><strong>U</strong></td> <td>\((a_1+\epsilon_1, a_2+\epsilon_2)\)</td> <td>\((b_1+\epsilon_3, b_2+\epsilon_4)\)</td> </tr> <tr> <td><strong>D</strong></td> <td>\((c_1+\epsilon_5, c_2+\epsilon_6)\)</td> <td>\((d_1+\epsilon_7, d_2+\epsilon_8)\)</td> </tr> </tbody> </table> <p>拥有奇数个 NE。</p> <p>证明没有详细地讲，只说了个大概的思路。主要是考虑一个 \(f: X\to X\) 的连续函数，不动点在大部分情况下有奇数个。除非与 \(y=x\) 相切或者端点在 \((x, x)\) 上，这种情况下稍稍移动一下函数就可以了。</p> <h2 id="welfare--optimality">Welfare / Optimality</h2> <p>很多时候我们需要知道什么是“好的”，因为有时候 Nash equilibrium 并不是最优的。</p> <h3 id="social-welfare">Social Welfare</h3> <p>最直观的方法是定义一个函数来表示整个社会的 welfare。我们定义 social welfare function 为</p> \[\mathcal{W}(x_1, \cdots, x_\mathcal{I})=\sum_{i=1}^\mathcal{I}\alpha_i u_i(x_i, x_{-i})\] <p>但这样做有两个很显然的问题：</p> <ol> <li>谁来定义 \(\alpha_i\)？</li> <li>是否所有人都能 accept 这个定义？</li> </ol> <p>所以我们下面引出 Pareto Optimality。</p> <h3 id="pareto-optimality">Pareto Optimality</h3> <p>假设我们有两个 agents 和两种物品进行分配，第一个物品有 \(A\) 个，第二个物品有 \(B\) 个。那么我们可以定义 allocation 为：</p> \[\left((x_1^a, x_2^a), (x_1^b, x_2^b)\right)\] <p>而物品的数量有限，所以：</p> \[\begin{cases} x_1^a+x_1^b=A\\ x_2^a+x_2^b=B \end{cases}\] <p>我们定义一个 Pareto Improvement \(\left((y_1^a, y_2^a), (y_1^b, y_2^b)\right)\) 满足：</p> \[\begin{bmatrix} u_a(y_1^a, y_2^a)\\ u_b(y_1^b, y_2^b) \end{bmatrix}&gt; \begin{bmatrix} u_a(x_1^a, x_2^a)\\ u_b(x_1^b, x_2^b) \end{bmatrix}\] <p>其中的 \(&gt;\) 指的是有一个大于其余大于等于。</p> <p>如果一个 allocation 没有 Pareto Improvement，那么我们称其为 Pareto Optimal。</p> <p>然而 Pareto Optimal 也不一定是 fair 的，但是他是 bare minimum，也就是说如果不是 Pareto Optimal，那么我们应该做出改进。</p> <p>上课提到了一个叫 laissez-fairez 的名词，其实就是自由放任。让市场自由调节来达到一个 Pareto Optimal 的状态。</p> <h3 id="mechanism--market-design">Mechanism / Market Design</h3> <p>另一种让社会达到最优状态的方法叫 mechanism design，也叫 reverse game theory。我们通过设计和修改游戏机制来打到社会的最优性。</p> <h2 id="rationalizable-strategies">Rationalizable Strategies</h2> <p>我们考虑一个游戏，如果对方做出某个选择，我们会做出相应的 best response。但是有些策略不管对方选了什么，我们都不可能作为 best response 去选择，我们把这种策略叫做 NBR（never best response）。</p> <p>那很显然 NBR 是可以忽略的，所以我们就重复在游戏中删除 NBR，直到没有 NBR 为止。</p> <p>最终剩下来的策略就是 rationalizable strategies。</p> <p>如果最终只剩了一个，那么我们说这个游戏是 dominance solvable 的。</p> <p>很显然 NE 肯定是 rationalizable 的，因为如果他不是 rationalizable，那肯定在某一次删除的时候被定义为 NBR 了，而那个 best response 肯定比这个好。</p> <p>但是 rationalizable 不一定是 NE 的，比如说 Matching Pennies：</p> <table> <thead> <tr> <th> </th> <th>Heads</th> <th>Tails</th> </tr> </thead> <tbody> <tr> <td><strong>Heads</strong></td> <td>\((1, -1)\)</td> <td>\((-1, 1)\)</td> </tr> <tr> <td><strong>Tails</strong></td> <td>\((-1, 1)\)</td> <td>\((1, -1)\)</td> </tr> </tbody> </table> <p>当然，NBR 也可能不是 strictly dominated by pure 的：</p> <table> <thead> <tr> <th> </th> <th>X</th> <th>Y</th> </tr> </thead> <tbody> <tr> <td><strong>A</strong></td> <td>\((2, 1)\)</td> <td>\((0, 0)\)</td> </tr> <tr> <td><strong>B</strong></td> <td>\((0, 1)\)</td> <td>\((2, 0)\)</td> </tr> <tr> <td><strong>C</strong></td> <td>\((1, 1)\)</td> <td>\((1, 2)\)</td> </tr> </tbody> </table> <p>尽管我们考虑 pure strategies，\(b_1(X)=\{A\}, b_1(Y)=\{B\}\)，\(C\) 是不会被选的。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-06-18-Berkeley-STAT155/rationalizable-480.webp 480w,/assets/img/2024-06-18-Berkeley-STAT155/rationalizable-800.webp 800w,/assets/img/2024-06-18-Berkeley-STAT155/rationalizable-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2024-06-18-Berkeley-STAT155/rationalizable.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="games-with-trembling-hands">Games with Trembling Hands</h2> <h3 id="trembling-hand-perfect-equilibrium">Trembling Hand Perfect Equilibrium</h3> <p>有时候我们做选择会手抖出错。也就其实是我们在选操作 \(i\) 的时候，我们其实选的是一个概率分布 \(\sigma_i\)。</p> <p>We say that a strategy profile \(\sigma\) is a trembling-hand perfect Nash Equilibrium if it can be approximated by a sequence of totally mixed strategy profiles for each player. 其中的 totally mixed 指的是所有概率都大于 \(0\)。也就是说，对于一个 pure strategy，稍稍扰动一下也是没有问题的。</p> <p>就比如下面这个例子：</p> <table> <thead> <tr> <th> </th> <th>U</th> <th>D</th> </tr> </thead> <tbody> <tr> <td><strong>U</strong></td> <td>\((1, 1)\)</td> <td>\((0, -3)\)</td> </tr> <tr> <td><strong>D</strong></td> <td>\((-3, 0)\)</td> <td>\((0, 0)\)</td> </tr> </tbody> </table> <p>\((D, D)\) 是 NE 但不是 THNE，因为如果稍微扰动一下，变成 \(((\epsilon_1, 1-\epsilon_1), (\epsilon_2, 1-\epsilon_2))\)，这时候是不如 \(((1-\epsilon_1, \epsilon_1), (\epsilon_2, 1-\epsilon_2))\) 的。也就是说，在有 trembling hand 的情况下，\(P_1\) 和 \(P_2\) 其实会考虑换到 \(U\)。</p> <h3 id="evolutionary-stable">Evolutionary Stable</h3> <p>当然根据这个定义，所有 totally mixed strategies 都是 THNE 的。但是我们可以沿用这个 idea 来定义和 “stability”。我们把一个 NE 扰动一下，如果还是 NE，那么我们就说这个 NE 是 stable 的。我们定义这个东西叫做 evolutionary stable。</p> <p>A mixed strategy profile \(\sigma^*\) is Evolutionary Stable if:</p> <ol> <li>\(u_i(\sigma_i^*, \sigma_{-i}^*)\ge u_i(\sigma_i, \sigma_{-i}^*)\) for all \(i\) and \(\sigma_i\in\Delta(\mathcal{S}_i)\)</li> <li>if \(u_i(\sigma_i^*, \sigma_{-i}^*)=u_i(\sigma_i, \sigma_{-i}^*)\), then \(u_i(\sigma_i^*, \sigma_{-i})&gt;u_i(\sigma_i, \sigma_{-i})\)</li> </ol>]]></content><author><name></name></author><category term="Notes"/><category term="Game Theory"/><summary type="html"><![CDATA[Notes for UC Berkeley STAT 155 Game Theory + NTU MH4320 Computational Economics]]></summary></entry><entry><title type="html">UC Berkeley CS 161 Computer Security</title><link href="https://pufanyi.github.io/blog/Berkeley-CS161/" rel="alternate" type="text/html" title="UC Berkeley CS 161 Computer Security"/><published>2024-06-17T00:00:00+00:00</published><updated>2024-06-17T00:00:00+00:00</updated><id>https://pufanyi.github.io/blog/Berkeley-CS161</id><content type="html" xml:base="https://pufanyi.github.io/blog/Berkeley-CS161/"><![CDATA[<p>居然有幸能来线下上课。</p> <p>这不记个笔记。</p> <p><a href="https://su24.cs161.org/">Summer 2024</a></p> <hr/> <h2 id="lecture-1-introduction-and-security-principles">Lecture 1: Introduction and Security Principles</h2> <h3 id="security-principles">Security Principles</h3> <ol> <li><strong>Know your threat model</strong>: 谁会来攻击你，为什么要攻击你。Threat Model 指的就是对攻击者建立一个合适的模型（比如他们有多少资源，他们的动机）。<em>You often just need to have “good enough” defense to make attackers turn somewhere else.</em></li> <li><strong>Consider Human Factors</strong>：考虑用户习惯，别让用户太麻烦。</li> <li><strong>Security is economics</strong>：搞 security 需要米，所以要考虑你保护的是啥。</li> <li><strong>Detect if You Can’t Prevent</strong>: <ul> <li><strong>Deterrence</strong>: Stop the attack before it happens.</li> <li><strong>Prevention</strong>: Stop the attack as it happens.</li> <li><strong>Detection</strong>: Learn that there was an attack (after it happened).</li> <li><strong>Response</strong>: Do something about the attack (after it happened). 对于 response，需要做的事 Mitigation and Recovery，就是比如在发现勒索软件的时候赶紧进行文件备份和转移。</li> </ul> </li> <li><strong>Defense in depth</strong>：多层防御，但是要考虑成本。</li> <li><strong>Least Privilege</strong>：然鹅其实现在的操作系统做的都很遭糕。</li> <li><strong>Ensure complete mediation</strong>：You should check <em>every</em> access to <em>every</em> object. 课上提出了一个叫做 <em>Reference Monitor</em> 的概念，就是一个任何 access 操作都必须经过的结点，比如说 network firewall。用这种方法来保证每个 access 都被检查过。</li> <li><strong>Separation of Responsibility</strong>：例子是原子弹发射，要两个人同时操作才行。</li> <li><strong>Shannon’s Maxim</strong>：你不能依赖于 Security Through Obscurity，也就是通过源代码的保密性来保护系统。想到 Kerckhoff’s Principle？</li> <li><strong>Use Fail-Safe Defaults</strong>：当系统崩溃的时候，应该让系统保持最安全的状态。比如说一些防盗门在断电的时候要自动关上。</li> <li><strong>Design in Security from the Start</strong></li> </ol> <h3 id="the-trusted-computing-base-tcb">The Trusted Computing Base (TCB)</h3> <p>TCB 指的是 The components of a system that security relies upon。</p> <p><strong>TCB Design Principles</strong>:</p> <ol> <li><strong>Unbypassable</strong> (or <strong>completeness</strong>)</li> <li><strong>Tamper-resistant</strong> (or <strong>security</strong>)：不能改，必须保证 TCB 的完整性</li> <li><strong>Verifiable</strong> (or <strong>correctness</strong>)：TCB 应该设计得越小越好（<strong>KISS principle</strong>: Keep It Simple, Stupid）</li> </ol> <p>这种让 TCB 和其他系统分离出来的方法让我们能够更方便的 focus on one thing。</p> <h3 id="tocttou-vulnerabilities">TOCTTOU Vulnerabilities</h3> <p>在讲 Ensure Complete Mediation 的时候提到了一个例子挺有意思的，叫做 The time of check to time of use (TOCTTOU) vulnerability。</p> <p>就是考虑一个 ATM 机提款的操作。假设现在你的银行账户里有 \(1000\) 块钱。一般情况下很直觉地会这样写提款程序：</p> <pre><code class="language-pseudocode">\begin{algorithm}
\caption{Withdrawal}
\begin{algorithmic}
\PROCEDURE{Withdrawal}{$w$}
  \STATE $b =$ \CALL{GetBalance}{} \COMMENT{Step (1)}
    \IF{$b &lt; w$}
      \STATE Abort
    \ENDIF
    \STATE \CALL{SetBalance}{$b - w$} \COMMENT{Step (2)}
    \STATE \CALL{DispenseCash}{$w$}
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}
</code></pre> <p>但这个程序事实上有一个巨大的漏洞，就是假设我现在开两个并行程序，两次都取 \(1000\) 块钱，当第一个程序运行到 <code class="language-plaintext highlighter-rouge">(2)</code> 之前时，我让第二个程序运行到 <code class="language-plaintext highlighter-rouge">(1)</code>。这时候我们会发现两个程序都能通过 <code class="language-plaintext highlighter-rouge">(1)</code> 进入 <code class="language-plaintext highlighter-rouge">(2)</code>，钱就会被取两次。这样我们能从 \(1000\) 块钱的账户中取出 \(2000\) 块钱。</p> <hr/> <h2 id="lecture-2-x86-assembly-and-call-stack">Lecture 2: x86 Assembly and Call Stack</h2> <h3 id="number-representation">Number Representation</h3> <ul> <li>nibble 是一个十六进制数的大小，1 nibble = 4 bits</li> <li>1 byte = 8 bits</li> <li>word 是指针的大小，32 位下是 32 bits，64 位下是 64 bits</li> </ul> <h3 id="call-compiler-assembler-linker-loader">CALL: Compiler, Assembler, Linker, Loader</h3> <ul> <li><strong>Compiler</strong>: 高级语言 -&gt; Assembly Code</li> <li><strong>Assembler</strong>: Assembly Code -&gt; Machine Code</li> <li><strong>Linker</strong>: Deals with dependencies and libraries</li> <li><strong>Loader</strong>: Sets up memory space and runs the machine code</li> </ul> <h3 id="c-memory-layout">C Memory Layout</h3> <p>讲课的时候考虑的是 32 位机，也就是 memory 是从 <code class="language-plaintext highlighter-rouge">0x00000000</code> 到 <code class="language-plaintext highlighter-rouge">0xFFFFFFFF</code>。其实可以把内存看作一个一维的数组，当然我们通常将其画成一张 \(n\times 4 \text{ bytes}\) 的表。</p> <pre><code class="language-typograms">                          4 bytes
                      |&lt;-----------&gt;|
     0xFFFFFFFF       +-------------+
--------------------&gt; |             |
                      |             |
   Higher Address     |             |
         ^            |             |
         |            |             |
         |            |             |
                      |   Memory    |
                      |             |
         |            |             |
         |            |             |
         v            |             |
    Lower Address     |             |
                      |             |
--------------------&gt; |             |
     0x00000000       +-------------+
                      --------------&gt;
                           index
</code></pre> <p>x86 中都是以 Little-endian 存储的，也就是说比如说一个东西是 <code class="language-plaintext highlighter-rouge">0x0123456789abcdef</code>，那么他在地址中应该存储为：</p> <pre><code class="language-typograms">+---------------------------+
| 0x67 | 0x45 | 0x23 | 0x01 |
+------+------+------+------+
| 0xef | 0xcd | 0xab | 0x89 |
+---------------------------+
</code></pre> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdint.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">union</span> <span class="p">{</span>
        <span class="kt">uint64_t</span> <span class="n">num_int64</span><span class="p">;</span>
        <span class="kt">unsigned</span> <span class="kt">char</span> <span class="n">num_char</span><span class="p">[</span><span class="mi">8</span><span class="p">];</span>
    <span class="p">}</span> <span class="n">num</span><span class="p">;</span>
    <span class="n">num</span><span class="p">.</span><span class="n">num_int64</span> <span class="o">=</span> <span class="mh">0x0123456789abcdef</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"%02x "</span><span class="p">,</span> <span class="n">num</span><span class="p">.</span><span class="n">num_char</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>输出：</p> <pre><code class="language-plain">ef cd ab 89 67 45 23 01
</code></pre> <p>但是数组和 <code class="language-plaintext highlighter-rouge">struct</code> 仍然是从小到大的顺序。</p> <p>然后 Memory 按照一下几个块分：</p> <pre><code class="language-typograms">+-------------------+
|       Stack       |
+~~~~~~~~~~~~~~~~~~~+
|         |         |
|         v         |
|                   |
|         ^         |
|         |         |
+~~~~~~~~~~~~~~~~~~~+
|       Heap        |
+-------------------+
|       Data        |
+-------------------+
|       Code        |
+-------------------+
</code></pre> <h3 id="function-call">Function Call</h3> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">foo</span><span class="p">(</span><span class="kt">int</span><span class="p">,</span> <span class="kt">int</span><span class="p">);</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">foo</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">foo</span><span class="p">(</span><span class="kt">int</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">b</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <pre><code class="language-assembly">main:
  pushq $2
  pushq $1

  call  foo


foo:
  movq  %rsp, %rbp
  subq  $32, %rsp
</code></pre> <p><code class="language-plaintext highlighter-rouge">leave</code> 等价于</p> <pre><code class="language-ass">mov   %ebp, %esp
pop   %ebp
</code></pre> <hr/> <h2 id="lecture-3-memory-safety-vulnerabilities">Lecture 3: Memory Safety Vulnerabilities</h2> <h3 id="buffer-overflow">Buffer Overflow</h3> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">vulnerable</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">char</span> <span class="n">name</span><span class="p">[</span><span class="mi">20</span><span class="p">];</span>
    <span class="n">gets</span><span class="p">(</span><span class="n">name</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">gets</code> 时将 <code class="language-plaintext highlighter-rouge">SHELLCODE</code> 写入内存，然后覆盖 <code class="language-plaintext highlighter-rouge">RIP</code> 使其指向他。</p> <pre><code class="language-typograms">+---------------+             +-------------------------+
|      ...      |             |          ...            |
+---------------+             +-------------------------+
|      RIP      |             |     (RIP)  &amp;SHELLCODE   |------+
+---------------+             +-------------------------+      |
|      SFP      |             |     (SFP)  'AAAA'       |      |
+---------------+             +-------------------------+      |
|     name      |    gets     |     (name) 'AAAA'       |      |
+---------------+  --------&gt;  +-------------------------+      |
|     name      |             |     (name) 'AAAA'       |      |
+---------------+             +-------------------------+      |
|     name      |             |     (name) SHELLCODE    |      |
+---------------+             +-------------------------+      |
|     name      |             |     (name) SHELLCODE    |      |
+---------------+             +-------------------------+      |
|     name      |             |     (name) SHELLCODE    |&lt;-----+
+---------------+             +-------------------------+
</code></pre> <p>当然 SHELLCODE 也可以写在其他地方比如说 <code class="language-plaintext highlighter-rouge">RIP</code> 上面这个随心情而定。</p> <pre><code class="language-diff2html">diff --git a/vulnerable.c b/vulnerable.c
--- a/vulnerable.c
+++ b/vulnerable.c
@@ -1,4 +1,4 @@
 void vulnerable(void) {
     char name[20];
-    gets(name);
+    fgets(name, 20, stdin);
 }
</code></pre> <p>实操的时候，看 RIP 和 SFP：</p> <pre><code class="language-gdb">(gdb) info frame
Stack level 0, frame at 0x7fffffffd9a0:
 rip = 0x555555555155 in foo (test.c:8); saved rip = 0x555555555140
 called by frame at 0x7fffffffd9b0
 source language c.
 Arglist at 0x7fffffffd990, args: a=1, b=2
 Locals at 0x7fffffffd990, Previous frame's sp is 0x7fffffffd9a0
 Saved registers:
  rbp at 0x7fffffffd990, rip at 0x7fffffffd998
</code></pre> <p>其中 <code class="language-plaintext highlighter-rouge">Saved registers</code> 中 <code class="language-plaintext highlighter-rouge">rbp</code> 指的是上课讲的 <code class="language-plaintext highlighter-rouge">sfp</code>，<code class="language-plaintext highlighter-rouge">rip</code> 是 <code class="language-plaintext highlighter-rouge">rip</code>，不太一样的是显示的 <code class="language-plaintext highlighter-rouge">rip</code> 是因为机器是 64 位的，是 register 里的 <code class="language-plaintext highlighter-rouge">rip</code>，如果是 32 位会显示 <code class="language-plaintext highlighter-rouge">ebp</code> 和 <code class="language-plaintext highlighter-rouge">eip</code>。这俩相差 $8$ bytes 正好一个 word。</p> <p>一些 vulnerable 的函数：</p> <ol> <li><code class="language-plaintext highlighter-rouge">gets</code>：改成 <code class="language-plaintext highlighter-rouge">fgets</code></li> <li><code class="language-plaintext highlighter-rouge">strcpy</code>：改成 <code class="language-plaintext highlighter-rouge">strncpy</code>（more compatible, less safe）或者 <code class="language-plaintext highlighter-rouge">strlcpy</code>（less compatible, more safe）</li> <li><code class="language-plaintext highlighter-rouge">strlen</code>：改成 <code class="language-plaintext highlighter-rouge">strnlen</code> 或者 <code class="language-plaintext highlighter-rouge">memchr</code></li> </ol> <h3 id="off-by-one-exploit">Off-by-One Exploit</h3> <p>这是很多初学者经常犯的错误就是</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">vulnerable</span><span class="p">()</span> <span class="p">{</span>
  <span class="kt">char</span> <span class="n">s</span><span class="p">[</span><span class="mi">32</span><span class="p">];</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">32</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">scanf</span><span class="p">(</span><span class="s">"%c"</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">vulnerable</span><span class="p">();</span>
  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>这样允许了我们有一个额外的输入。然而这个输入最多只能允许我们部分控制 <code class="language-plaintext highlighter-rouge">SFP</code>。</p> <p>我们需要这样修改：</p> <pre><code class="language-typograms">+--------------------------+                +---------------------------+
|       RIP of main        |                |        RIP of main        |
+--------------------------+                +---------------------------+
|       SFP of main        |&lt;---+           |        SFP of main        |
+--------------------------+    |           +---------------------------+
|    RIP of vulnerable     |    |           |     RIP of vulnerable     |
+--------------------------+    |           +---------------------------+
|    SFP of vulnerable     |----+           |   Fake SFP of vulnerable  |----+
+--------------------------+                +---------------------------+    |
|          x[2]            |      gets      |       Garbage bytes       |    |
+--------------------------+  -----------&gt;  +---------------------------+    |
|          x[1]            |                |      Fake RIP of main     |----+---&gt; SHELLCODE
+--------------------------+                +---------------------------+    |
|          x[0]            |                |      Fake SFP of main     |&lt;---+
+--------------------------+                +---------------------------+
</code></pre> <hr/> <h2 id="homework-1">Homework 1</h2> <p>也记录一下做 Homework 时学到的东西。</p> <h3 id="gdb">GDB</h3> <pre><code class="language-gdb">(gdb) x/4xw buf
0xbffffdf8:  0xbffffeac  0xb7ffc165  0x00000000  0x00000000
</code></pre> <p><code class="language-plaintext highlighter-rouge">0xbffffdf8</code> 是 <code class="language-plaintext highlighter-rouge">buf</code> 的地址，<code class="language-plaintext highlighter-rouge">4xw</code> 显示了 $4$ 个 word 的内容。</p> <pre><code class="language-gdb">(gdb) layout split
</code></pre> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-06-17-Berkeley-CS161/layout_split-480.webp 480w,/assets/img/2024-06-17-Berkeley-CS161/layout_split-800.webp 800w,/assets/img/2024-06-17-Berkeley-CS161/layout_split-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2024-06-17-Berkeley-CS161/layout_split.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>离开：<code class="language-plaintext highlighter-rouge">Ctrl + X</code> 再按 <code class="language-plaintext highlighter-rouge">A</code>。</p> <p>切换窗口：<code class="language-plaintext highlighter-rouge">Ctrl + X</code> 再按 <code class="language-plaintext highlighter-rouge">O</code>。</p> <p>看汇编代码</p> <pre><code class="language-gdb">(gdb) disas main
Dump of assembler code for function main:
   0x00001629 &lt;+0&gt;:     lea    0x4(%esp),%ecx
   0x0000162d &lt;+4&gt;:     and    $0xfffffff0,%esp
   0x00001630 &lt;+7&gt;:     push   -0x4(%ecx)
   0x00001633 &lt;+10&gt;:    push   %ebp
   0x00001634 &lt;+11&gt;:    mov    %esp,%ebp
   0x00001636 &lt;+13&gt;:    push   %ebx
   0x00001637 &lt;+14&gt;:    push   %ecx
   0x00001638 &lt;+15&gt;:    sub    $0x20,%esp
   0x0000163b &lt;+18&gt;:    call   0x1142 &lt;__x86.get_pc_thunk.bx&gt;
   ...
</code></pre>]]></content><author><name></name></author><category term="Notes"/><category term="Computer Security"/><summary type="html"><![CDATA[Notes for UC Berkeley CS 161 Computer Security]]></summary></entry><entry><title type="html">2021 Zhejiang Gao Kao</title><link href="https://pufanyi.github.io/blog/GaoKao/" rel="alternate" type="text/html" title="2021 Zhejiang Gao Kao"/><published>2024-06-06T00:00:00+00:00</published><updated>2024-06-06T00:00:00+00:00</updated><id>https://pufanyi.github.io/blog/GaoKao</id><content type="html" xml:base="https://pufanyi.github.io/blog/GaoKao/"><![CDATA[<h1 id="导数大题">导数大题</h1> <h2 id="question">Question</h2> <p>Let \(a, b\) be real numbers, and \(a&gt;1\). Consider the function \(f(x)=a^x-bx+e^2\) (\(x\in\mathbb{R}\)).</p> <ol> <li>Find the monotonic intervals of the function \(f(x)\).</li> <li>If for any \(b&gt;2e^2\), the function \(f(x)\) has two different zeros, find the range of \(a\).</li> <li>When \(a=e\), prove that: for any \(b&gt;e^4\), the function \(f(x)\) has two different zeros \(x_1, x_2\), satisfying \(x_2&gt;\frac{b\ln b}{2e^2}x_1 + \frac{e^2}{b}\).</li> </ol> <p><strong>Note</strong>:</p> <ol> <li>\(e=2.71828\cdots\) is the base of the natural logarithm.</li> <li>We define the natural logarithm as \(\ln x\), which is \(\ln x=\log_e x\).</li> </ol> <details><summary>中文原题</summary> <p>设 \(a, b\) 为实数，且 \(a&gt;1\)，函数 \(f(x)=a^x-bx+e^2\) (\(x\in\mathbb{R}\))</p> <ol> <li>求函数 \(f(x)\) 的单调区间；</li> <li>若对任意 \(b&gt;2e^2\)，函数 \(f(x)\) 有两个不同的零点，求 \(a\) 的取值范围；</li> <li>当 \(a=e\) 时，证明：对任意 \(b&gt;e^4\)，函数 \(f(x)\) 有两个不同的零点 \(x_1, x_2\)，满足 \(x_2&gt;\frac{b\ln b}{2e^2}x_1 + \frac{e^2}{b}\)。</li> </ol> <p>注：\(e=2.71828\cdots\) 是自然对数的底数。</p> </details> <h2 id="solution">Solution</h2> <h3 id="part-1">Part 1</h3> <p>The derivative of \(f(x)\) is</p> \[f'(x)=a^x\ln a-b\] <p>\(f''(x)=a^x\ln^2 a&gt;0\), so \(f'(x)\) is an strictly increasing function.</p> <p>When \(b&lt;0\), \(f'(x)&gt;\lim_{x\to-\infty}f'(x)=0\), so \(f(x)\) is an strictly increasing function.</p> <p>When \(b\ge 0\), solving \(f'(x)=0\) we can get \(x=\log_a\frac{b}{\ln a}\). Since \(f'(x)\) is increasing, we have:</p> <table> <thead> <tr> <th style="text-align: center">$x$</th> <th style="text-align: center">\(x\in\left(-\infty, \log_a\frac{b}{\ln a}\right)\)</th> <th style="text-align: center">\(x=\log_a\frac{b}{\ln a}\)</th> <th style="text-align: center">\(x\in\left(\log_a\frac{b}{\ln a}, +\infty\right)\)</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(f'(x)\)</td> <td style="text-align: center">\(f'(x)&lt;0\)</td> <td style="text-align: center">\(f'(x)=0\)</td> <td style="text-align: center">\(f'(x)&gt;0\)</td> </tr> <tr> <td style="text-align: center">\(f(x)\)</td> <td style="text-align: center">\(f(x)\) is decreasing</td> <td style="text-align: center">\(f(x)\) has a local minimum</td> <td style="text-align: center">\(f(x)\) is increasing</td> </tr> </tbody> </table> <p>As a result, when \(b&lt;0\), \(f(x)\) has a monotonically increasing interval \((-\infty, +\infty)\); when \(b\ge 0\), \(f(x)\) has a monotonically decreasing interval \(\left(-\infty, \log_a\frac{b}{\ln a}\right)\) and a monotonically increasing interval \(\left(\log_a\frac{b}{\ln a}, +\infty\right)\).</p> <h3 id="part-2">Part 2</h3> <p>Given that \(b&gt;2e^2&gt;0\), the function \(f(x)\) has a local minimum at \(x=\log_a\frac{b}{\ln a}\).</p> <p>Also, we have:</p> \[\begin{aligned} \lim_{x\to-\infty}f(x)&amp;=\lim_{x\to-\infty}a^x-bx+e^2=\infty\\ \lim_{x\to+\infty}f(x)&amp;=\lim_{x\to+\infty}a^x-bx+e^2=\infty \end{aligned}\] <p>Therefore, \(f(x)\) has two distinct zeros if and only if \(f\left(\log_a\frac{b}{\ln a}\right)&lt;0\).</p> <p>Let’s simplify \(f\left(\log_a\frac{b}{\ln a}\right)\):</p> \[\begin{aligned} f\left(\log_a\frac{b}{\ln a}\right)&amp;=a^{\log_a\frac{b}{\ln a}}-b\log_a\frac{b}{\ln a}+e^2\\ &amp;=\frac{b}{\ln a}-b\cdot\left(\log_ab-\log_a\ln a\right)+e^2\\ &amp;=\frac{b}{\ln a}-\frac{b\ln b}{\ln a}+\frac{b\ln\ln a}{\ln a} + e^2\\ &amp;=\frac{b}{\ln a}\left(1-\ln b+\ln\ln a\right)+e^2 \end{aligned}\] <p>For \(f\left(\log_a\frac{b}{\ln a}\right)&lt;0\) to hold, we must ensure:</p> \[\lim_{b\to \left(2e^{2}\right)^+}f\left(\log_a\frac{b}{\ln a}\right)\le 0\] <p>This implies:</p> \[\begin{aligned} 0&amp;\ge \lim_{b\to {\left(2e^{2}\right)}^+}f\left(\log_a\frac{b}{\ln a}\right)\\ &amp;=\lim_{b\to \left(2e^{2}\right)^+}\frac{b}{\ln a}\left(1-\ln b+\ln\ln a\right)+e^2\\ &amp;=\frac{2e^2}{\ln a}\left(1-\ln\left(2e^2\right)+\ln\ln a\right)+e^2\\ &amp;=\frac{2e^2}{\ln a}\left(\ln\ln a-1-\ln 2\right)+e^2\\ \end{aligned}\] <p>Hence, we should have:</p> \[2e^2\left(\ln\ln a-1-\ln 2\right)+e^2\ln a\le 0\] <p>This simplifies to:</p> \[2\ln\ln a+\ln a\le 2\ln 2+2\] <p>Let’s define \(\phi(x)=2\ln x+x\). The inequality above is equivalent to:</p> \[\phi(\ln a)\le \phi(2)\] <p>Given that \(\phi(x)\) is a strictly increasing function, we can have:</p> \[\ln a\le 2\Rightarrow a\le e^2\] <p>However, this is not the final answer since we should consider the whole range of \(b&gt;2e^2\) instead of a specific value of \(b\to \left(2e^2\right)^+\). But we have a necessary condition for \(a\) to satisfy.</p> <p>From \(f\left(\log_a\frac{b}{\ln a}\right)&lt;0\), we can get:</p> \[\frac{b}{\ln a}(1-\ln b+\ln\ln a)+e^2&lt;0\] <p>Let</p> \[g(a, b)=\frac{b}{\ln a}(1-\ln b+\ln\ln a)+e^2\] <p>We have:</p> \[\frac{\partial g}{\partial b}=\frac{1}{\ln a}(1-\ln b+\ln\ln a)-\frac{b}{\ln a}\cdot\frac{1}{b}=\frac{\ln\ln a-\ln b}{\ln a}\] <p>When \(a\le e^2, b&gt;2e^2\),</p> \[\ln\ln a-\ln b\le \ln\ln e^2-\ln 2e^2=\ln 2-\ln 2-2=-2&lt;0\] <p>So \(\frac{\partial g}{\partial b}&lt;0\) which means when \(a\le e^2\),</p> \[g(a, b) &lt; g(a, 2e^2)\le 0\] <p>So when \(a\le e^2\), \(f(x)=0\) must have two distinct solutions.</p> <p>In conclusion, the range of \(a\) is \(\left(1, e^2\right]\).</p> <h3 id="part-3">Part 3</h3> <p>When \(a=e\in(1, e^2], b&gt;e^4&gt;2e^2\), so \(f(x)=0\) has two distinct solutions.</p> <p>Let \(x_1, x_2\) be the two solutions, and \(x_1&lt;x_2\):</p> \[\begin{cases} e^{x_1}-bx_1+e^2=0 &amp; (1)\\ e^{x_2}-bx_2+e^2=0 &amp; (2) \end{cases}\] <p>\((1) - (2)\), we have:</p> \[e^{x_1}-e^{x_2}-b(x_1-x_2)=0\Rightarrow \frac{e^{x_1}-e^{x_2}}{x_1-x_2}=b\] <p>然后不会了啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊，有空再来更</p>]]></content><author><name>Pu Fanyi</name></author><category term="Notes"/><category term="Gao Kao"/><category term="Calculus"/><summary type="html"><![CDATA[明天就要高考去了，今天临时抱个佛脚]]></summary></entry><entry><title type="html">Classical Mechanics</title><link href="https://pufanyi.github.io/blog/ClassicalMechanics/" rel="alternate" type="text/html" title="Classical Mechanics"/><published>2024-06-03T00:00:00+00:00</published><updated>2024-06-03T00:00:00+00:00</updated><id>https://pufanyi.github.io/blog/ClassicalMechanics</id><content type="html" xml:base="https://pufanyi.github.io/blog/ClassicalMechanics/"><![CDATA[<p>偶然间刷到 Leonard Susskind 在 Stanford 的讲课视频，学着玩一玩。</p> <p><a href="https://theoreticalminimum.com/courses/classical-mechanics/2011/fall">视频链接</a></p> <hr/> <h1 id="state-diagrams-and-the-nature-of-physical-laws">State diagrams and the nature of physical laws</h1> <p>用状态来描述世界，这玩意儿在机器学习中也这么搞。</p> <p>但是在经典物理中我们认为如果我们知道这个世界处于某个状态，我们可以</p> <ol> <li>追溯过去，在状态图中就是每个状态入度为 \(1\)；</li> <li>预测未来，在状态图中就是每个状态出度为 \(1\)。</li> </ol> <p>那么在有穷图中这个图肯定是由多个环构成，当然其实 prof 在讲的时候说无穷图里我们也可以认为 \((\cdots\to -2\to 0\to 2\to 4\to\cdots)\) 是一个环。</p> <p>上课过程中有一个同学问了个问题，就是说按这样的话 classical statistical mechanics 怎么搞。这个是因为在状态中我们认为世界是已知的，但是在经典统计力学中一部分东西是未知的才能导致有概率的引入。我们认为世界是确定的。</p> <p>一个记号是 \(\dot{f}\) 表示 \(f\) 对事件的导数，也就是说 \(\dot{f} = \frac{\mathrm{d}f}{\mathrm{d}t}\)。</p> \[\begin{cases} \vec{v}=\dot{\vec{x}}\\ \vec{a}=\dot{\vec{v}}=\ddot{\vec{x}} \end{cases}\] <p>然后他举的例子是圆周运动：</p> \[\begin{cases} \vec{x} = \begin{bmatrix}r\cos\omega\theta\\ r\sin\omega\theta\end{bmatrix}\\ \vec{v} = \dot{\vec{x}} = \begin{bmatrix}-\omega r\sin\omega\theta\\ \omega r\cos\omega\theta\end{bmatrix}\\ \vec{a} = \ddot{\vec{x}} = \begin{bmatrix}-\omega^2r\cos\omega\theta\\-\omega^2r\sin\omega\theta\end{bmatrix}\\ \end{cases}\] <hr/> <h1 id="newtons-law-phase-space-momentum-and-energy">Newton’s law, phase space, momentum and energy</h1> <p>一个粒子的状态可以被描述为 \((\vec{x}, \vec{p})\)，即位置与动量。我们称整个空间为 phase space。</p> <p>根据牛顿第二定律：</p> \[\vec{F}=\dot{\vec{p}}\] <p>我们与 \(\vec{p}=m\dot{\vec{x}}\) 联立，我们就能解出 \((\vec{x}, \vec{p})\) 和 \(t\) 的关系。因此我们说牛顿力学是可逆的。</p>]]></content><author><name>Pu Fanyi</name></author><category term="Notes"/><category term="Classical Mechanics"/><category term="Physics"/><summary type="html"><![CDATA[学点好玩的]]></summary></entry><entry><title type="html">NTU MH3700 Numerical Analysis I</title><link href="https://pufanyi.github.io/blog/MH3700-Notes/" rel="alternate" type="text/html" title="NTU MH3700 Numerical Analysis I"/><published>2024-05-30T00:00:00+00:00</published><updated>2024-05-30T00:00:00+00:00</updated><id>https://pufanyi.github.io/blog/MH3700-Notes</id><content type="html" xml:base="https://pufanyi.github.io/blog/MH3700-Notes/"><![CDATA[<p>可选太多学不完了。</p> <p>趁着暑假对着 ppt 复习一下。</p> <p>尽管上课时候讲这玩意儿还是很严谨的，但时间原因以及毕竟选这门课纯属玩，很多情况下就不给出严格证明或者一笔带过了。</p> <hr/> <h2 id="root-finding">Root Finding</h2> <p>首先登场的是二分法，不讲。</p> <p>接下来说 fixed-point iteration。就是我们要解决 \(g(x)-x=0\) 也就是 \(g(x)=x\) 的问题。</p> <p>那么首先很显然的是如果 \(x\in[a, b]\) 时，\(g(x)\in[a, b]\)，那么在 \([a, b]\) 里铁定有一个解的。</p> <p>那啥时候不动点唯一呢？如果存在 \(k&lt;1\) 使得 \(\forall x\in[a, b], \left\lvert g'(x)\right\rvert \le k\)，那么我们说是唯一的。</p> <p>感性理解是可以嘟，严格证明用 Largrange 中值定理搞搞。</p> <p>然后 fixed-point iteration 就是我们一开始选个 \(p_0\)，然后 \(p_{n+1}=g(p_n)\)，蹲着他收敛就行。</p> <p>一定收敛吗？我们有一个定理就是如果存在一个 \(k\in(0, 1)\) 使得 \(\left\lvert g'(x)\right\rvert \le k\)，那么就一定收敛。</p> <p>证明的话因为我们有 Largrange 中值定理</p> \[\left|p_{n+1}-p\right|=\left|g(p_n)-g(p)\right|=\left|g'(\xi_n)\right|\cdot\left|p_n-p\right|\le k\cdot\left|p_n-p\right|\] <p>也就是说 \(k\) 越小收敛得越快。</p> <p>然后我们考虑我们要解 \(f(x)=0\)，我们要构造一个 \(g(x)\) 使得</p> \[f(x)=0\Leftrightarrow g(x)=x\] <p>我们可以有：</p> \[g(x)=x-\phi(x)f(x)\] <p>咱现在需要做的就是找到一个合适得 \(\phi(x)\) 让他收敛的尽量快。</p> <p>那怎么看收敛的尽量快呢，我们假设有个序列 \(\{p_n\}_{n=0}^\infty\)，如果存在 \(\alpha, \lambda&gt;0\) 使得</p> \[\lim_{n\to\infty}\frac{\left|p_{n+1}-p\right|}{\left|p_n-p\right|^\alpha}=\lambda\] <p>我们定义 \(\{p_n\}_{n=0}^\infty\) converge to \(p\) with order \(\alpha\).</p> <p>我们转到 \(g(x)\) 上的时候，我们发现 \(g'(p)=0\) 意味着这个序列的收敛速度一定是大于 \(1\) 的。我们考虑泰勒展开：</p> \[\lim_{n\to\infty}\frac{\left|p_{n+1}-p\right|}{\left|p_n-p\right|}=\lim_{n\to\infty}\frac{\left|g(p_n)-g(p)\right|}{\left|p_n-p\right|}=\left|g'(p)\right|=0\] <p>也就是说 \(\alpha=1\) 的时候 \(\lambda=0\)，而定义里说 \(\lambda&gt;0\)，也就是我们得让下面的阶数更大，即 \(\alpha&gt;1\)。</p> <p>那我们导一下 \(g(x)\)：</p> \[g'(x)=1-\phi(x)f'(x)-\phi'(x)f(x)\] <p>考虑到 \(f(p)=0\)，我们有</p> \[g'(p)=1-\phi(p)f'(p)\] <p>当 \(f'(p)=0\) 时，方程无解，否则我们可以让 \(\phi(p)=\frac{1}{f'(p)}\)。</p> <p>于是我们就推出了 Newton’s method：</p> \[p_{n+1}=p_n-\frac{f(p_n)}{f'(p_n)}\] <p>另一种 secant method 是因为有时候 \(f'(x)\) 很难求，我们可以用两个点的斜率代替：</p> \[p_{n+1}=p_n-f(p_n)\cdot\frac{p_n-p_{n-1}}{f(p_n)-f(p_{n-1})}\] <p>尽管这玩意儿的 rate of convergence 是 \(\frac{1+\sqrt{5}}{2}\approx1.618\)，但不需要求导，通常情况下 have better convergence than Newton per evaluation of \(f\)。</p> <p>然后现在问题是我们需要求解更高维度的方程，那我们就可以构造一个 \(\mathbb{R}^n\to\mathbb{R}^n\) 的函数 \(\boldsymbol{f}\) 求解</p> \[\boldsymbol{f}(\boldsymbol{x})=\boldsymbol{0}\] <p>大概感性理解一下，我们对 \(\boldsymbol{f}\) 做泰勒展开：</p> \[\boldsymbol{f}(\boldsymbol{a}+\boldsymbol{\delta})=\boldsymbol{f}(\boldsymbol{a})+\mathsf{D}\boldsymbol{f}(\boldsymbol{a})\cdot\boldsymbol{\delta}+\mathcal{O}\left(\left\|\boldsymbol{\delta}\right\|^2\right)\] <p>其中 \(\mathsf{D}\boldsymbol{f}(\boldsymbol{a})\) 是 Jacobian matrix，我们通常记作 \(\mathsf{J}(\boldsymbol{x})\)：</p> \[\mathsf{J}(\boldsymbol{x})=\mathsf{D}\boldsymbol{f}(\boldsymbol{x})=\begin{bmatrix} \frac{\partial f_1}{\partial x_1} &amp; \frac{\partial f_1}{\partial x_2} &amp; \cdots &amp; \frac{\partial f_1}{\partial x_n} \\ \frac{\partial f_2}{\partial x_1} &amp; \frac{\partial f_2}{\partial x_2} &amp; \cdots &amp; \frac{\partial f_2}{\partial x_n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial f_n}{\partial x_1} &amp; \frac{\partial f_n}{\partial x_2} &amp; \cdots &amp; \frac{\partial f_n}{\partial x_n} \end{bmatrix}\] <p>于是我们有迭代公式：</p> \[\boldsymbol{x}_{n+1}=\boldsymbol{x}_n-\mathsf{J}^{-1}(\boldsymbol{x}_n)\cdot\boldsymbol{f}(\boldsymbol{x}_n)\] <h2 id="interpolation">Interpolation</h2> <h3 id="polynomial-interpolation">Polynomial Interpolation</h3> <p>我们有一组点 \((x_0, y_0), (x_1, y_1), \cdots, (x_n, y_n)\)，我们要找一个多项式 \(\mathcal{P}(x)\) 使得 \(\mathcal{P}(x_i)=y_i\)。</p> <p>最直接的方法是解方程：</p> \[\boldsymbol{a}=\mathcal{V}^{-1}\boldsymbol{y}\] <p>其中 \(\mathcal{V}\) 是 Vandermonde matrix：</p> \[\mathcal{V}=\begin{bmatrix} 1 &amp; x_0 &amp; x_0^2 &amp; \cdots &amp; x_0^n \\ 1 &amp; x_1 &amp; x_1^2 &amp; \cdots &amp; x_1^n \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; x_n &amp; x_n^2 &amp; \cdots &amp; x_n^n \end{bmatrix}\] <p>复杂度 \(\mathcal{O}(n^3)\)。</p> <p>在历史上的话欧陆这边最有名的是 Lagrange 插值，以及 Newton 那边的 divided difference。</p> <p>Lagrange 插值是一种 \(\mathcal{O}(n^2)\) 的算法。</p> <p>我们想要的是构造一组基：</p> \[\mathcal{L}_{n, k}(x_i)=[i=k]\] <p>那我们就可以有：</p> \[\mathcal{P}_n(x)=\sum_{k=0}^n y_k\cdot \mathcal{L}_{n, k}(x)\] <p>而基的构造方式是：</p> \[\mathcal{L}_{n, k}(x)=\prod_{j\neq k}\frac{x-x_j}{x_k-x_j}\] <p>关于准确性我们用 Rolle 定理可以证明，对于 \((x_0, x_1, \cdots, x_n)\in[l, r]^n\)，如果 \(x\in[l, r]\)，我们有存在 \(\xi\in[l, r]\) 使得：</p> \[f(x)=\mathcal{P}_n(x)+\frac{f^{(n+1)}(\xi)}{(n+1)!}\prod_{i=0}^n(x-x_i)\] <p>接下来讲的是 Neville’s scheme，我们令 \(\mathcal{P}_{n-1, i}\) 表示用 \(x_0, x_1, \cdots, x_{i-1}, x_{i+1}, \cdots, x_n\) 插值出的多项式，我们有：</p> \[\mathcal{P}_n(x)=\frac{(x-x_j)\cdot\mathcal{P}_{n-1, j}(x)-(x-x_i)\cdot\mathcal{P}_{n-1, i}(x)}{x_i-x_j}\] <p>于是乎我们就能用这种方法进行 dp，令 \(\mathcal{P}_{l, r}(x)\) 表示通过 \(x_l, x_{l+1}, \cdots, x_r\) 插值出的多项式。我们就有：</p> \[\mathcal{P}_{l, r}(x)=\frac{(x-x_l)\cdot\mathcal{P}_{l+1, r}(x)-(x-x_r)\cdot\mathcal{P}_{l, r-1}(x)}{x_r-x_l}\] <p>这个做法的一个好处是可以在线性时间内增加一个点。</p> <p>另外一种方法叫做 Newton’s divided difference，我们定义：</p> \[\begin{aligned} f[x_i]&amp;=f(x_i) \\ f[x_i, x_{i+1}]&amp;=\frac{f[x_{i+1}]-f[x_i]}{x_{i+1}-x_i} \\ f[x_i, x_{i+1}, \cdots, x_{i+k}]&amp;=\frac{f[x_{i+1}, x_{i+2}, \cdots, x_{i+k}]-f[x_i, x_{i+1}, \cdots, x_{i+k-1}]}{x_{i+k}-x_i} \end{aligned}\] <p>我们有：</p> \[\mathcal{P}_n(x)=f[x_0]+\sum_{k=1}^n\left(f[x_0, x_1, \cdots, x_k]\cdot\prod_{j=0}^{k-1}(x-x_j)\right)\]]]></content><author><name>Pu Fanyi</name></author><category term="Notes"/><category term="Numerical Analysis"/><summary type="html"><![CDATA[Notes for NTU MH3700 Numerical Analysis I.]]></summary></entry><entry><title type="html">Maxwell’s Equations</title><link href="https://pufanyi.github.io/blog/Maxwell/" rel="alternate" type="text/html" title="Maxwell’s Equations"/><published>2024-04-26T00:00:00+00:00</published><updated>2024-04-26T00:00:00+00:00</updated><id>https://pufanyi.github.io/blog/Maxwell</id><content type="html" xml:base="https://pufanyi.github.io/blog/Maxwell/"><![CDATA[<p>要学不完了。</p> <p>简单记一点点。</p> <p>由于 MathJax 居然不支持多重的环积分，我下面所有的多重环积分全部用 \(\oint\) 来表示，能看懂就行。没时间调了啊啊啊啊啊啊啊啊啊来不及了要考试了啊啊啊啊啊啊啊啊</p> \[\iint_S\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\ \;\;\large{\subset\!\supset}\] <p>这样子打：</p> <div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\iint</span><span class="p">_</span>S<span class="k">\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\ \;\;\large</span><span class="p">{</span><span class="k">\subset\!\supset</span><span class="p">}</span>
</code></pre></div></div> <p>虽然有点抽象，但你就说打没打出来吧（</p> <hr/> <h2 id="gausss-law">Gauss’s Law</h2> \[\iint_S{\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\ \;\;\large{\subset\!\supset} \vec{E}\cdot\mathrm{d}\vec{A}} = \frac{\sum q}{\varepsilon_0}\] <p>这个 \(\varepsilon_0\) 其实是真空的电容率。</p> <p>直观理解就是每个电荷 \(q\) 能产生 \(\frac{q}{\varepsilon_0}\) 的电场线。</p> <p>他能推库仑定律，就是你考虑一个点电荷 \(q\) 为中心，半径为 \(r\) 的球面，表面积是 \(4\pi r^2\)，然后因为整个球是中心对称的，于是我们就有：</p> \[\left\|\vec{E}\right\|\cdot A = \iint_S{\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\ \;\;\large{\subset\!\supset} \vec{E}\cdot\mathrm{d}\vec{A}} = \frac{q}{\varepsilon_0}\] <p>于是乎：</p> \[\left\|\vec{E}\right\| = \frac{q}{4\pi r^2 \varepsilon_0}\] <p>如果不是真空，也就是如果有电解质（Dielectric，记住这个单词！！！）的话，就是你假设现在我有个平板电容中间是电解质。两个板子电荷密度分别为 \(\sigma_m\) 和 \(-\sigma_m\)。</p> <p>然后把电场加上之后，会发现中间的 dielectric 因为正负电子被拉开然后产生一个电场，可以认为是在这个 dielectric 的边缘出现了 \(-\sigma_D\) 和 \(\sigma_D\) 的电荷。其中：</p> \[\sigma_D=\varepsilon_0\chi_e E\] <p>然后这个 \(\chi_e\) 就叫 electric susceptibility（电极化率），跟 dielectric 有关的一个数。</p> <p>我们用用高斯定律就能得到一个：</p> \[\left\|\vec{E}\right\| = \frac{\sigma_m-\sigma_D}{\varepsilon_0}\] <p>然后我们跟上面的公式联立，就能得到：</p> \[\left\|\vec{E}\right\| = \frac{\sigma_m}{\varepsilon_0(1+\chi_e)}\] <p>于是乎：</p> \[V = \int \vec{E}\cdot\mathrm{d}\vec{l} = \frac{\sigma_md}{\varepsilon_0(1+\chi_e)}=\frac{Qd}{\varepsilon_0(1+\chi_e)A}\] <p>我们让：</p> \[C = \frac{\varepsilon_0 (1+\chi_e)A}{d}\] <p>就能得到：</p> \[V = \frac{Q}{C}\] <p>然后我们就推了一下平板电容的公式，而其中这东西的电容率就是 \(\varepsilon_0 (1+\chi_e)\)。</p> <p>然后我们考虑另一个结果就是其实我们就可以直接去认为电场穿过 dielectric 的时候，电场强度会变小，这个变小的倍数就是 \(1+\chi_e\)，于是乎我们可以改进一下这个方程：</p> \[\iint_S{\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\ \;\;\large{\subset\!\supset} \left(1+\chi_e\right)\vec{E}\cdot\mathrm{d}\vec{A}} = \frac{\sum q}{\varepsilon_0}\] <hr/> <h2 id="gausss-law-for-magnetism">Gauss’s Law for Magnetism</h2> <p>同样很好理解，毕竟磁感线一定是个闭环：</p> \[\iint_S{\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\ \;\;\large{\subset\!\supset}{\vec{B}\cdot\mathrm{d}\vec{A}}} = 0\] <hr/> <h2 id="faradays-law">Faraday’s Law</h2> <p>感应电动势等于磁通量的变化率：</p> \[\oint{\vec{E}\cdot\mathrm{d}\vec{\ell}} = -\frac{\mathrm{d}\Phi_B}{\mathrm{d}t}=-\frac{\mathrm{d}}{\mathrm{d}t}\iint_S{\vec{B}\cdot\mathrm{d}\vec{S}}\] <hr/> <h2 id="ampères-law-with-maxwells-addition">Ampère’s Law with Maxwell’s Addition</h2> <p>就首先我们需要说的是 Ampère’s Law：</p> \[\oint\vec{B}\mathrm{d}\vec{\ell} = \mu_0\sum I_\text{enc}\] <p>就和高斯定律很像的一个东西，其实就是每个 \(I\) 都会产生一个 \(\mu_0 I\) 的磁感线。</p> <p>这个东西如果在电流恒定的情况下是对的，然后可以推 Biot-Savart Law：</p> \[\vec{B} = \frac{\mu_0}{4\pi}\int\frac{I\cdot\mathrm{d}\vec{\ell}\times\hat{r}}{\left\|\vec{r}\right\|^2}\] <p>当然需要注意的是其中的 \(\hat{r}=\frac{\vec{r}}{\left\|\vec{r}\right\|}\)</p> <p>证明上课没讲有空再推。</p> <p>当然如果是单个粒子的话运动的话我们可以把 Biot-Savart Law 稍稍改一改：</p> \[\vec{B}=\frac{\mu_0}{4\pi}\cdot \frac{q\cdot\vec{v}\times\hat{r}}{\left\|\vec{r}\right\|^2}\] <p>然后这个东西其实有一点小问题，就是你假设有一个电容，在一开始充电的时候电容里面那部分是没有电流的，他其实是一个电场的改变，就我们可以把它当成电流，而这其实是电场的改变率。于是乎我们在公式里加个项就可以了：</p> \[\oint{\vec{E}\cdot\mathrm{d}\vec{l}} = \mu_0\sum I_\text{enc} + \mu_0\varepsilon_0\frac{\mathrm{d}}{\mathrm{d}t}\iint_S{\vec{E}\cdot\mathrm{d}\vec{A}}\] <p>当然 \(\iint_S{\vec{E}\cdot\mathrm{d}\vec{A}}\) 其实就是电通量的变化量了：</p> \[\oint{\vec{E}\cdot\mathrm{d}\vec{l}} = \mu_0\sum I_\text{enc} + \mu_0\varepsilon_0\frac{\mathrm{d}\Phi_E}{\mathrm{d}t}\] <details><summary>咋来的</summary> <p>就考虑到：</p> \[I = \frac{\mathrm{d}Q}{\mathrm{d}t}=\varepsilon_0\frac{\mathrm{d}}{\mathrm{d}t}\frac{Q}{\varepsilon_0}=\varepsilon_0\frac{\mathrm{d}}{\mathrm{d}t}\iint_S{\vec{E}\cdot\mathrm{d}\vec{A}}\] <p>于是乎我们有：</p> \[\oint\vec{E}\cdot\mathrm{d}\vec{l} = \mu_0\left(\sum I_\text{enc} + \varepsilon_0\frac{\mathrm{d}}{\mathrm{d}t}\iint_S\vec{E}\cdot\mathrm{d}\vec{A}\right)=\mu_0\sum I_\text{enc} + \mu_0\varepsilon_0\frac{\mathrm{d}}{\mathrm{d}t}\iint_S\vec{E}\cdot\mathrm{d}\vec{A}\] </details>]]></content><author><name>Pu Fanyi</name></author><category term="Notes"/><category term="Physics"/><category term="Electromagnetism"/><summary type="html"><![CDATA[学不完了学不完了学不完了啊啊啊啊啊啊啊啊啊啊啊]]></summary></entry><entry><title type="html">Statistics Notes</title><link href="https://pufanyi.github.io/blog/MH3500-Notes/" rel="alternate" type="text/html" title="Statistics Notes"/><published>2024-01-26T00:00:00+00:00</published><updated>2024-01-26T00:00:00+00:00</updated><id>https://pufanyi.github.io/blog/MH3500-Notes</id><content type="html" xml:base="https://pufanyi.github.io/blog/MH3500-Notes/"><![CDATA[<p>这学期学了门叫做 Statistics 的课，然后发现有点学不明白，所以记点笔记。</p> <p>除了上课听到的，应该还会记一些书里看到的和自己想到的。</p> <p>教材用的是这三本：<d-cite key="hogg2019introduction"></d-cite><d-cite key="rice2006mathematical"></d-cite><d-cite key="casella2021statistical"></d-cite></p> <p>2024 Spring 的课，lecturer 是 <a href="https://www.linkedin.com/in/kwee-poo-yeo-ph-d-2966a43">Yeo Kwee Poo</a> 老师，tutor 是 <a href="https://www.linkedin.com/in/mu-yue-4a5a7a33/">Mu Yue</a> 老师。</p> <p>应该会想到啥写啥，所以可能比较混乱。另外因为里面有一大堆我自己乱七八糟的想法，所以里面的东西不一定对。</p> <hr/> <h2 id="什么是-statistics">什么是 statistics</h2> <p>首先是 population, property, population distribution, random sample 这些名词，应该不用咋写。</p> <p>Static inference 是指用 sample 来推断整个 population 的性质。</p> <p>就是假设我们随机抽取了 \(n\) 个 sample \(\boldsymbol{x} = (x_1, x_2, \dots, x_n)\)。我们假设这个 \(\boldsymbol{x}\) 是由 \(\boldsymbol{X}=(X_1, X_2, \cdots, X_n)\) 生成的。我们称 \(x_1, x_2, \dots, x_n\) are the realizations of i.i.d. random variables \(X_1, X_2, \dots, X_n\)。也称 \(x_1, x_2, \dots, x_n\) are observations of \(X_1, X_2, \dots, X_n\)。</p> <p>而 statistic 事实上指的是 a real valued function, \(T(X_1, X_2, \dots, X_n)\)。需要注意的是，这个 function 之和 \(X_1, X_2, \dots, X_n\) 有关，而不是 \(x_1, x_2, \dots, x_n\)。</p> <p>然后 the distribution of a statistic is called a sampling distribution。也就是说，sampling distribution 是很多变量的 distribution，而 population 只是一个变量的 distribution。</p> <p>Sample mean 是 \(\overline{X} = \frac{1}{n} \sum_{i=1}^n X_i\)，sample variance 是 \(S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2\)。</p> <details><summary>为什么是 \(\frac{1}{n-1}\)</summary> <p>感性理解是，你这 \(n\) 个东西的平均值，事实上是根据这 \(n\) 个东西的“趋向”有一定偏移的。就比如说我现在有一个 \(\mathcal{N}(0, 1)\)，我取两个 sample，假设拿到了 \(x_1=-1, x_2=2\)，这个时候他的 $\overline{X}$ 其实不是 \(0\)，而是 \(\frac{1}{2}\)，也就是被往右边拉过去了一点的。这时候如果我们用 \(\frac{1}{n}\) 计算，那事实上算出来的值应该是偏小的（因为这里的 \(\overline{X}\) 根据样本的抽取结果“调整”了一下）。而 \(\frac{1}{n-1}\) 正好抵消了这一点。</p> <p>下面是严格的数学证明。</p> <p>我们有 \(\mathbb{E}(S^2)=\sigma^2\)。</p> <p>我们考虑 \(\mathbb{E}(S^2)=\frac{1}{n-1}\sum_{i-1}^n\mathbb{E}\left[(X_i-\overline{X})^2\right]\)，于是我们考虑计算 \(\mathbb{E}\left[(X_i-\overline{X})^2\right]\)：</p> \[\begin{aligned} \mathbb{E}\left[\left(X_i-\overline{X}\right)^2\right] &amp;= \mathbb{E}\left[\left((X_i-\mu)-(\overline{X}-\mu)\right)^2\right] \\ &amp;= \mathbb{E}\left[(X_i-\mu)^2+(\overline{X}-\mu)^2-2(X_i-\mu)(\overline{X}-\mu)\right]\\ &amp;=\mathbb{E}\left[(X_i-\mu)^2\right]+\mathbb{E}\left[(\overline{X}-\mu)^2\right]-2\mathbb{E}\left[(X_i-\mu)(\overline{X}-\mu)\right]\\ &amp;=\mathrm{Var}(X_i)+\mathrm{Var}(\overline{X})-2\cdot\mathrm{Cov}(X_i,\overline{X})\\ &amp;=\sigma^2+\mathrm{Var}\left(\frac{1}{n}\sum_{j=1}^nX_j\right)-2\cdot\mathrm{Cov}\left(X_i,\frac{1}{n}\sum_{j-1}^nX_j\right)\\ &amp;=\sigma^2+\frac{1}{n^2}\sum_{j=1}^n\mathrm{Var}(X_j)-\frac{2}{n}\mathrm{Cov}(X_i,X_i)\\ &amp;=\sigma^2+\frac{1}{n}\sigma^2-\frac{2}{n}\sigma^2\\ &amp;=\frac{n-1}{n}\sigma^2 \end{aligned}\] <p>于是我们有 \(\mathbb{E}(S^2)=\frac{1}{n-1}\sum_{i-1}^n\mathbb{E}\left[(X_i-\overline{X})^2\right]=\frac{1}{n-1}\sum_{i-1}^n\frac{n-1}{n}\sigma^2=\sigma^2\)。</p> </details> <p>有一个好玩的性质是 如果 \(X_i\sim \mathcal{N}(\mu, \sigma^2)\) 的话，\(\overline{X}\) 和 \(S^2\) 是独立的。上课老师讲了中方法但我有点没搞懂，Rice 书里有一个证法，感觉清楚一些。</p> <details><summary>上课老师讲的证法</summary> <p>其实我至今没搞懂他到底是咋搞的。因为他用了一个结论，就是两个协方差为 \(0\) 的 normal distribution 是相互独立的。不是很清楚不用 MGF 这玩意儿还能咋证（用 MGF 的话，那还不如 Rice 的证法呢）。</p> <p>当然如果这玩意儿是成立的，那就好办了。就是毕竟我们是知道 \(\overline{X}\sim N\left(\mu, \frac{\sigma^2}{n}\right)\)，然后 \(X_i-\overline{X}\sim \mathcal{N}\left(0, \sigma^2\right)\) 的。那我们只要搞出他俩的 covariance 就行了。</p> <p>那我们算算：</p> \[\begin{aligned} \mathrm{Cov}\left(\overline{X}, X_i-\overline{X}\right)&amp;=\mathrm{Cov}\left(\overline{X},X_i\right)-\mathrm{Cov}\left(\overline{X},\overline{X}\right)\\ &amp;=\mathrm{Cov}\left(\frac{1}{n}\sum_{j=1}^nX_j,X_i\right)-\frac{\sigma^2}{n}\\ &amp;=\frac{1}{n}\mathrm{Cov}\left(X_i, X_i\right)-\frac{\sigma^2}{n}\\ &amp;=\frac{\sigma^2}{n}-\frac{\sigma^2}{n}\\ &amp;=0 \end{aligned}\] <p>然后他们就独立了。</p> </details> <details><summary>Rice Book 的证法</summary> <p>考虑到 \(S^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2\)，我们其实只要证明 \(\overline{X}\) 和 \(X_i-\overline{X}\) 是独立的就可以了。</p> <p>首先我们需要知道一件事情，就是假设有一个 \(r\)，使得：</p> \[M_{\boldsymbol{X}}(\boldsymbol{t})=M_{\boldsymbol{X}}(t_1, t_2, \dots, t_r, 0, \dots, 0)\cdot M_{\boldsymbol{X}}(0, \dots, 0, t_{r+1}, t_{r+2}, t_n)\] <p>那么 \((t_1, t_2, \cdots, t_r)\) 和 \((t_{r+1}, t_{r+2}, \dots, t_n)\) 是独立的。</p> <p>这个证明是假设我们随机两次，第一次是 \(\boldsymbol{X}\)，第二次是 \(\boldsymbol{\widetilde{X}}\)。我们考虑：</p> \[Y=(X_1, \dots, X_r, \widetilde{X}_{r+1}, \dots, \widetilde{X}_{n})\] <p>由于 \(\boldsymbol{X}\) 和 \(\boldsymbol{\widetilde{X}}\) 是独立的，所以我们有：</p> \[M_{\boldsymbol{Y}}(\boldsymbol{t})=M_{\boldsymbol{X}}(t_1, t_2, \dots, t_r, 0, \dots, 0)\cdot M_{\boldsymbol{\widetilde{X}}}(0, \dots, 0, t_{r+1}, t_{r+2}, t_n)\] <p>而又因为 \(\boldsymbol{X}\) 和 \(\boldsymbol{\widetilde{X}}\) 其实是一样的，\(M_{\boldsymbol{X}}(\boldsymbol{t})=M_{\boldsymbol{\widetilde{X}}}(\boldsymbol{t})\)，也就是说：</p> \[M_{\boldsymbol{Y}}(\boldsymbol{t})=M_{\boldsymbol{X}}(t_1, t_2, \dots, t_r, 0, \dots, 0)\cdot M_{\boldsymbol{X}}(0, \dots, 0, t_{r+1}, t_{r+2}, t_n)\] <p>也就是 \(M_{\boldsymbol{X}}=M_{\boldsymbol{Y}}\)，也就是对于任意集合 \(A_1, A_2, \dots, A_n\)，我们有：</p> \[\begin{aligned} &amp;\mathbb{P}\left\{(X_1\in A_1)\land (X_2\in A_2)\land\dots\land (X_n\in A_n)\right\}\\ =\ &amp;\mathbb{P}\left\{(X_1\in A_1)\land \dots\land(X_r\in A_r)\land\left(\widetilde{X}_{r+1}\in A_{r+1}\right)\land\dots\land\left(\widetilde{X}_{n}\in A_n\right)\right\}\\ =\ &amp;\mathbb{P}\left\{(X_1\in A_1)\land \dots\land(X_r\in A_r)\right\}\cdot\mathbb{P}\left\{\left(\widetilde{X}_{r+1}\in A_{r+1}\right)\land\dots\land\left(\widetilde{X}_{n}\in A_n\right)\right\} \end{aligned}\] <p>所以我们令 \(\boldsymbol{\widehat{X}}=\left(\overline X, X_1-\overline{X}, \dots, X_n-\overline{X}\right)\)，\(\boldsymbol{\widehat{t}}=(s, t_1, t_2,\dots, t_n)\)。</p> <p>考虑到 \(X_1-\overline{X}, X_2-\overline{X},\dots,X_n-\overline{X}\) 这些玩意儿的独立性是显然的，所以其实我们要证明的就是：</p> \[M_{\boldsymbol{\widehat{X}}}\left(\boldsymbol{\widehat{t}}\right)=M_{\overline{X}}(s, 0, \dots, 0)\cdot M_{\boldsymbol{X}-\overline{X}}(0, t_1, \dots, t_n)\] <p>然后我们接下来想做的是能不能把 \(M_{\widehat{\boldsymbol{X}}}(\widehat{\boldsymbol{t}})\) 和 \(M_{\boldsymbol{X}}(\boldsymbol{a})\) 联系起来。</p> <p>为啥要这样转化呢？因为虽然我们现在不知道 \(\widehat{\boldsymbol{X}}\) 的独立性，但是 \(\boldsymbol{X}\) 的精神状态咋样我们是知道的。这样我们就能通过 \(\boldsymbol{X}\) 把整个 MGF 给拆解开来，从而计算这个 MGF 到底是啥。</p> <p>我们是这样做的：</p> \[\begin{aligned} M_{\boldsymbol{\widehat{X}}}\left(\boldsymbol{\widehat{t}}\right)&amp;=\mathbb{E}\left[\exp\left({\widehat{\boldsymbol{X}}^\mathrm{T}\widehat{\boldsymbol{t}}}\right)\right]\\ &amp;=\mathbb{E}\left[\exp\left({s\overline{X}+\sum_{i=1}^nt_i\left(X_i-\overline{X}\right)}\right)\right]\\ &amp;=\mathbb{E}\left[\exp\left(\frac{s}{n}\sum_{i=1}^nX_i+\sum_{i=1}^nt_iX_i-\left(\sum_{i=1}^nt_i\right)\cdot\left(\frac{1}{n}\cdot\sum_{i=1}^nX_i\right)\right)\right]\\ &amp;=\mathbb{E}\left[\exp\left(\sum_{i=1}^n\left(\frac{s}{n}+t_i-\overline{t}\right)X_i\right)\right] \end{aligned}\] <p>于是乎我们就可以令 \(a_i=\frac{s}{n}+t_i-\overline{t}\)，于是我们就有：</p> \[M_{\boldsymbol{\widehat{X}}}\left(\boldsymbol{\widehat{t}}\right)=M_{\boldsymbol{X}}\left(\boldsymbol{a}\right)\] <p>然后我们就能根据 \(\boldsymbol{X}\) 的独立性把 \(M_{\boldsymbol{X}}\left(\boldsymbol{a}\right)\) 拆开来了：</p> \[\begin{aligned} M_{\boldsymbol{\widehat{X}}}\left(\boldsymbol{\widehat{t}}\right)&amp;=M_{\boldsymbol{X}}\left(\boldsymbol{a}\right)\\ &amp;=\prod_{i=1}^nM_{X_i}\left(a_i\right)\\ &amp;=\prod_{i = 1}^n\exp\left(\mu a_i+\frac{1}{2}\sigma^2a_i^2\right)\\ &amp;=\exp\left(\mu\sum_{i=1}^na_i+\frac{\sigma^2}{2}\sum_{i=1}^na_i^2\right) \end{aligned}\] <p>考虑到：</p> \[\begin{aligned} \sum_{i=1}^na_i&amp;=\sum_{i=1}^n\left(\frac{s}{n}+t_i-\overline{t}\right)\\ &amp;=s+\sum_{i=1}^nt_i-n\overline{t}\\ &amp;=s\\ \sum_{i=1}^na_i^2&amp;=\sum_{i=1}^n\left(\frac{s}{n}+t_i-\overline{t}\right)^2\\ &amp;=\sum_{i=1}^n\left(\left(\frac{s}{n}\right)^2+2\cdot\frac{s}{n}\left(t_i-\overline t\right)+\left(t_i-\overline{t}\right)^2\right)\\ &amp;=\frac{s^2}{n}+\sum_{i=1}^n\left(t_i-\overline{t}\right)^2 \end{aligned}\] <p>于是我们就有：</p> \[\begin{aligned} M_{\boldsymbol{\widehat{X}}}\left(\boldsymbol{\widehat{t}}\right)&amp;=\exp\left(\mu\sum_{i=1}^na_i+\frac{\sigma^2}{2}\sum_{i=1}^na_i^2\right)\\ &amp;=\exp\left(\mu s+\frac{\sigma^2}{2}\left(\frac{s^2}{n}+\sum_{i=1}^n\left(t_i-\overline{t}\right)^2\right)\right)\\ &amp;=\exp\left(\mu s+\frac{\sigma^2}{2}\frac{s^2}{n}+\frac{\sigma^2}{2}\sum_{i=1}^n\left(t_i-\overline{t}\right)^2\right)\\ &amp;=\exp\left(\mu s+\frac{1}{2}\cdot\frac{\sigma^2}{n}s^2\right)\cdot\prod_{i=1}^n\exp\left(\frac{\sigma^2}{2}\left(t_i-\overline{t}\right)^2\right) \end{aligned}\] <p>酱紫我们就已经把 \(M_{\boldsymbol{\widehat{X}}}\left(\boldsymbol{\widehat{t}}\right)\) 给算出来了。简单算算就能发现</p> \[M_{\boldsymbol{\widehat{X}}}\left(\boldsymbol{\widehat{t}}\right)=M_{\overline{X}}(s, 0, \dots, 0)\cdot M_{\boldsymbol{X}-\overline{X}}(0, t_1, \dots, t_n)\] <p>这玩意儿是成立的。于是我们就证完了。</p> </details> <p>接下来我们讨论的是数据的分类。对于一个 variable，根据以下的方式分个类：</p> <p><img src="/assets/svg/2024-01-26-MH3500-Notes/variable_class.svg" alt=""/></p> <hr/> <h2 id="summarizing-data">Summarizing Data</h2> <p>首先 Mean，Median，Mode 就不说了。</p> <p>Skewness 说的是数据往哪儿偏，其实就是 standardize 之后的 3rd moment：</p> \[\gamma_1=\frac{\mathbb{E}[(X-\mu)^3]}{\sigma^3}= \frac{\mathbb{E}[(X-\mu)^3]}{\mathbb{E}[(X-\mu)^2]^{3/2}}\] <details><summary>不同 skewness 的图像</summary> <div class="l-page"> <iframe src="/assets/plotly/2024-01-26-MH3500-Notes/distributions/skewness.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> </details> <p>其中尾巴在左边的（\(\gamma_1&lt;0\)）就叫 left-skewed，尾巴在右边的（\(\gamma_1&gt;0\)）就叫 right-skewed。</p> <details><summary>\(\log\) and \(\exp\) transformation</summary> <p>说一下我傻傻分不清的 \(\log\) 和 \(\exp\) transformation。</p> <p>考虑到 \(\log\) 函数是前面陡后面平的，他把左边那段的尾巴给拉长了。所以假如说 \(X\sim\mathcal{N}(\mu, \sigma^2)\) 的话，那么 \(\log X\) 他就是一个 left-skewed 的。同样的考虑到 \(\exp\) 是后面比较陡，所以他把右边那一段给拉长了，于是 \(\exp X\) 是 right-skewed 的。</p> </details> <p>接着是 trimmed mean，就是我们比赛的时候看到的那种去掉最高分最低分的感觉。为啥要用 trimmed mean 捏？感性来讲的话，就是我们考虑到 mean 是很容易受到极端情况影响的，而 median 不会。但是 median 又没法反应整体情况。那办法就是去掉一些极端情况，因为其实 median 就是 trim 掉 \(0.5\) 的 mean 嘛。</p> <p>如果想更理性一点说的话。就是我们要考虑一个叫做 standard error 的东西。就是为啥咱有些时候不去 trim 捏？因为假设这个 distribution 是 normal distribution 的话，其实 trim 掉是比较亏的。就是我们考虑在做 normal distribution 的时候，所观测到 mean 和 median 的 standard error 是多少。考虑到 mean 其实就是 \(\mathcal{N}(\mu, \frac{\sigma^2}{n})\)，而 median 其实是 \(\mathcal{N}(\mu, \frac{\pi}{2}\cdot\frac{\sigma^2}{n})\)。所以其实我们是可以通过 mean 和 median 的 standard error 来判断我们是不是要 trim 的。</p> <hr/> <h2 id="from-normal-distribution">From Normal Distribution</h2> <p>第一个需要讨论的是 Chi Square Distribution。就是我现在有 \(n\) 个 i.i.d. \(\mathcal{N}(0, 1)\) 的 random variables，\(X_1, X_2, \dots, X_n\)，我们定义 \(Z=\sum_{i=1}^nX_i^2 \sim \chi^2_n\)。</p> <p>那就是我们咋计算这个 \(\chi^2_n\) 呢，因为显然我们发现 \(\chi^2_n\) 其实是 \(n\) 个 \(\chi^2_1\) 的和，所以我们第一件事就是计算 \(\chi^2_1\)。</p> <p>这个好算，我们假设 \(Y\sim \mathcal{N}(0, 1), X=Y^2\)，那么 \(X\sim \chi_1^2\)：</p> \[\begin{aligned} F_X(x)&amp;=\mathbb{P}(X\leq x)\\ &amp;=\mathbb{P}(Y^2\leq x)\\ &amp;=\mathbb{P}(-\sqrt{x}\leq Y\leq\sqrt{x})\\ &amp;=\Phi(\sqrt{x})-\Phi(-\sqrt{x})\\ &amp;=2\Phi(\sqrt{x})-1 \end{aligned}\] <p>然后我们两边求个到得到 PDF：</p> \[\begin{aligned} f_X(x)&amp;=\frac{\mathrm{d}F_X(x)}{\mathrm{d}x}\\ &amp;=2\phi(\sqrt{x})\cdot\frac{1}{2\sqrt{x}}\\ &amp;=\frac{1}{\sqrt{x}}\cdot\frac{1}{\sqrt{2\pi}}e^{-\frac{x}{2}}\\ &amp;=\frac{1}{\sqrt{2\pi x}}e^{-\frac{x}{2}} \end{aligned}\] <p>然后就发现其实这玩意儿就是 \(\mathrm{Gamma}\left(\frac{1}{2}, 2\right)\)。</p> <p>而考虑到 \(n\) 个 \(\chi_1^2\) 相加，那就是 \(n\) 个 \(\mathrm{Gamma}\left(\frac{1}{2}, 2\right)\) 相加，也就是 \(\mathrm{Gamma}\left(\frac{n}{2}, 2\right)\)。</p> <details><summary>不同自由度的 Chi Square Distribution</summary> <div class="l-page"> <iframe src="/assets/plotly/2024-01-26-MH3500-Notes/distributions/chi_square.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> </details> <details><summary>Gamma Distribution</summary> <p>写到这里的时候发现一些 Gamma Distribution 的细节已经给忘光光了。</p> <p>首先需要复习的是 Gamma Distribution 的引入。他主要是想要推广 exponential distribution。就是我们想知道第 \(n\) 次发生事情的时候，我们需要等多久。</p> <p>我们是通过 Poisson Distribution 推下来的。就是我们考虑这个新 distribution 的 CDF \(F(t)\)，其实表示的是在 \(1\sim t\) 这段时间里要发生大于等于 \(n\) 次。于是我们有：</p> \[F(t)=\sum_{k=n}^\infty\frac{(\lambda t)^ke^{-\lambda t}}{k!}\] <p>那么我们就能轻松得到他的 PDF：</p> \[\begin{aligned} f(t)&amp;=\frac{\mathrm{d}F(t)}{\mathrm{d}t}\\ &amp;=\sum_{k=n}^{\infty}\frac{k\lambda^kt^{k-1}e^{-\lambda t}-\lambda^{k+1}t^ke^{-\lambda t}}{k!}\\ &amp;=e^{-\lambda t}\left(\sum_{k=n}^\infty\frac{\lambda^k t^{k-1}}{(k-1)!}-\sum_{k=n}^\infty\frac{\lambda^{k+1}t^k}{k!}\right)\\ &amp;=e^{-\lambda t}\left(\sum_{k=n-1}^{\infty}\frac{\lambda^{k+1}t^k}{k!}-\sum_{k=n}^\infty\frac{\lambda^{k+1}t^k}{k!}\right)\\ &amp;=e^{-\lambda t}\cdot\frac{\lambda^nt^{n-1}}{(n-1)!} \end{aligned}\] <p>然后我们将 \((n-1)!\) 推广成 \(\Gamma(n)=\int_{0}^{+\infty} x^{n-1}e^{-x}\mathrm{d}x\)，就得到了 Gamma Distribution 的 PDF：</p> \[f(t)=\frac{\lambda^n}{\Gamma(n)} t^{n-1}e^{-\lambda t}\] <p>不过上课的时候老师比较习惯用 \(\Gamma(\alpha,\beta)\) 来表示，也就是 \(\beta=\frac{1}{\lambda}\)，于是乎 PDF 就变成了：</p> \[f(t)=\frac{t^{\alpha-1}e^{-\frac{t}{\beta}}}{\beta^\alpha\Gamma(\alpha)}\] <p>一个有趣的性质就是 Gamma Distribution 的 \(n\) 阶矩：</p> \[\begin{aligned} \mathbb{E}(X^n)&amp;=\int_{0}^{+\infty}x^nf(x)\mathrm{d}x\\ &amp;=\int_0^{+\infty}x^n\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x}\mathrm{d}x\\ &amp;=\frac{\lambda^\alpha}{\Gamma(\alpha)}\int_0^{+\infty}x^{n+\alpha-1}\cdot\frac{1}{-\lambda}\cdot\mathrm{d}\left(e^{-\lambda x}\right)\\ &amp;=-\frac{\lambda^{\alpha-1}}{\Gamma(\alpha)}\left(\left.x^{n+\alpha-1}e^{-\lambda x}\right|_0^{+\infty}-\int_0^{+\infty}e^{-\lambda x}\cdot\mathrm{d}\left(x^{n+\alpha-1}\right)\right)\\ &amp;=\frac{\lambda^{\alpha-1}}{\Gamma(\alpha)}\int_0^{+\infty}e^{-\lambda x}\cdot(n+\alpha-1)x^{n+\alpha-2}\mathrm{d}x\\ &amp;=\frac{n+\alpha-1}{\lambda}\int_{0}^{+\infty}x^{n-1}\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{}e^{-\lambda x}\mathrm{d}x\\ &amp;=\frac{n+\alpha-1}{\lambda}\mathbb{E}(X^{n-1}) \end{aligned}\] <p>而 \(\mathbb{E}(X^{0})=1\)，所以</p> \[\begin{aligned} \mathbb{E}(X^n)&amp;=\frac{1+\alpha-1}{\lambda}\cdot\frac{2+\alpha-1}{\lambda}\cdots\frac{n+\alpha-1}{\lambda}\\ &amp;=\frac{\alpha^{\overline{n}}}{\lambda^n} =\frac{\Gamma(n+\alpha)}{\Gamma(\alpha)\lambda^n} \end{aligned}\] <p>下面是一点小小的想法，就是这个 Gamma Function 是咋来的。其实就是考虑我们要把 \(n\) 拓展到实数 \(\alpha\)，那么我们是必须要保证 \(\int_{0}^{+\infty}e^{-\lambda t}\cdot\frac{\lambda^\alpha t^{\alpha-1}}{\Gamma(\alpha)}=1\)。于是我们就可以得到：</p> \[\Gamma(\alpha)=\int_{0}^{+\infty}e^{-\lambda t}\lambda^\alpha t^{\alpha-1}\mathrm{d}t\] <p>而我们要的 \(\Gamma(\alpha)\) 是想和 \(\lambda\) 无关的，这时候我们考虑换元：</p> \[\begin{aligned} \Gamma(\alpha)&amp;=\int_{0}^{+\infty}e^{-\lambda t}\lambda^\alpha t^{\alpha-1}\mathrm{d}t\\ &amp;=\int_{0}^{+\infty}e^{-(\lambda t)}(\lambda t)^{\alpha-1}\mathrm{d}(\lambda t)\\ &amp;=\int_{0}^{+\infty}e^{-x}x^{\alpha-1}\mathrm{d}x \end{aligned}\] <p>于是我们就得到了一个能够拟合 \((n-1)!\) 的 Gamma 函数。</p> <p>下面是不同 \(\alpha\) 和 \(\beta\) 的 Gamma Distribution 的图像：</p> <div class="l-page"> <iframe src="/assets/plotly/2024-01-26-MH3500-Notes/distributions/gamma_distribution_change_alpha.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> <div class="l-page"> <iframe src="/assets/plotly/2024-01-26-MH3500-Notes/distributions/gamma_distribution_change_beta.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> </details> <p>接着我们要讨论的是当 \(X_1, X_2, \dots, X_n\sim \mathcal{N}(\mu, \sigma^2)\) 时，\(S^2\) 的分布和 Chi-Square Distribution 的关系：</p> \[\frac{(n-1)S^2}{\sigma^2}\sim \chi_{n-1}^2\] <details><summary>证明</summary> <p>首先我们需要观察到的是：</p> \[\sum_{i=1}^n\left(\frac{X_i-\mu}{\sigma}\right)^2\sim\chi^2_n\] <p>接着我们考虑通过 \(\left(X_i-\mu\right)^2\) 来得到 \(\left(X_i-\overline{X}\right)^2\)：</p> \[\begin{aligned} \sum_{i=1}^n\left(\frac{X_i-\mu}{\sigma}\right)^2&amp;=\frac{1}{\sigma^2}\sum_{i=1}^n\left(\left(X_i-\overline{X}\right)+\left(\overline{X}-\mu\right)\right)^2\\ &amp;=\frac{1}{\sigma^2}\sum_{i=1}^n\left(X_i-\overline{X}\right)^2+\frac{2}{\sigma^2}\sum_{i=1}^n\left(X_i-\overline{X}\right)\left(\overline{X}-\mu\right)+\frac{1}{\sigma^2}\sum_{i=1}^n\left(\overline{X}-\mu\right)^2\\ &amp;=\frac{1}{\sigma^2}\sum_{i=1}^n\left(X_i-\overline{X}\right)^2+\frac{2}{\sigma^2}\left(\overline{X}-\mu\right)\sum_{i=1}^n\left(X_i-\overline{X}\right)+\frac{n}{\sigma^2}\left(\overline{X}-\mu\right)^2\\ &amp;=\frac{1}{\sigma^2}\sum_{i=1}^n\left(X_i-\overline{X}\right)^2+\left(\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\right)^2 \end{aligned}\] <p>然后我们发现其实他是一个 \(W=U+V\) 的形式，其中 \(W=\sum_{i=1}^n\left(\frac{X_i-\mu}{\sigma}\right)^2\sim \chi_n^2\)，\(V=\left(\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\right)^2\sim \chi_1^2\)，我们唯一不知道也是想要知道的是 \(U=\frac{1}{\sigma^2}\sum_{i=1}^n\left(X_i-\overline{X}\right)^2=\frac{(n-1)S^2}{\sigma^2}\)。</p> <p>由于 \(X_i-\overline{X}\) 和 \(\overline{X}\) 是独立的，于是 \(U\) 和 \(V\) 也是独立的。于是我们有：</p> \[M_W(t)=M_U(t)\cdot M_V(t)\] <p>那我们很容易解出：</p> \[\begin{aligned} M_U(t)&amp;=\frac{M_W(t)}{M_v(t)}\\ &amp;=\frac{(1-2t)^{-\frac{n}{2}}}{(1-2t)^{-\frac{1}{2}}}\\ &amp;=(1-2t)^{-\frac{n-1}{2}} \end{aligned}\] <p>也就是</p> \[\frac{(n-1)S^2}{\sigma^2}\sim \chi_{n-1}^2\] <p>于是就证完了。</p> </details> <p>接下来是 \(t\) distribution。Motivation 是这样的，我们现在还是有 \(n\) 个 i.i.d. \(\mathcal{N}(\mu, \sigma^2)\) 的 random variables，\(X_1, X_2, \dots, X_n\)。我们知道 \(\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\sim \mathcal{N}(0, 1)\)，我们现在想知道的是 \(Z=\frac{\overline{X}-\mu}{S/\sqrt{n}}\) 的 distribution 长啥样。</p> <p>我们考虑：</p> \[Z=\frac{\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}}{\sqrt{\frac{(n-1)S/\sigma^2}{n-1}}}=\frac{C}{\sqrt{D/(n-1)}}\] <p>我们发现 \(C=\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\sim \mathcal{N}(0, 1)\)，\(D=\frac{(n-1)S}{\sigma^2}\sim \chi_{n-1}^2\)，而且 \(C\) 和 \(D\) 是独立的。</p> <p>于是我们就这样考虑定义一个新的 distribution：</p> \[t_k=\frac{C}{\sqrt{D_k/k}}\] <p>其中 \(C\sim \mathcal{N}(0, 1)\)，\(D_k\sim \chi_k^2\) 且 \(C\) 和 \(D_k\) 是独立的。</p> <p>于是我们有：</p> \[\frac{\overline{X}-\mu}{S/\sqrt{n}}\sim t_{n-1}\] <p>而我们知道在 \(n\) 越来越大的时候，\(S\) 是越来越趋向于 \(\sigma\) 的，也就是说当 \(n\) 变大的时候，\(t_{n}\) 会越来越像 \(\mathcal{N}(0, 1)\)。</p> <details><summary>不同自由度的 \(t\) Distribution</summary> <div class="l-page"> <iframe src="/assets/plotly/2024-01-26-MH3500-Notes/distributions/t_distribution.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> </details> <p>接下来是 \(t_n\) 的表达式，我们有：</p> \[f_T(t)=\frac{\Gamma\left(\frac{n+1}{2}\right)}{\sqrt{n\pi}\cdot\Gamma\left(\frac{n}{2}\right)}\left(1+\frac{t^2}{n}\right)^{-\frac{n+1}{2}}\] <details><summary>证明</summary> <p>首先一个需要解决的小问题就是我们需要知道俩随机变量是咋除的。</p> <p>我们考虑现在有俩独立的随机变量 \(X, Y\)，然后我们考虑 \(Z = \frac{X}{Y}\)。</p> <p>我们考虑：</p> \[\begin{aligned} F_Z(z)&amp;=\mathbb{P}(Z\leq z)\\ &amp;=\mathbb{P}\left(\frac{X}{Y}\leq z\right)\\ &amp;=\mathbb{P}\left(X\geq zY\land Y&lt;0\right)+\mathbb{P}\left(X\leq zY\land Y&gt;0\right)\\ &amp;=\int_{-\infty}^{0}\mathbb{P}(X\ge zy)f_Y(y)\mathrm{d}y+\int_{0}^{+\infty}\mathbb{P}(X\le zy)f_Y(y)\mathrm{d}y\\ &amp;=\int_{-\infty}^0\left(\int_{zy}^{+\infty}f_X(x)\mathrm{d}x\right)f_{Y}(y)\mathrm{d}y+\int_{0}^{+\infty}\left(\int_{-\infty}^{zy}f_X(x)\mathrm{d}x\right)f_Y(y)\mathrm{d}y \end{aligned}\] <p>于是我们可以通过两边求导得到 \(f_Z(z)\)：</p> \[\begin{aligned} f_Z(z)&amp;=\frac{\mathrm{d}F_Z(z)}{\mathrm{d}z}\\ &amp;=\int_{-\infty}^0\left(-y\cdot f_{X}(zy)\right)\cdot f_Y(y)\mathrm{d}y+\int_{0}^{+\infty}\left(y\cdot f_{X}(zy)\right)\cdot f_Y(y)\mathrm{d}y\\ &amp;=\int_{-\infty}^{+\infty}|y|\cdot f_X(zy)\cdot f_Y(y)\mathrm{d}y \end{aligned}\] <p>于是乎我们就能通过这玩意儿来说明 \(t_k\) 是啥。</p> <p>当然在此之前我们先把 \(\sqrt{D_n/n}\) 的 PDF 给求出来。</p> <p>我们考虑到：</p> \[\begin{aligned} F_{\sqrt{D_n/n}}(t)&amp;=\mathbb{P}\left(\sqrt{\frac{D_n}{n}}\leq t\right)\\ &amp;=\mathbb{P}\left(-nt^2\le D_n\leq nt^2\right)\\ &amp;=\int_{-nt^2}^{nt^2}f_{D_n}(x)\mathrm{d}x\\ &amp;=\int_{0}^{nt^2}\frac{x^{\frac{n}{2}-1}e^{-\frac{x}{2}}}{2^{\frac{n}{2}}\Gamma\left(\frac{n}{2}\right)}\mathrm{d}x\\ &amp;=\frac{1}{2^{\frac{n}{2}}\Gamma\left(\frac{n}{2}\right)}\int_{0}^{nt^2}x^{\frac{n}{2}-1}e^{-\frac{x}{2}}\mathrm{d}x \end{aligned}\] <p>然后我们对两边求个导：</p> \[\begin{aligned} f_{\sqrt{D_n/n}}(t)&amp;=\frac{\mathrm{d}F_{\sqrt{D_n/n}}(t)}{\mathrm{d}t}\\ &amp;=\frac{1}{2^{\frac{n}{2}}\Gamma\left(\frac{n}{2}\right)}\cdot 2nt\cdot (nt^2)^{\frac{n}{2}-1}e^{-\frac{nt^2}{2}}\\ &amp;=\frac{n^{\frac{n}{2}}{t}^{n-1}e^{-\frac{nt^2}{2}}}{2^{\frac{n}{2}-1}\Gamma\left(\frac{n}{2}\right)} \end{aligned}\] <p>当然是 \(t\ge 0\) 的时候，当 \(t&lt;0\) 的时候就是 \(0\) 了。</p> <p>然后我们带入公式得到 \(f_{T}(t)\)：</p> \[\begin{aligned} f_T(t)&amp;=\int_{-\infty}^{+\infty}|y|\cdot f_{C}(ty)\cdot f_{\sqrt{D_k/k}}(y)\mathrm{d}y\\ &amp;=\int_{0}^{+\infty}y\cdot\frac{1}{\sqrt{2\pi}}e^{-\frac{(ty)^2}{2}}\cdot\frac{k^{\frac{k}{2}}{y}^{k-1}e^{-\frac{ky^2}{2}}}{2^{\frac{k}{2}-1}\Gamma\left(\frac{k}{2}\right)}\mathrm{d}y\\ &amp;=\frac{k^{\frac{k}{2}}}{\sqrt{2\pi}\cdot 2^{\frac{k}{2}-1}\cdot \Gamma\left(\frac{k}{2}\right)}\int_{0}^{+\infty}y^ke^{-\frac{(k+t^2)y^2}{2}}\mathrm{d}y \end{aligned}\] <p>我们发现这个后面那个积分式子特别像 \(\Gamma\) 函数，于是我们来凑一凑。考虑到 \(\Gamma\) 函数中 \(e\) 那边是个 \(e^{-t}\) 的形式，那么就换个元。为了方便书写我们假设 \(\alpha=\frac{k+t^2}{2}\)，\(u=\alpha y^2\)。</p> <p>于是乎我们就有：</p> \[\begin{aligned} \int_{0}^{+\infty}y^ke^{-\frac{(k+t^2)y^2}{2}}\mathrm{d}y&amp;=\int_{0}^{+\infty}\left(\frac{u}{\alpha}\right)^\frac{k}{2}e^{-u}\cdot \mathrm{d}\left(\sqrt{\frac{u}{\alpha}}\right)\\ &amp;=\int_0^{+\infty}\left(\frac{u}{\alpha}\right)^{\frac{k}{2}}e^{-u}\cdot \frac{1}{\alpha}\cdot\frac{1}{2}\cdot\sqrt{\frac{\alpha}{u}}\cdot\mathrm{d}u\\ &amp;=\frac{1}{2\alpha}\int_0^{+\infty}\left(\frac{u}{\alpha}\right)^\frac{k-1}{2}e^{-u}\mathrm{d}u\\ &amp;=\frac{1}{2\alpha^{\frac{k+1}{2}}}\int_0^{+\infty}u^{\frac{k-1}{2}}e^{-u}\mathrm{d}u\\ &amp;=\frac{1}{2\alpha^{\frac{k+1}{2}}}\int_0^{+\infty}u^{\left(\frac{k+1}{2}\right)-1}e^{-u}\mathrm{d}u\\ &amp;=\frac{1}{2\alpha^{\frac{k+1}{2}}}\cdot\Gamma\left(\frac{k+1}{2}\right)\\ \end{aligned}\] <p>然后我们最后把所有东西一股脑代进去大概整理一下得到答案：</p> \[\begin{aligned} f_T(t)&amp;=\frac{k^{\frac{k}{2}}}{\sqrt{2\pi}\cdot 2^{\frac{k}{2}-1}\cdot \Gamma\left(\frac{k}{2}\right)}\int_{0}^{+\infty}y^ke^{-\frac{(k+t^2)y^2}{2}}\mathrm{d}y\\ &amp;=\frac{k^{\frac{k}{2}}}{\sqrt{2\pi}\cdot 2^{\frac{k}{2}-1}\cdot\Gamma\left(\frac{k}{2}\right)}\cdot\frac{1}{2\alpha^{\frac{k+1}{2}}}\cdot\Gamma\left(\frac{k+1}{2}\right)\\ &amp;=\frac{\Gamma\left(\frac{k+1}{2}\right)\cdot 2^{\frac{k+1}{2}}\cdot k^{\frac{k}{2}}}{\sqrt{\pi}\cdot\Gamma\left(\frac{k}{2}\right)\cdot 2^{\frac{k+1}{2}}\cdot\left(k+t^2\right)^{\frac{k+1}{2}}}\\ &amp;=\frac{1}{\sqrt{\pi}}\cdot\frac{\Gamma\left(\frac{k+1}{2}\right)}{\Gamma\left(\frac{k}{2}\right)}\cdot\frac{k^{\frac{k}{2}}}{\left(k+t^2\right)^{\frac{k+1}{2}}}\\ &amp;=\frac{1}{\sqrt{\pi}}\cdot\frac{\Gamma\left(\frac{k+1}{2}\right)}{\Gamma\left(\frac{k}{2}\right)}\cdot\frac{1}{\sqrt{k}}\cdot\left(\frac{k}{k+t^2}\right)^{\frac{k+1}{2}}\\ &amp;=\frac{\Gamma\left(\frac{k+1}{2}\right)}{\sqrt{k\pi}\cdot\Gamma\left(\frac{k}{2}\right)}\cdot\left(1+\frac{t^2}{k}\right)^{-\frac{k+1}{2}} \end{aligned}\] <p>于是我们就得到了最终的 PDF：</p> \[f_T(t)=\frac{\Gamma\left(\frac{k+1}{2}\right)}{\sqrt{k\pi}\cdot\Gamma\left(\frac{k}{2}\right)}\cdot\left(1+\frac{t^2}{k}\right)^{-\frac{k+1}{2}}\] </details> <p>接下来是 \(F\) distribution。Motivation 是我们有俩 i.i.d. 的 random variables \(U_m\sim \chi_m^2, V_n\sim \chi_n^2\)，我们想知道 \(F=\frac{U_m/m}{V_n/n}\) 的 distribution 长啥样。</p> <p>PDF 是这样的：</p> \[f(w)=\frac{\Gamma\left(\frac{n+m}{2}\right)}{\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}\cdot\left(\frac{m}{n}\right)^{\frac{m}{2}}\cdot w^{\frac{m}{2}-1}\cdot\left(1+\frac{m}{n}w\right)^{-\frac{m+n}{2}}\] <details><summary>证明</summary> <p>首先我们先要知道 \(U_m/m\) 长啥样。</p> \[\begin{aligned} F_{U_m/m}(t)&amp;=\mathbb{P}\left(\frac{U_m}{m}\leq t\right)\\ &amp;=\mathbb{P}\left(U_m\leq mt\right)\\ &amp;=F_{U_m}(mt)\\ \end{aligned}\] <p>然后两边求导：</p> \[\begin{aligned} f_{U_m/m}(t)&amp;=\frac{\mathrm{d}F_{U_m/m}(t)}{\mathrm{d}t}\\ &amp;=f_{U_m}(mt)\cdot m\\ &amp;=\frac{m\cdot (mt)^{\frac{m}{2}-1}\cdot e^{-\frac{mt}{2}}}{2^{\frac{m}{2}}\cdot \Gamma\left(\frac{m}{2}\right)}\\ &amp;=\frac{m^{\frac{m}{2}}\cdot t^{\frac{m}{2}-1}\cdot e^{-\frac{mt}{2}}}{2^{\frac{m}{2}}\cdot \Gamma\left(\frac{m}{2}\right)}\\ \end{aligned}\] <p>于是我们也有：</p> \[f_{V_n/n}(t)=\frac{n^{\frac{n}{2}}\cdot t^{\frac{n}{2}-1}\cdot e^{-\frac{nt}{2}}}{2^{\frac{n}{2}}\cdot \Gamma\left(\frac{n}{2}\right)}\] <p>于是我们带入之前两个变量除法的柿子：</p> \[\begin{aligned} f_F(w)&amp;=\int_{-\infty}^{+\infty}|t|\cdot f_{U_m/m}(tw)\cdot f_{V_n/n}(t)\mathrm{d}t\\ &amp;=\int_{0}^{+\infty}t\cdot f_{U_m/m}(tw)\cdot f_{V_n/n}(t)\mathrm{d}t\\ &amp;=\int_0^{+\infty}t\cdot\frac{m^{\frac{m}{2}}\cdot (tw)^{\frac{m}{2}-1}\cdot e^{-\frac{mtw}{2}}}{2^{\frac{m}{2}}\cdot \Gamma\left(\frac{m}{2}\right)}\cdot\frac{n^{\frac{n}{2}}\cdot t^{\frac{n}{2}-1}\cdot e^{-\frac{nt}{2}}}{2^{\frac{n}{2}}\cdot \Gamma\left(\frac{n}{2}\right)}\mathrm{d}t\\ &amp;=\frac{m^\frac{m}{2}n^\frac{n}{2}\cdot w^{\frac{w}{2}-1}}{2^{\frac{m+n}{2}}\cdot \Gamma\left(\frac{m}{2}\right)\cdot \Gamma\left(\frac{n}{2}\right)}\int_0^{+\infty}t^{\frac{m+n}{2}-1}\cdot e^{-\frac{(mw+n)\cdot t}{2}}\mathrm{d}t \end{aligned}\] <p>故技重施换个元：</p> \[u=\frac{(mw+n)}{2}t\] <p>于是我们整理一下就可以了！</p> \[\begin{aligned} f_F(w)&amp;=\frac{m^\frac{m}{2}n^\frac{n}{2}\cdot w^{\frac{w}{2}-1}}{2^{\frac{m+n}{2}}\cdot \Gamma\left(\frac{m}{2}\right)\cdot \Gamma\left(\frac{n}{2}\right)}\int_0^{+\infty}t^{\frac{m+n}{2}-1}\cdot e^{-\frac{(mw+n)\cdot t}{2}}\mathrm{d}t\\ &amp;=\frac{m^{\frac{m}{2}}n^{\frac{n}{2}}\cdot w^{\frac{m}{2}-1}}{2^{\frac{m+n}{2}}\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}\int_{0}^{+\infty}\left(\frac{2u}{mw+n}\right)^{\frac{m + n}{2} - 1}e^{-u}\cdot\frac{2}{mw+n}\mathrm{d}u\\ &amp;=\frac{m^{\frac{m}{2}}n^{\frac{n}{2}}\cdot w^{\frac{m}{2}-1}}{(mw+n)^{\frac{m + n}{2}}\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}\int_{0}^{+\infty}u^{\frac{m+n}{2}-1}e^{-u}\mathrm{d}u\\ &amp;=\frac{\Gamma\left(\frac{m+n}{2}\right)}{\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}\cdot\frac{m^{\frac{m}{2}}n^{\frac{n}{2}}\cdot w^{\frac{m}{2}-1}}{(mw+n)^{\frac{m + n}{2}}}\\ &amp;=\frac{\Gamma\left(\frac{m+n}{2}\right)}{\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}\cdot w^{\frac{m}{2}-1}\cdot\left(\frac{m}{n}\right)^{\frac{m}{2}}\cdot n^{\frac{m}{2}}\cdot n^{\frac{n}{2}}\cdot\frac{1}{(mw+n)^{\frac{m + n}{2}}}\\ &amp;=\frac{\Gamma\left(\frac{m+n}{2}\right)}{\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}\cdot\left(\frac{m}{n}\right)^{\frac{m}{2}}\cdot w^{\frac{m}{2}-1}\cdot\left(\frac{n}{mw+n}\right)^{\frac{m + n}{2}}\\ &amp;=\frac{\Gamma\left(\frac{m+n}{2}\right)}{\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}\cdot\left(\frac{m}{n}\right)^{\frac{m}{2}}\cdot w^{\frac{m}{2}-1}\cdot\left(1+\frac{m}{n}w\right)^{-\frac{m + n}{2}} \end{aligned}\] <p>当然很多教材上我们会引入一个很像组合数的 Beta 函数：</p> \[B(z_1, z_2)=\frac{\Gamma(z_1)\Gamma(z_2)}{\Gamma(z_1+z_2)}\] <p>然后就能简写上面的式子。</p> </details> <details><summary>不同自由度的 \(F\) Distribution</summary> <div class="l-page"> <iframe src="/assets/plotly/2024-01-26-MH3500-Notes/distributions/F_distribution_change_M.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> <div class="l-page"> <iframe src="/assets/plotly/2024-01-26-MH3500-Notes/distributions/F_distribution_change_N.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> </details> <p>关于 \(t\) distribution 和 \(F\) distribution 有一定联系：</p> \[t_n^2\sim \frac{\mathcal{N}(0, 1)^2}{\chi_n^2/n}\sim \frac{\chi_1^2/1}{\chi_n^2/n}\sim F(1, n)\] <hr/> <h2 id="limit-theorems">Limit Theorems</h2> <p>这玩意儿其实我学概率的时候就没咋学好。</p> <p>就是首先是俩不等式。</p> <p>第一个是 Markov Inequality，就是假设有一个非负的随机变量 \(X\)，我们可以预测其尾部事件发生的概率上界：</p> \[\mathbb{P}(X\ge c)\le\frac{\mathbb{E}(X)}{c}\] <p>当然也有教材（比如 Hogg 那本 <d-cite key="hogg2019introduction"></d-cite>）说的是随便一个随机变量 \(X\)，然后如果 \(u(X)\) 为非负函数，那么：</p> \[\mathbb{P}(u(X)\ge c)\le\frac{\mathbb{E}(u(X))}{c}\] <p>不过反正都是一样的其实。</p> <p>一个简单的理解方式就是，“不超过 \(\frac{1}{n}\) 的人拥有超过平均 \(n\) 倍的工资”。</p> <details><summary>证明</summary> <p>其实证明是很简都嘟，我们首先考虑“不超过 \(\frac{1}{n}\) 的人拥有超过平均 \(n\) 倍的工资”这个命题。因为如果超过 \(\frac{1}{n}\) 了，那么就算其他人啥都没有（也就是 \(0\)），那平均也已经超过 \(\frac{1}{n}\times n\times \mathbb{E}(x)\) 了，那显然是だめ的。</p> <p>那我们照猫画虎证明一下尊命题。就是因为我们考虑到 \(X&gt;0\) 所以说 \(x\cdot f(x)&gt;0\)。那么很显然的</p> \[\begin{aligned} \mathbb{E}(X)&amp;=\int_0^\infty x\cdot f(x)\mathrm{d}x\\ &amp;\ge \int_{c}^\infty x\cdot f(x)\mathrm{d}x\\ &amp;\ge c\int_{c}^\infty f(x)\mathrm{d}x\\ &amp;=c\cdot \mathbb{P}(X\ge c) \end{aligned}\] </details> <p>第二个是 Chebyshev’s Inequality。就是假设 \(\mathbb{E}(X)\) 和 \(\mathrm{Var}(X)\) 都存在的情况下，我们考虑变量离均值的距离：</p> \[\mathbb{P}(|X - \mathbb{E}(X)|\ge t)\le \frac{\mathrm{Var}(X)}{t^2}\] <details><summary>证明</summary> <p>这个其实就是一个 Markov Inequality 的拓展，我们考虑：</p> \[\begin{aligned} \mathbb{P}(|X - \mathbb{E}(X)|\ge t)&amp;=\mathbb{P}((X - \mathbb{E}(X))^2\ge t^2)\\ &amp;\le \frac{\mathbb{E}((X - \mathbb{E}(X))^2)}{t^2}\\ &amp;=\frac{\mathrm{Var}(X)}{t^2} \end{aligned}\] </details> <p>然后是跟朋友讨论的时候看到的一个有趣的不等式，是一个很像 Chebyshev’s Inequality 的东西，叫做 Cantelli’s Inequality。其实就是单边的 Chebyshev’s Inequality：</p> \[\mathbb{P}(X - \mathbb{E}(X)\ge t)\le \frac{\mathrm{Var}(X)}{\mathrm{Var}(X) + t^2}\] <details><summary>证明</summary> <p>当时是他们期中考的一道考题，然鹅我想了半天没想出来。</p> <p>我们考虑的是把整个变量平移之后再平方，使得左边那部分可以忽略。假设我们平移了 \(a\)：</p> \[\begin{aligned} \mathbb{P}(X - \mathbb{E}(X)\ge t)&amp;=\mathbb{P}((X) - \mathbb{E}(X) + a\ge t + a)\\ &amp;\le \mathbb{P}\left(\left|X - \mathbb{E}(X) + a\right|\ge t + a\right)\\ &amp;=\mathbb{P}\left(\left(X - \mathbb{E}(X) + a\right)^2\ge \left(t + a\right)^2\right)\\ &amp;\le \frac{\mathbb{E}\left(\left(X - \mathbb{E}(X) + a\right)^2\right)}{\left(t + a\right)^2}\\ &amp;=\frac{\mathbb{E}\left(\left(X - \mathbb{E}(X)\right)^2+2\cdot a\cdot\left(X - \mathbb{E}(X)\right)+a^2\right)}{\left(t + a\right)^2}\\ &amp;=\frac{\mathbb{E}\left((X - \mathbb{E}(X))^2\right) + a^2}{\left(t + a\right)^2}\\ &amp;=\frac{\mathrm{Var}(X) + a^2}{\left(t + a\right)^2} \end{aligned}\] <p>然后我们因为是要求一个下界，也就是这个 \(a\) 是可以随便取的。那我们就求个导，看看取什么 \(a\) 最好：</p> \[\begin{aligned} \frac{\partial}{\partial a}\left(\frac{\mathrm{Var}(X) + a^2}{\left(t + a\right)^2}\right)&amp;=\frac{2a(t+a)^2-2(t+a)\cdot\left(a^2+\mathrm{Var}(X)\right)}{(t+a)^4}\\ &amp;=\frac{2at-2\cdot\mathrm{Var}(X)}{(t+a)^3} \end{aligned}\] <p>现在我们要让这个东西等于 \(0\)，那么我们就有：</p> \[\frac{2at-2\cdot\mathrm{Var}(X)}{(t+a)^3}=0\] <p>也就是：</p> \[a=\frac{\mathrm{Var}(X)}{t}\] <p>那我们把这个 \(a\) 代回去就可以了：</p> \[\begin{aligned} \mathbb{P}(X - \mathbb{E}(X)\ge t)&amp;\le \frac{\mathrm{Var}(X) + a^2}{\left(t + a\right)^2}\\ &amp;=\frac{\mathrm{Var}(X) + \left(\frac{\mathrm{Var}(X)}{t}\right)^2}{\left(t + \frac{\mathrm{Var}(X)}{t}\right)^2}\\ &amp;=\frac{\mathrm{Var}(X)\cdot t^2+\left(\mathrm{Var}(X)\right)^2}{\left(t^2 + \mathrm{Var}(X)\right)^2}\\ &amp;=\frac{\mathrm{Var}(X)\cdot\left(\mathrm{Var}(X) + t^2\right)}{\left(\mathrm{Var}(X) + t^2\right)^2}\\ &amp;=\frac{\mathrm{Var}(X)}{\mathrm{Var}(X) + t^2} \end{aligned}\] <p>于是乎我们就得到了一个比较紧的不等式。</p> </details> <p>弱大数定理的描述很简单，其实就是说当样本足够大的时候，sample mean 会收敛到 population mean。更数学一点，就是对于任意的 \(\epsilon&gt;0\)，我们都有：</p> \[\mathbb{P}\left(\left|\overline{X}_n-\mu\right|&gt;\epsilon\right)\to 0 \text{ as } n\to\infty\] <p>证明的话用切比雪夫搞搞就可以了。</p> <p>强大数定理：</p> \[\mathbb{P}\left(\lim_{n\to\infty}\overline{X}_n=\mu\right)=1\] <p>然后是 Central Limit Theorem (CLT)。我们令：</p> \[S_n=\sum_{i=1}^nX_i\] <p>那么：</p> \[\lim_{n\to\infty}\mathbb{P}\left(\frac{S_n}{\sigma\sqrt{n}}\le x\right)=\Phi(x)\] <details><summary>证明</summary> <p>上课的时候是只证了 MGF 存在的情况，看看暑假的时候有没有空写一写用 characteristic functions 的方法。</p> <p>就我们假设 \(Z_n=\frac{S_n}{\sigma\sqrt{n}}\)，\(\frac{X_i-\mu}{\sigma}\) 的 MGF 是 \(M(t)\)。</p> <p>我们考虑：</p> \[M_{\frac{S_n-n\mu}{\sigma}}(t)=\left(M(t)\right)^n\] <p>于是我们考虑 \(Z_n\) 的 MGF：</p> \[\begin{aligned} M_{Z_n}(t)&amp;=\mathbb{E}\left[e^{tZ_n}\right]\\ &amp;=\mathbb{E}\left[e^{t\frac{S_n-n\mu}{\sigma\sqrt{n}}}\right]\\ &amp;=\mathbb{E}\left[e^{\frac{t}{\sqrt{n}}\cdot\frac{\left(S_n-\mu\right)}{\sigma}}\right]\\ &amp;=M_{\frac{S_n-n\mu}{\sigma}}\left(\frac{t}{\sqrt{n}}\right)\\ &amp;=\left(M\left(\frac{t}{\sqrt{n}}\right)\right)^n \end{aligned}\] <p>然后我们考虑 \(M(t)\) 的泰勒展开：</p> \[M(t)=M(0)+M'(0)t+\frac{M''(0)}{2!}t^2+\varepsilon(t)\] <p>其中：</p> \[\lim_{t\to 0}\frac{\varepsilon(t)}{t^2}=0\] <p>然后我们考虑到：</p> \[\begin{cases} \mathbb{E}\left[\frac{X-\mu}{\sigma}\right]=0\\ \mathrm{Var}\left[\frac{X-\mu}{\sigma}\right]=1 \end{cases}\] <p>于是我们有：</p> \[\begin{cases} M(0)=1\\ M'(0)=\mathbb{E}\left[\frac{X-\mu}{\sigma}\right]=0\\ M''(0)=\mathbb{E}\left[\left(\frac{X-\mu}{\sigma}\right)^2\right]=\mathrm{Var}\left[\frac{X-\mu}{\sigma}\right]=1 \end{cases}\] <p>然后代进去！</p> \[\begin{aligned} M_{Z_n}(t)&amp;=\left(M\left(\frac{t}{\sqrt{n}}\right)\right)^n\\ &amp;=\left(M(0) + M'(0)\cdot t + M''(0)\cdot \frac{\left(\frac{t}{\sqrt{n}}\right)^2}{2}+\varepsilon\left(\frac{t}{\sqrt{n}}\right)\right)^n\\ &amp;=\left(1 + \frac{t^2}{2n} + \mathcal{O}\left(\frac{t^2}{n}\right)\right)^n \end{aligned}\] <p>又因为我们知道：</p> \[\lim_{n\to\infty}\left(1 + \frac{t}{2n}\right)^n=e^{t}\] <p>于是乎我们有：</p> \[\lim_{n\to\infty}M_{Z_n}(t)=e^{\frac{t^2}{2}}\] <p>而 \(e^{\frac{t^2}{2}}\) 就是 \(\mathcal{N}(0, 1)\) 的 MGF，于是乎我们成功证明了 CLT。</p> </details> <hr/> <h2 id="parameter-estimation">Parameter Estimation</h2> <p>有两种主要的 type of statistics，一种是 point statistics，一种是 interval statistics。顾名思义就是一种是直接去研究点的比如 sample mean，另一种是去研究区间比如 confidence interval。</p> <h3 id="point-estimation">Point Estimation</h3> <p>这边主要先讲的是 point statistics。</p> <p>现在假设我们有数据 \(\boldsymbol{x}=(x_1, x_2, \cdots, x_n)\)，我们认为他是由随机变量 \(\boldsymbol{X}=(X_1, X_2, \cdots, X_n)\) 所生成的，</p> <p>然后我们假设知道了 \(X\) 的分布应该是由某个参数 \(\boldsymbol{\theta}\) 决定，然后我们 point estimation 就是找到一个合适的函数 \(\hat{\boldsymbol{\theta}}(\boldsymbol{X})\) 来估计 \(\boldsymbol{\theta}\)。</p> <p>我们考虑如何评估一个 \(\hat{\theta}\) 的好坏，我们提出三个量：\(\mathrm{Bias}(\hat{\theta})\), \(\mathrm{SE}(\hat{\theta})\) 和 \(\mathrm{MSE}(\hat{\theta})\)。</p> <p>其中 Bias 预估的是 \(\hat{\theta}\) 对不对：</p> \[\mathrm{Bias}(\hat{\theta})=\mathbb{E}(\hat{\theta})-\theta\] <p>如果 \(\mathrm{Bias}(\hat{\theta})=0\)，那么我们就说 \(\hat{\theta}\) 是 unbiased 的。</p> <p>Standard Error 来评估的是 \(\hat{\theta}\) 的稳定性：</p> \[\mathrm{SE}(\hat{\theta})=\sqrt{\mathrm{Var}(\hat{\theta})}\] <p>而最后 Mean Squared Error 是综合评定了 \(\hat{\theta}\) 的准不准：</p> \[\mathrm{MSE}(\hat{\theta})=\mathbb{E}\left[\left(\hat{\theta}-\theta\right)^2\right]\] <p>而其中我们有：</p> \[\mathrm{MSE}(\hat{\theta})=\mathrm{Bias}(\hat{\theta})^2+\mathrm{SE}(\hat{\theta})^2\] <details><summary>证明</summary> \[\begin{aligned} \mathrm{MSE}(\hat{\theta})&amp;=\mathbb{E}\left(\left(\hat{\theta}-\theta\right)^2\right)\\ &amp;=\mathbb{E}\left(\hat{\theta}^2-2\cdot\hat{\theta}\cdot\theta+\theta^2\right)\\ &amp;=\mathbb{E}\left(\hat{\theta}^2\right)-2\cdot\theta\cdot\mathbb{E}\left(\hat{\theta}\right)+\theta^2\\ &amp;=\left[\mathbb{E}\left(\hat{\theta}^2\right)-\left(\mathbb{E}(\hat{\theta})\right)^2\right]+\left[\left(\mathbb{E}(\hat{\theta})\right)^2-2\cdot\theta\cdot\mathbb{E}\left(\hat{\theta}\right)+\theta^2\right]\\ &amp;=\mathrm{Var}(\hat{\theta})+\left[\mathbb{E}(\hat{\theta})-\theta\right]^2\\ &amp;=\mathrm{SE}(\hat{\theta})^2+\mathrm{Bias}(\hat{\theta})^2 \end{aligned}\] <p>不是很理解为什么如果不在长公式后随便加一句话 presentation 就会出问题啊啊啊啊啊啊啊啊啊啊</p> </details> <p>有一个事情就是有时候我们不一定更 prefer \(\mathrm{Bias}(\hat{\theta})=0\) 的，而是更喜欢 \(\mathrm{MSE}\) 更小的。</p> <details><summary>例子</summary> <p>比如说我们需要估计 \(X\sim \mathcal{B}(n, \theta)\) 中的 \(\theta\)。一个很显然的 unbiased estimator 就是 \(\hat{\theta}=\frac{X}{n}\)。那这个 estimator 的 variance 是 \(\mathrm{Var}(\hat{\theta})=\frac{\mathrm{Var}_\theta(X)}{n^2}=\frac{\theta\cdot(1-\theta)}{n^2}\)。</p> <p>我们考虑另一个 estimator \(\hat{\theta}=w\cdot\frac{X}{n}+(1-w)\cdot\frac{1}{2}\)，其中 \(w\) 是我们想要定的一个权重。于是乎</p> \[\begin{aligned} \mathbb{E}(\hat{\theta})&amp;=w\cdot\theta+(1-w)\cdot\frac{1}{2}\\ \mathrm{Bias}(\hat{\theta})&amp;=\left(1-w\right)\left(\frac{1}{2}-\theta\right)\\ \mathrm{Var}(\hat{\theta})&amp;=w^2\frac{\theta\cdot(1-\theta)}{n^2}\\ \mathrm{MSE}(\hat{\theta})&amp;=w^2\frac{\theta\cdot(1-\theta)}{n^2}+\left(1-w\right)^2\left(\frac{1}{2}-\theta\right)^2 \end{aligned}\] <p>也就是说，如果我们想让 \(\mathrm{MSE}(\hat{\theta})\) 尽量在普遍情况下都小，我们可以在 \(\frac{\theta\cdot(1-\theta)}{n^2}\) 和 \(\left(\frac{1}{2}-\theta\right)^2\) 之间找平衡。</p> <p>如果我们找到一个合适的 \(w\)，很可能这个 estimator 在一些情况下 MSE 会更小。比如下面画的是当 \(n=5\) 时，取 \(w=\frac{n}{n + 0.5}\) 的图，可以看到这个 estimator 更加均衡，在中间的很大一段区间内 MSE 都比较小。</p> <div class="l-page"> <iframe src="/assets/plotly/2024-01-26-MH3500-Notes/estimation/mse.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> </details> <p>当然还有一个是 consistency，是指在数据量足够大的时候，预测出来的参数是对的。也就是对于任意 $\varepsilon &gt; 0$，我们都有：</p> \[\lim_{n\to\infty}\mathbb{P}\left(\left|\hat{\theta}_n-\theta\right|&gt;\varepsilon\right)=0\] <p>一个显然的充分条件是如果</p> \[\begin{cases} \lim_{n\to\infty}\mathrm{Bias}(\hat{\theta}_n)=0\\ \lim_{n\to\infty}\mathrm{SE}(\hat{\theta}_n)=0 \end{cases}\] <p>那么 \(\hat{\theta}\) 肯定是 consistent 的。</p> <p>接下来有个叫做 sufficient statistics 的东西。假设我们有个 statistic \(T(\boldsymbol{X})\) 和一个参数 \(\theta\)。我们想知道 \(T\) 是否包含了数据 \(\boldsymbol{x}\) 所能给出的关于 \(\theta\) 的全部信息。也就是说，如果我们知道了 \(T\)，我们就不需要再知道 \(\theta\) 了。</p> <p>所以我们定义 \(T(\boldsymbol{X})\) 是 sufficient statistic，当且仅当 \(\mathbb{P}_{\boldsymbol{X}\mid T}(\boldsymbol{x}\mid T=t)\) 不依赖于 \(\theta\)。</p> <p>判断 \(T\) 是不是 sufficient 的有一个充要条件，就是需要能对 \(f_\boldsymbol{X}(\boldsymbol{x}\mid\theta)\) 进行分解：</p> \[f_{\boldsymbol{X}}(\boldsymbol{x}\mid\theta)=g(T(\boldsymbol{x}), \theta)\cdot h(\boldsymbol{x})\] <details><summary>证明</summary> <p>假设我们有</p> \[f_{\boldsymbol{X}}(\boldsymbol{x}\mid\theta)=g(T(\boldsymbol{x}), \theta)\cdot h(\boldsymbol{x})\] <p>那么对于 \(T(\boldsymbol{x})=t\)，有：</p> \[\begin{aligned} f_{\boldsymbol{X}\mid T}(x\mid T=t)&amp;=\frac{\mathbb{P}(\boldsymbol{X}=\boldsymbol{x}\land T=t)}{\mathbb{P}(T=t)}\\ &amp;=\frac{\mathbb{P}(\boldsymbol{X}=\boldsymbol{x})}{\mathbb{P}(T=t)}\\ &amp;=\frac{f_{\boldsymbol{X}}(\boldsymbol{x}\mid\theta)}{\sum_{T(\boldsymbol{x}'=t)}f_{\boldsymbol{X}}(\boldsymbol{x}'\mid\theta)}\\ &amp;=\frac{g(t, \theta)\cdot h(\boldsymbol{x})}{\sum_{T(\boldsymbol{x}'=t)}g(t, \theta)\cdot h(\boldsymbol{x}')}\\ &amp;=\frac{h(x)}{\sum_{T(\boldsymbol{x}'=t)}h(\boldsymbol{x}')} \end{aligned}\] <p>现在我们先假设 \(T\) 是 sufficient 的，那么我们就有：</p> \[\begin{aligned} f(\boldsymbol{x}\mid\theta)&amp;=\mathbb{P}(\boldsymbol{X}=\boldsymbol{x})\\ &amp;=\mathbb{P}(\boldsymbol{X}=\boldsymbol{x}\land T=T(\boldsymbol{x}))\\ &amp;=\mathbb{P}(\boldsymbol{X}=\boldsymbol{x}\mid T=T(\boldsymbol{x}))\cdot\mathbb{P}(T=T(\boldsymbol{x})) \end{aligned}\] <p>考虑到 \(T\) 是 sufficient 的，所以 \(\mathbb{P}(\boldsymbol{X}=\boldsymbol{x}\mid T=T(\boldsymbol{x}))\) 不依赖于 \(\theta\)，我们令</p> \[\begin{cases} g(T, \theta)=\mathbb{P}(T=T(\boldsymbol{x}))\\ h(\boldsymbol{x})=\mathbb{P}(\boldsymbol{X}=\boldsymbol{x}\mid T=T(\boldsymbol{x})) \end{cases}\] <p>那么我们就有</p> \[f(\boldsymbol{x}\mid\theta)=g(T(\boldsymbol{x}), \theta)\cdot h(\boldsymbol{x})\] <p>于是我们充分必要就都证完了。</p> </details> <p>接下来是 estimation methods。首先需要讲一个比较简单的 Method of Moments。这种方法的动机很简单，就是我们考虑到</p> \[\mathbb{E}\left[\frac{1}{n}\sum_{i=1}^nX_i^k\right]=\mathbb{E}\left[X^k\right]=\mu_k\] <p>也就是说用 \(\frac{1}{n}\sum_{i=1}^nX_i^k\) 来估计 \(\mu_k\) 是无偏的。</p> <p>那我们就可以找到一个 \(m\) 使得 \(\boldsymbol{\mu}=(\mu_1, \mu_2, \cdots, \mu_m)\)，算出：</p> \[\boldsymbol{\mu}=g(\boldsymbol{\theta})\] <p>其中 \(g\) 是 one-to-one 的，那我们就可以找到 \(h=g^{-1}\) 使得：</p> \[\boldsymbol{\theta}=h(\boldsymbol{\mu})\Rightarrow\hat{\boldsymbol{\theta}}=h(\hat{\boldsymbol{\mu}})\] <p>接下来就是 Maximum Likelihood Estimation (MLE)。我们定义 likelihood function 为：</p> \[\mathcal{L}(\boldsymbol{x}\mid\boldsymbol{\theta})=\mathbb{P}(\boldsymbol{X}=\boldsymbol{x}\mid\boldsymbol{\theta})=\prod_{i=1}^n f(x_i\mid\boldsymbol{\theta})\] <p>在离散情况下就是出现 \(\boldsymbol{x}\) 的概率，在连续情况下是概率省去 \(\left(\mathrm{d}x\right)^n\) 的值。</p> <p>关于连续情况下为啥是这个其实很好理解，就是我们同样是考虑概率，只不过考虑的是 \(x\in \left[x_i-\delta, x_i+\delta\right]\) 的概率，然后取极限之后除以 \(\left(2\delta\right)^n\) 就可以了。</p> <p>接下来我们先讨论一个参数的情况，我们让 \(\boldsymbol{\theta}\) 变成一个标量，也就是 \(\theta\)。</p> <p>我们想要算的是 likelihood function 的最大值，也就是说我们要找到一个 \(\hat{\theta}\) 使得：</p> \[\left.\frac{\partial}{\partial\theta}\mathcal{L}(\boldsymbol{x}\mid\theta)\right|_{\theta=\hat{\theta}}=0\] <p>当然有个条件是这个 \(\mathcal{L}\) 是足够好的，这个“足够好”是需要在某个区间 \((a, b)\subseteq\mathbb{R}\) 上满足三个条件，我们称之为 regularity conditions：</p> <ol> <li>\(\forall\theta\in(a, b)\)，\(\mathcal{L}(\theta)&gt;0\)；</li> <li>\(\forall\theta\in(a, b)\)，\(\frac{\partial\mathcal{L}}{\partial\theta}\) 存在；</li> <li>\(\lim_{\theta\to a^{+}}\mathcal{L}(\theta)=\lim_{\theta\to b^{-}}\mathcal{L}(\theta)=0\)。</li> </ol> <p>可是一堆乘积的偏导实在太难算了，考虑到 \(y=\log x\) 是单调递增的，于是我们对其取 \(\log\)：</p> \[\ell(\boldsymbol{x}\mid\theta)=\log\mathcal{L}(\boldsymbol{x}\mid\theta)=\sum_{i=1}^n\log f(x_i\mid\theta)\] <p>我们将其称为 log-likelihood function。</p> <p>当然，取 \(\log\) 的时候事实上是必须要满足某些性质的，只是这些性质在大部分情况下都满足。事实上要满足的是 Regularity Conditions 的 \(\mathcal{R}_0\sim \mathcal{R}_2\)。</p> <details><summary>Regularity Conditions</summary> <ul> <li>\(\mathcal{R}_0\): The CDFs are distinct; i.e., \(\theta\neq\theta'\Rightarrow F(x_i\mid\theta)\neq F(x_i\mid\theta)\).</li> <li>\(\mathcal{R}_1\): The PDFs have common support. 也就是说，对于每个 \(\theta\)，\(\{x: f(x\mid\theta)&gt;0\}\) 是相同的。</li> <li>\(\mathcal{R}_2\): The point \(\theta_0\) is an interior point in \(\Omega\).</li> <li>\(\mathcal{R}_3\): The PDF \(f(x\mid\theta)\) is twice differentiable as a function of \(\theta\).</li> <li>\(\mathcal{R}_4\): The integral \(\int f(x\mid\theta)\mathrm{d}x\) can be differentiated twice under the integral sign as a function of \(\theta\).</li> <li>\(\mathcal{R}_5\): The PDF \(f(x\mid\theta)\) is three times differentiable as a function of \(\theta\). Further, for all \(\theta\in\Omega\), there exist a constant \(c\) and a function \(M(x)\) such that \(\left\lvert\frac{\partial^3}{\partial\theta^3}\log f(x\mid\theta)\right\rvert\le M(x)\), with \(\mathbb{E}_{\theta_0}[M(X)] &lt; \infty\), for all \(θ_0 - c &lt; \theta &lt; \theta_0 + c\) and all \(x\) in the support of \(X\).</li> </ul> <p>而事实上，\(\mathcal{R}_1\sim\mathcal{R}_4\) 的作用是保证了：</p> <ol> <li>\(\theta\) 不会出现在 \(f(x\mid\theta)\) 的边界上；</li> <li>我们可以交换积分和求导符号：\(\frac{\partial}{\partial\theta}\int_{-\infty}^{\infty}f(x\mid\theta)\mathrm{d}x=\int_{-\infty}^{\infty}\frac{\partial}{\partial\theta}f(x\mid\theta)\mathrm{d}x\)</li> </ol> </details> <p>而这东西其实和 cross entropy 是等价的：</p> \[\mathcal{H}(p, q)=-\mathbb{E}_p[\log q]\] <p>也就是说：</p> \[\hat{\boldsymbol{\theta}}=\arg\max_{\boldsymbol{\theta}}\mathcal{L}(\boldsymbol{x}\mid\boldsymbol{\theta})=\arg\max_{\boldsymbol{\theta}}\ell(\boldsymbol{x}\mid\boldsymbol{\theta})=\arg\min_{\boldsymbol{\theta}}\mathcal{H}(p, q_{\boldsymbol{\theta}})=\arg\min_{\boldsymbol{\theta}}\mathrm{KL}(p\|q_{\boldsymbol{\theta}})\] <details><summary>Cross Entropy and KL Divergence</summary> <p>这里详细介绍一下 cross entropy。</p> <p>首先是 entropy。</p> <p>我们想知道如果某个概率为 \(p\) 的事件发生，我们所能得到的信息是多少，我们将这个“信息”定义为 Surprising Function \(\mathcal{S}(p)\)，我们考虑构造这个函数。</p> <p>我们思考这个函数需要满足哪些性质：</p> <ol> <li>如果 \(A\) 和 \(B\) 是两个独立事件，那么当我们知道这两个事件同时发生时，我们应该得到双倍的信息，也就是 \(\mathcal{S}(\mathbb{P}(A\cap B))=f(\mathbb{P}(A))+f(\mathbb{P}(B))\)；</li> <li>如果 \(p=1\)，那么这个事情一点也不奇怪，也就是我们啥信息都得不到，\(S(1)=0\)；</li> <li>如果 \(p\) 很小，那么这个事情很奇怪，也就是我们得到的信息很多，所以 \(\mathcal{S}(p)\) 应该是单调递减的。</li> </ol> <p>根据这两个性质，我们能够造出的 \(\mathcal{S}\) 只能是长这样的：</p> \[\mathcal{S}(p)=-c\log_a p\] <p>而一般情况下我们取 \(c=1, a=2\)，并由此定义信息熵：</p> \[\mathcal{H}(X)=\mathbb{E}[\mathcal{S}(p_\mathcal{X})]=-\mathbb{E}[\log_2 p_X]=\begin{cases} -\sum_{x\in X}p(x)\log_2 p(x) &amp; \text{Discrete}\\ -\int_{X}f(x)\log_2 f(x)\mathrm{d}x &amp; \text{Continuous} \end{cases}\] <p>\(\mathcal{H}\) 越大表示事件的不确定性越大，我们知道结果时期望得到的信息越多。</p> <p>在信息论中，\(\mathcal{H}(X)\) 表示了大概需要多少个二进制 bit 来表示某个事件。</p> <p>接下来是 Kullback-Leibler Divergence，我们定义：</p> \[\begin{aligned} \mathrm{KL}(p\| q)&amp;=\sum_x p(x)\log\left(\frac{p(x)}{q(x)}\right)\\ &amp;=\sum_x p(x)\log p(x)-\sum_x p(x)\log q(x)\\ &amp;=-\mathcal{H}(p)+\mathcal{H}(p, q) \end{aligned}\] <p>指的是当我们用 \(q\) 的最优编码来编码 \(p\) 所需要的额外 bit 数量。</p> <p>而其中的 \(\mathcal{H}(p, q)\) 就是 cross entropy，也就是当我们用 \(q\) 来编码 \(p\) 所需要的平均 bit 数量：</p> \[\mathcal{H}(p, q)=-\mathbb{E}_p[\log q]\] </details> <p>课上讲了一个叫做 Condition (*) 的东西，其实就是积分和求导的可交换性。接下来我们经常要用到。然而其实这个 condition 大部分常见的函数都是满足的，其实很多情况下我们都是在直接用的。</p> <details><summary>Condition (*)</summary> <p>离散情况：</p> \[\sum_x\frac{\partial}{\partial\theta}f(x\mid\theta)=\frac{\partial}{\partial\theta}\sum_xf(x\mid\theta)\] <p>连续情况：</p> \[\int_{-\infty}^{\infty}\frac{\partial}{\partial\theta}f(x\mid\theta)\mathrm{d}x=\frac{\partial}{\partial\theta}\int_{-\infty}^{\infty}f(x\mid\theta)\mathrm{d}x\] <p>而事实上这个 condition 就是 Regularity Conditions 的一个推论。</p> </details> <p>当随机变量满足 Condition (*) 时，我们能证明 MLE 一定是 consistent 的。</p> <details><summary>证明</summary> <p>考虑到当 \(n\to\infty\) 时，</p> \[\frac{1}{n}\ell(\boldsymbol{x}\mid\theta)=\frac{1}{n}\sum_{i=1}^n\log f(x_i\mid\theta)\to\mathbb{E}[\log f(x\mid\theta)]\] <p>我们假设真实参数为 \(\theta_0\)，那么我们有：</p> \[\mathbb{E}[\log f(x\mid\theta)]=\int_{-\infty}^{\infty}f(x\mid\theta_0)\cdot\log f(x\mid\theta)\cdot\mathrm{d}x\] <p>根据 Condition (*)，我们有：</p> \[\begin{aligned} \frac{\partial}{\partial\theta}\mathbb{E}[\log f(x\mid\theta)]&amp;=\frac{\partial}{\partial\theta}\int_{-\infty}^{\infty}f(x\mid\theta_0)\cdot\log f(x\mid\theta)\cdot\mathrm{d}x\\ &amp;=\int_{-\infty}^{\infty}\frac{\partial}{\partial\theta}f(x\mid\theta_0)\cdot\log f(x\mid\theta)\cdot\mathrm{d}x\\ &amp;=\int_{-\infty}^{\infty}f(x\mid\theta_0)\cdot\frac{\partial}{\partial\theta}\log f(x\mid\theta)\cdot\mathrm{d}x\\ &amp;=\int_{-\infty}^{\infty}f(x\mid\theta_0)\cdot\frac{\frac{\partial}{\partial\theta}f(x\mid\theta)}{f(x\mid\theta)}\mathrm{d}x\\ \end{aligned}\] <p>当 \(\theta=\theta_0\) 时，我们有：</p> \[\begin{aligned} \frac{\partial}{\partial\theta}\lim_{n\to\infty}\frac{1}{n}\ell(\theta)&amp;=\frac{\partial}{\partial\theta}\mathbb{E}[\log f(x\mid\theta)]\\ &amp;=\int_{-\infty}^{\infty}f(x\mid\theta_0)\cdot\frac{\frac{\partial}{\partial\theta}f(x\mid\theta)}{f(x\mid\theta)}\mathrm{d}x\\ &amp;=\int_{-\infty}^{\infty}\frac{\partial}{\partial\theta}f(x\mid\theta_0)\mathrm{d}x\\ &amp;=\frac{\partial}{\partial\theta}\int_{-\infty}^{\infty}f(x\mid\theta_0)\mathrm{d}x\\ &amp;=\frac{\partial}{\partial\theta}1=0 \end{aligned}\] <p>也就是说当 \(n\to\infty\) 的时候，\(\theta=\theta_0\) 一定是 \(\frac{\partial\ell}{\partial\theta}=0\) 的一个解，也就是说 MLE 一定是 consistent 的。</p> </details> <p>接下来我们考虑估计 \(\hat{\theta}\) 的效率，首先我们来感性理解一下。当 \(n\) 足够大的时候，考虑到 MLE 是 consistent 的，也就是说 \(\hat{\theta}-\theta\approx 0\)。于是我们有：</p> \[\frac{\partial}{\partial\theta}\ell(\hat{\theta})\approx\frac{\partial}{\partial\theta}\ell(\theta) + \frac{\partial}{\partial\theta}\left(\frac{\partial}{\partial\theta}\ell\right)(\theta)\cdot(\hat{\theta}-\theta)=\frac{\partial}{\partial\theta}\ell(\theta) + \frac{\partial^2}{\partial\theta^2}\ell(\theta)\cdot(\hat{\theta}-\theta)\] <p>考虑到 \(\frac{\partial}{\partial\theta}\ell(\hat{\theta})=0\)，我们有：</p> \[\hat{\theta}-\theta\approx-\frac{\frac{\partial}{\partial\theta}\ell(\theta)}{\frac{\partial^2}{\partial\theta^2}\ell(\theta)}\] <p>我们考虑这个 \(-\frac{\frac{\partial}{\partial\theta}\ell(\theta)}{\frac{\partial^2}{\partial\theta^2}\ell(\theta)}\)，首先我们有：</p> \[\frac{\partial}{\partial\theta}\ell(\theta)=\frac{\partial}{\partial\theta}\sum_{i=1}^n\log f(x_i\mid\theta)=\sum_{i=1}^n\frac{\partial}{\partial\theta}\log f(x_i\mid\theta)\] <p>是一个和式的形式，根据 CLT，当 \(n\) 足够大的时候，我们有：</p> \[\frac{\partial}{\partial\theta}\ell(\theta)\to\mathcal{N}\left(\mathbb{E}\left[\frac{\partial}{\partial\theta}\ell(\theta)\right], \mathrm{Var}\left(\frac{\partial}{\partial\theta}\ell(\theta)\right)\right)\] <p>当然其实我们有：</p> \[\begin{aligned} \mathbb{E}\left[\frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\right]&amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)\mathrm{d}\vec{x}\\ &amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\frac{\partial}{\partial\theta}\log f(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)\mathrm{d}\vec{x}\\ &amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\frac{\frac{\partial}{\partial\theta}f(\vec{x}\mid\theta)}{f(\vec{x}\mid\theta)}\cdot f(\vec{x}\mid\theta)\mathrm{d}\vec{x}\\ &amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\frac{\partial}{\partial\theta}f(\vec{x}\mid\theta)\mathrm{d}\vec{x}\\ &amp;=\frac{\partial}{\partial\theta}\idotsint_{\vec{x}\in\mathbb{R}^n}f(\vec{x}\mid\theta)\mathrm{d}\vec{x}\\ &amp;=\frac{\partial}{\partial\theta}1=0 \end{aligned}\] <p>方差的式子比较难算，但是我们可以先列出来：</p> \[\mathrm{Var}\left(\frac{\partial}{\partial\theta}\ell(x\mid\theta)\right)=\mathbb{E}\left[\left(\frac{\partial}{\partial\theta}\ell(x\mid\theta)\right)^2\right]\] <p>组合起来，也就是：</p> \[\frac{\partial}{\partial\theta}\ell(\theta)\to\mathcal{N}\left(0, \mathbb{E}\left[\left(\frac{\partial}{\partial\theta}\ell(\theta)\right)^2\right]\right)\] <p>而考虑到分母除了一个数，当 \(n\) 特别大的时候，我们感性地认为这个数是一个常数，也就是分母的期望。于是我们有：</p> \[\begin{aligned} \hat{\theta}-\theta&amp;\approx-\frac{\frac{\partial}{\partial\theta}\ell(\theta)}{\frac{\partial^2}{\partial\theta^2}\ell(\theta)}\\ &amp;\to \mathcal{N}\left( 0, \frac{\mathbb{E}\left[\left(\frac{\partial}{\partial\theta}\ell(\theta) \right)^2\right ]}{\left(\mathbb{E}\left[-\frac{\partial^2}{\partial\theta^2}\ell(\theta) \right ] \right )^2} \right ) \end{aligned}\] <p>具体为什么除以期望时可以的 Hogg <d-cite key="hogg2019introduction"></d-cite> 的书上给了具体的证明，上课老师没讲所以有空回来补。</p> <p>然后意见非常有趣的事情是我们考虑：</p> \[\idotsint_{\vec{x}\in\mathbb{R}^n}f(x\mid\theta)\mathrm{d}\vec{x}=1\] <p>我们对两边求导，有：</p> \[\begin{aligned} 0&amp;=\frac{\partial}{\partial\theta}\idotsint_{\vec{x}\in\mathbb{R}^n}f(x\mid\theta)\mathrm{d}\vec{x}\\ &amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\frac{\partial}{\partial\theta}f(x\mid\theta)\mathrm{d}\vec{x} \end{aligned}\] <p>而考虑到</p> \[\frac{\partial}{\partial\theta}\log f(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)=\frac{\partial}{\partial\theta}f(\vec{x}\mid\theta)\] <p>所以我们有：</p> \[\begin{aligned} 0&amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\frac{\partial}{\partial\theta}f(\vec{x}\mid\theta)\mathrm{d}\vec{x}\\ &amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\frac{\partial}{\partial\theta}\log f(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)\mathrm{d}\vec{x}\\ &amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)\mathrm{d}\vec{x} \end{aligned}\] <p>这个其实是我们刚才得出的</p> \[\mathbb{E}\left[\frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\right]=0\] <p>然后我们对式子的左右两边再求导：</p> \[\begin{aligned} 0&amp;=\frac{\partial}{\partial\theta}\left( \idotsint_{\vec{x}\in\mathbb{R}^n}\frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)\mathrm{d}\vec{x}\right )\\ &amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\frac{\partial}{\partial\theta}\left( \frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)\right )\mathrm{d}\vec{x}\\ &amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\left( \frac{\partial^2}{\partial\theta^2}\ell(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)+\frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\cdot \frac{\partial}{\partial\theta}f(\vec{x}\mid\theta)\right )\mathrm{d}\vec{x}\\ &amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\left( \frac{\partial^2}{\partial\theta^2}\ell(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)+\frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\cdot \frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)\right )\mathrm{d}\vec{x}\\ &amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\left( \frac{\partial^2}{\partial\theta^2}\ell(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)+\left(\frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\right)^2\cdot f(\vec{x}\mid\theta)\right )\mathrm{d}\vec{x}\\ &amp;=\idotsint_{\vec{x}\in\mathbb{R}^n}\left( \frac{\partial^2}{\partial\theta^2}\ell(\vec{x}\mid\theta)\cdot f(\vec{x}\mid\theta)\right)+\idotsint_{\vec{x}\in\mathbb{R}^n}\left(\left(\frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\right)^2\cdot f(\vec{x}\mid\theta)\right )\mathrm{d}\vec{x}\\ &amp;=\mathbb{E}\left [ \frac{\partial^2}{\partial\theta^2}\ell(\vec{x}\mid\theta) \right ]+\mathbb{E}\left[\left(\frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\right)^2 \right ] \end{aligned}\] <p>也就是说我们得到了：</p> \[\mathbb{E}\left[\left(\frac{\partial}{\partial\theta}\ell(\vec{x}\mid\theta)\right)^2 \right ]=-\mathbb{E}\left [ \frac{\partial^2}{\partial\theta^2}\ell(\vec{x}\mid\theta) \right ]\] <p>于是乎</p> \[\begin{aligned} \hat{\theta}-\theta&amp;\to \mathcal{N}\left( 0, \frac{\mathbb{E}\left[\left(\frac{\partial}{\partial\theta}\ell(\theta) \right)^2\right ]}{\left(\mathbb{E}\left[-\frac{\partial^2}{\partial\theta^2}\ell(\theta) \right ] \right )^2} \right )\\ &amp;\equiv\mathcal{N}\left(0, \frac{1}{\mathbb{E}\left[\left(\frac{\partial}{\partial\theta} \ell(\theta)\right ) ^2\right ]} \right ) \end{aligned}\] <p>当然事实上我们是一个比较不严谨的推理过程，主要是根据 Rice <d-cite key="rice2006mathematical"></d-cite> 的书写的。具体的细节有空再补。</p> <p>而我们将这个 variance 的倒数定义为 Fisher Information：</p> \[\mathcal{I}_{\vec{X}}(\theta)=\mathbb{E}\left[\left(\frac{\partial}{\partial\theta}\ell(\theta)\right)^2\right]\] <p>在满足 \(\mathcal{R}_0\sim\mathcal{R}_4\) 的情况下，我们能得到 Fisher Information 的另一个表达式：</p> \[\mathcal{I}_{\vec{X}}(\theta)=-\mathbb{E}\left[\frac{\partial^2}{\partial\theta^2}\ell(\theta)\right]\] <p>在满足 \(\mathcal{R}_0\sim\mathcal{R}_5\) 的情况下，如果 \(n\to\infty\)，那么我们有：</p> \[\hat{\theta}-\theta\to\mathcal{N}\left(0, \frac{1}{\mathcal{I}_{\vec{X}}(\theta)}\right)\]]]></content><author><name>Pu Fanyi</name></author><category term="Notes"/><category term="Statistics"/><category term="Probability Theory"/><summary type="html"><![CDATA[Notes for NTU MH3500 Statistics.]]></summary></entry></feed>